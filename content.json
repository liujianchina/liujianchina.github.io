{"meta":{"title":"树先生的金融风控工程师博客","subtitle":"","description":"","author":"树先生","url":"https://blog.sofunnyai.com","root":"/"},"pages":[{"title":"about-关于我","date":"2018-03-21T08:41:44.000Z","updated":"2020-05-20T08:46:47.021Z","comments":true,"path":"about/index.html","permalink":"https://blog.sofunnyai.com/about/index.html","excerpt":"","text":""},{"title":"categories-博文分类","date":"2018-03-21T08:35:01.000Z","updated":"2020-05-20T08:46:34.397Z","comments":true,"path":"categories/index.html","permalink":"https://blog.sofunnyai.com/categories/index.html","excerpt":"","text":""},{"title":"tags-标签文章","date":"2018-03-21T08:41:37.000Z","updated":"2020-05-20T08:46:25.013Z","comments":true,"path":"tags/index.html","permalink":"https://blog.sofunnyai.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"风控策略相关的一切","slug":"strategy","date":"2020-04-15T06:37:22.000Z","updated":"2020-05-25T09:22:58.773Z","comments":true,"path":"article/strategy.html","link":"","permalink":"https://blog.sofunnyai.com/article/strategy.html","excerpt":"","text":"风控策略概要 什么是风控审批策略 其中多维度数据的策略规则包括： 风控审批策略的目的 风控审批策略的作用 风控审批策略的类别 风控的基本量化指标 确定目标变量 制定风控审批策略 策略预估 策略监控 策略回顾 风控策略分析师 日常工作内容 必备技能 核心作用 策略分析常见工作场景与对应分析方法 三方数据测评 举例—黑名单数据评测 准入策略的制定 年龄准入策略 地区准入策略 白名单策略 黑名单策略 规则阈值cutoff如何设定 背景 第一步：通过评分找到风险被低估的区间 第二步，评估拟拒绝人群的收益/风险比 通过率下降的策略调整 1.寻找通过率下降的时间点或时间段 2.判断策略节点主次要拒绝影响 3.从节点聚焦到节点规则层深度分析 4.具体规则分布分析 5.分析指导决策 逾期率上升的策略调整 第一步：确定存量还是新增客户导致逾期上升 第二步：多维度分析，找出最主要影响规则 第三步：制定策略调整方案 信用多头策略 1.什么是多头借贷 2.多头借贷数据的分析方法 3.多头借贷数据为何少用于模型 4.多头借贷数据在策略规则上的应用 评分的策略应用 评分卡模型的运用，主要是为了解决两大问题： 评分模型的cutoff 模型与策略的关系 模型是否可以替代所有的策略规则? 策略规则+评分模型 策略规则+模型规则 策略规则的粗放式管理 评分模型的常见三种盲区 建模数据集与实际贷款人之间存在偏差 模型数据集来自历史，与未来实际情况存在偏差 模型对于目标变量的界定与实际商业目标存在偏差 精简摘录自微信公众号：金科应用研院，有精简 风控策略概要# 什么是风控审批策略# 基于数据分析在申请阶段制定各式各样多维度的策略和规则; 其中多维度数据的策略规则包括：# 社交及短信维度规则 移动设备维度规则 外部数据源（如：征信报告、各种黑名单来源）规则 多维度评分卡规则 行为数据(设备信息、注册时间、登陆时间)规则 风控审批策略的目的# 在贷前审批减少风险事件的发生的各种可能性，挽回风险事件时造成的损失。较大的程度上筛选过滤高风险客户，保留低风险客户予以营销。针对客群分级实行个性化的审批流程，提高审批效率。 风控审批策略的作用# 在保证业务量的同时降低业务坏账率、控制逾期风险，最终实现公司盈利。 风控审批策略的类别# 多维度数据分析呈现了借款人的用户画像，制定多维度完善的审批策略规则，具体策略规则包含： 1）经济能力维度(月收入、工资流水等信息) 2）app信息维度(贷款APP安装个数、短信命中高风险关键词) 3）基本信息维度(年龄、性别、工龄等信息) 4）信用历史(征信贷款信息、还款记录) 5）行为表现(活动轨迹、登陆时间、注册时间等信息) 风控的基本量化指标# FPDx：首期逾期，x对应天数 CPDx：当前逾期，x对应天数 逾期时间的长短来定义逾期的等级，C代表正常资产。M3-M6属于不良，M6+属于坏账。 迁移率、vintage账龄分析、滚动率见上一篇博客，这里：https://blog.sofunnyai.com/article/vintage_rollrate_fpd.html 确定目标变量# 根据催回率及迁徙率确定好坏客户（不过一般还是用滚动率比较多） 由上表可以看出，M2以上的迁徙率将近90%，所以确定当前逾期31天以上为区分好坏客户的标准，及后续分析的目标变量。 制定风控审批策略# 如以城市等级为例，城市等级与逾期的关系：城市等级越低，其对应的逾期率越高。 策略预估# 预估策略上线对生产运营阶段的影响，基于进件量、放款量、通过率的影响。 策略监控# 策略上线后，监控此策略的占比与预计的占比是否发生严重偏差，且在正常运行阶段是否全部执行。 策略回顾# 对上线后的策略，在一定时间后。对于有表现的数据进行策略回顾，看策略调整后的进件量、通过率及贷后表现。若是想及时的查看策略上线后的贷后表现可以针对FPD指标分不同的天数去观测，FPD4，FPD10，FPD30等。 若策略是调宽或者是放松时，可以针对性回顾下豁免出来的客户的进件情况、通过率及贷后表现。 若策略是调严或者收紧时，可以针对性回顾拒绝阈值边缘维度的贷后表现及拟定拒绝的客户数。 风控策略分析师# 风控策略分析师是完成上述P1部分所有分析，构架风控策略的人员。 日常工作内容# 贷前、贷中及贷后各环节的风险策略与流程，制订各项策略规则，具体包括准入、授信、定价、用信、还款、调额等信贷流程各阶段的策略规则 通过对各类风险指标与报表的分析，关注各类资产和客群的风险变动，对公司全渠道风险政策与策略进行跟踪评价，并及时优化调整相应的风险政策与策略 必备技能# 结合内外数据，通过统计分析方法，对不同风险点制定出不同类型的风险规则 完成整个贷前、贷中和贷后的风险规则架构，实现自动化风控 可以实现策略规则优化，不限于A、D类调优方法 规则的部署与监控预警 临时指标调整的项目经验 核心作用# 实现具体规则和流程的设计、开发、部署、监控与优化 策略分析常见工作场景与对应分析方法# 三方数据测评# 案例：现有1000个样本数据，分别测试2家黑名单，2家欺诈名单与2家多头，如何选择合适的第三方数据源？ 首先要专业科普选择第三方数据源重要考察的5大指标计算公式（以黑名单为例）： 查得率(Search rate)=查得数/样本量 覆盖率(Cover rate)=查得命中黑名单数/样本中命中黑名单量 误拒率(Error reject rate)=查得命中黑名单数/样本中通过且为Good量 有效差异率(Effective difference rate)=查得命中黑名单数/样本中通过且Bad量 无效差异率(Invalid difference rate)=查得命中黑名单数/样本中其他拒绝量 其中SR、CR、EDR指标越高越好，ERR越低越好，IDR与EDR结合起来观察，如果IDR和EDR都较高，反应的一种情况是数据源定义黑名单是广撒网式，黑名单质量相对不够精准。 其中前三个指标是重点考察，如果想更全面的测试第三方数据源，后面两个差异率指标也可以加入考核标准。 举例—黑名单数据评测# 1000个测试样本数据中，审批结果字段表示样本通过和拒绝，其中通过样本中有未逾期和发生逾期的客户样本，拒绝样本中有通过黑名单库拒绝客户，也有其他原因产生拒绝。比如，数据源1（黑名单）代表一家提供黑名单数据的数据供应商A，数据源2（黑名单）代表另一家提供黑名单数据的数据供应商B，以此类推。 对1000条测试数据返回结果进行整理可以总结出如上数据概要，对比看到数据源1的返回结果如下： 按照文章开始介绍的指标分析方法，对比数据源1和数据源2的测试结果可以得出如下结论： 数据供应商1的查得率、覆盖率高于数据供应商2大约5%、4%； 数据供应商1的误拒率低于数据供应商2大约0.3%； 数据供应商1的有效差异率低于数据供应商2大约8%，无效差异率低于数据供应商2大约7%； 依据五大指标分析标准，SR、CR、EDR指标越高越好，ERR越低越好，IDR与EDR结合起来观察，如果IDR和EDR都较高，反应的一种情况是数据源定义黑名单是广撒网式，黑名单质量相对不够精准！ 最终分析结论： 数据供应商2虽然覆盖的黑名单比数据供应商1的更广，但其不如数据供应商1精准，更偏向选择数据供应商1的黑名单数据。 准入策略的制定# 风控准入策略作为金融借贷机构评估一个借款人是否有机会获得授信的第一道门槛，是保卫金融机构的第一道护卫。 风控准入策略属于贷前风控策略体系的一部分，贷前风控策略包括基础认证、准入策略，贷前反欺诈策略，黑名单策略，特殊名单策略及信用风险策略。风控准入策略中的规则更多是由产品政策性规则构成。 针对不同信贷场景采取更适应业务的准入规则，设定科学的准入策略，对于风险的防范与降维有十分重要意义。合理的风险准入策略，也能对信贷业务的走向与风险倾向产生直接影响，进一步影响金融机构的最终盈亏。 为什么要设计风控准入策略 风控准入策略的规则属性全部为强拒绝规则（硬规则），借款人一旦不满足一条准入规则金融贷款机构都不会给予贷款的授信与发放；同时，风控准入规则不需要经过复杂的规则衍生，通常可以简单有效的判决借款人是否有资格进入之后的风控流程；最后，风控准入规则的策略理念是验证借款人依法合规未被政策限制。 风控准入策略模块 风控基础认证模块: 基础认证模块主要作用是验证借款此人是本人，也是以风控规则形式出现，规则大多为公允共认的规则。比如身份证信息验证，人脸信息验证、银行卡四要素验证、运营商三要素验证等。 在验证完借款人基础信息后，风控贷前流程才会进入准入策略模块。 准入策略模块主要分为年龄准入、地区准入、行业准入及其他。这些准入规则的根本设定原则是基于监管和金融机构产品政策性导向。 年龄准入策略# 对于年龄准入而言，中国银行业监督管理委员会令《个人贷款管理暂行办法》中指出个人贷款申请应具备以下条件： （一）借款人为具有完全民事行为能力的中华人民共和国公民或符合国家有关规定的境外自然人； （二）贷款用途明确合法； （三）贷款申请数额、期限和币种合理； （四）借款人具备还款意愿和还款能力； （五）借款人信用状况良好，无重大不良信用记录； （六）贷款人要求的其他条件。 其中借款人具有完全民事行为能力的中华人民共和国公民年龄范围在18-60岁。所以合规的金融机构信贷产品的借款人年龄准入策略中，年龄规则的设定是：年龄&gt;X &amp; 年龄&lt;X ，X属于18-60。有些贷款产品，则是根据贷款人的性别不同来限制年龄的。比如对于女性申请人的年龄限制是22周岁以上，而男性申请人的年龄限制为20周岁。 地区准入策略# 一般金融机构会按照风险热力地图将一些重灾风险区进行隔离或者进行“象征性”政策贷款发放。 地区准入规则的初始设定一般是风险集中度比较高、社会稳定性比较弱、地区经济GDP比较低，亦或是难催收的地区，比如新疆、东北等个别地域。 在之后随着信贷业务的开展，也会根据贷款回收率对地区准入规则进行一些策略调整，比如一些地区的贷款回收率长期观测较低，金融机构企业内部信贷战略调整后，可以将这些地区加入限制性地区里。 上图事例1中展示的是M1阶段的回收率热力分布地图，可以发现灰色区域的M1贷款回收率低于60%。如果需要进行地区准入策略的调整，还可以将M1回收率0-60%的区间划分的更细，比如0-15%的M1回收率，也可以将省维度拆成市级维度进行限制。 此处需要提醒，一旦加入到地区准入规则后的地域在之后将无法进行信贷业务，同时也会失去观测业务数据，所以此类的策略调整要谨慎设计。 地区准入策略的常用规则如户籍地址 in（x,x,x），单位地址 in （x,x,x）,家庭地址 in （x,x,x）等。 行业准入策略 行业准入策略的基础原则是对一些行业工作不稳定或无业的借款人禁止提供信贷业务。如禁止： 金融属性行业如投资、担保、理财、典当；政策性敏感娱乐行业如KTV、按摩院、会所等；无业和自由职业、学生、媒体工作者，检察院。 白名单策略# 白名以下两种业务场景： A.在存在自有存量数据的前提下，金融机构想开展信贷业务，前期需要通过白名单控制入口，此类场景多存在于业务初期，或者是内部员工贷的业务场景。(风控模型不完善的条件下，先把业务开展起来。同时，在这个展业的过程中，可以逐渐组建适合金融机构业务的风控策略和模型。) B.在业务开展中期，需要部分进件客户走特殊贷前审批流程，满足特殊审批的要求，此类场景多存在于较大的金融公司。(有着较好的信用、较好的资产亦或是较好的“背景”，通过一些特殊审批流程进行贷款的审核，最终满足“VIP”的借贷需求。) 综合来讲，白名单可以定义为，通过金融机构内部现有数据判断的“好客户”，或者经过一系列规则挖掘分析得出的“好客户”，由他们组成的借贷优质名单。 如何筛选出白名单 联合建模： 金融机构在有存量数据的前提下，自有数据是不缺乏X特征变量，主要缺乏相应业务场景有表现特征的目标Y变量。在这个时候可以通过引进一些外部机构进行联合建模，用以补充一些Y变量。 通过与外部机构联合建模得出评分，不论是将其用于内部客户分层，还是将评分分数直接做规则，都对筛选白名单有很好的帮助。 内部数据探索： 我们在筛选白名单的时候，除了通过联合建模弥补相应业务场景下目标变量的缺失，还可以通过内部数据探索，寻找分析一些对逾期违约表现相关性较强的一些特征规则，逐渐设定出白名单规则。这里面分为两种规则设定方式。 第一种是寻找与新开展业务相似模式和场景的已有产品，参照已有产品的风控策略规则对新业务场景数据进行比对分析，参照已有产品的策略规则制定出新业务场景的风控白名单规则。 另外一种方式是在更“艰苦”的环境下，没有任何可对比参照的已有产品，这个时候设定的白名单规则相对更严谨，同时对风控策略工作者的业务经验要求更高，可以认为是一种专家经验规则。 引入外部数据匹配： 工作单位、学历、社保缴费单位、公积金缴费单位、缴费基数等信息去筛选优质客户。 白名单的作用： 控制放量节奏：初期的时候用于控制节奏，整体调控。 降低风险 提高过审率 协助调整贷前策略：白名单筛选的过程就是贷前策略的一部分。 黑名单策略# 黑名单：性质极其恶劣的坏客户。无论是其还款能力，还款意愿，借款目的等都不能满足正常客户的标准。 有自建和外部引用两种。对于业务初期的金融机构通常调用三方数据接口查询行内黑名单客户，同时在自家展业过程中，通过贷后管理逐渐补充、完善自家黑名单库。 黑名单的使用：# 一般来说金融机构一旦触碰到黑名单规则，金融机构通常会全部拒绝。（全部拒绝黑名单前，会随机放过5%或者10%的触碰黑名单的客户，去测试黑名单数据有“多黑”，测试该黑名单客群是否适用于该机构。） 导流助贷机构可能会选择性放入一部分客群，结合客户评分，多头等数据综合判断，或者随机放过。（反正不是他兜底） 敞口测算# 假设一个场景：如果有一万块钱，借款一年，不考虑其他，综合年化36%的信贷产品，因为一个黑名单客户导致本金全部损失，那么实际上需要大约3个好客户才能弥补1个坏客户的损失。 如果我们加上资金的运营成本，人力成本，引流成本，实际成本等。 假设需要的综合年化是15%，那么实际上 ，也就是5个好客户才能覆盖一个坏客户的本金损失，同时还需要覆盖上述的各种成本 ，也就是说金融机构大约要用6个完全的好人才能替代一个完整的坏人。 如果是3期、6期产品，同时也包含资金占有率问题，实际上需要的用更多的好人去覆盖坏客户带来的损失。 假设5000 6期 36%，每个好人收益是5000×0.36/2 = 900，不算其他成本也需要5.5个人才能cover一个欺诈。（此时坏账率：1/6.5=15.4%） 实际同上假设人力、引流、IT，使得实际年华15%，每个好人收益是5000×0.15/2 = 375，需要13.3人才能cover。（坏账率1/14.3=6.99%） PS：助贷导流客户平均成本一般不会超过5毛钱，金融机构开展信贷业务所需风控数据成本也不会超过10元。 所以黑名单很重要，坏账很难搞。。。 自建黑名单# 黑名单一般的自建维度有参照回款表现、渠道、利率、各种公布失信类客户以及通过爬虫获得的一系列坏客户，黑名单的设定不一定仅限客户本身，也可以拓展为身份证、手机号、邮箱、银行卡、ip地址等，都可作为自建黑名单的参考维度。 和通讯记录、电话簿、二度通讯记录等联系起来。 自建黑名单命中率通常不会太高（相同客户再次注册的概率较低），且自建黑名单库需要长期的业务积累过程，因此金融信贷机构常常需要借助三方金融科技公司的黑名单库服务（特指三方数据供应商商以及其他金融信贷机构）。 大量p2p以及小贷机构接入百行征信，但我想要说明的是：滞后性和成本的增加使得黑名单需要更多的共享，只有共享才能更全面了解我们金融机构所接触的客群。 规则阈值cutoff如何设定# 风险策略拒绝线的设定，背后有严谨的分析逻辑，本文就以评分分数区间和年龄规则为例，为大家讲解审批策略拒绝线的内在分析方法。 背景# 评分模型，尤其是主流基于线性Logistic算法的评分模型，对于一些边际评分区间的风险，其实常常无法精准的预估到，势必会造成一些区间风险被低估的现象。如果不通过一些规则维度的拒绝补充，容易因为模型风险发生不必要的利益损失。 假设我们已经对评分模型分数分为T1-T5组，T1风险最低T5风险最大。年龄规则也使用单变量树模型初步分为5组区间。我们希望结合评分分数找到年龄规则这个核心策略维度的合理拒绝线。 第一步：通过评分找到风险被低估的区间# 本例中，首先将年龄与评分卡进行交叉矩阵分析，观测不同交叉区间里的用户违约概率。 一般策略规则多数组之间的趋势线是紧密相近的。从图示数据走线可以发现，年龄组[35,47)和[47,53)这两个年龄组的违约概率走线脱离了其他分组，尤其是年龄组[35,47)，其走线脱离其他“群体”过多。通过分析初步定位年龄组[35,47)和[47,53)可以是待确定的规则拒绝线。 第二步，评估拟拒绝人群的收益/风险比# 虽然经过评分与年龄的交叉对比，发现年龄规则的两个待确定高风险拒绝区间。但是实际拒绝线的划分要结合年龄分组区间人群的实际收益与风险进一步考虑。如果高风险的人群可以带来高收益，对于策略来讲也是可以接受的。 将年龄分组区间按照上图示例2横轴所示指标进行统计，假设年龄分组[35,47)的收益/风险大于[47,53)且为正，即表明虽然[35,47)年龄分组的人群违约率最高，但其收益同样也是最大。反而[47,53)年龄区间的人群为公司带来负收益。 本着收益覆盖风险的商业理念，此时对于年龄这一维度的策略最佳拒绝线，应该划分在[47,53)这一分组区间。 通过率下降的策略调整# 审批通过率和不良率是一对权衡指标，在新业务上线初期，维持一个较低的通过率可以保证最好的客群进去。随着业务规模做大和风控样本积累，此时需要在风险容忍度可接受范围内提升通过率，以保持收益的最大化。 如果某一天风控通过率忽然降低，这种情况下策略分析人员应该如何应对？ 1.寻找通过率下降的时间点或时间段# 在风控策略稳定之后，审批通过率一般稳定在某一小范围内波动，当监控每日通过率指标时发现，T-1、T-2时点的通过率明显下降，我们应该先通过监控报表迅速定位到具体时间点或时间段。 2019.6.23和6.24授信通过率下降。 Tip：上图示例通过率下降到6.9%、7.0%可以直接用肉眼分辨数据，但实际业务一般建议以通过率趋势图和PSI指标监控通过率下降。 2.判断策略节点主次要拒绝影响# 发现通过率下降的时间点或时间段之后，下一步先聚焦到策略节点。本文为FALers举例两个策略节点A（准入）和B（规则）。以6月23日为时间节点划分，对比数据分析，寻找拒绝率的波动差。 上图示例2中波动差按照B段A节点拒绝率-A段A节点拒绝率计算出来，以此类推。此时计算波动差仍然可以考虑加入PSI=(B-A)*LN(B/A)测算波动差,A节点的PSI为0.77%，B节点的PSI为0.01%。 按照波动差确定通过率的下降主要因为A节点的拒绝率上升引起，从而将通过率下降的影响因素从策略A和B两个节点问题进一步聚焦到A节点上。 3.从节点聚焦到节点规则层深度分析# 完成节点的聚焦分析，定位到引起通过率下降的主要原因节点A，接下来需要进一步分析节点A内包含的所有规则拒绝情况。 与节点聚焦分析一致，寻找引起拒绝率上升的主次要拒绝规则。在规则层确定主次要影响因子时，分析方法不仅结合数据同时也参考业务场景。 从上图示例4可以发现，按照波动差分析得出年龄准入拒绝和X3_准入拒绝是主要引起通过率下降的规则。 4.具体规则分布分析# 从步骤3确定出年龄准入拒绝是第一位引起通过率下降的规则后，第四步就从规则层聚焦到具体策略规则的分布上。 通过分析具体策略规则分布的波动差定位具体策略规则的某一分布，找出引起通过率下降的主要策略分布。 从上图示例6可以发现，年龄准入拒绝这一策略规则中，18-25岁的分布拒绝率在时间A段和时间B段的波动差最大，这个年龄分布的拒绝率上升可能是引起整个审批通过率下降的主要规则分布。 造成以上18-25岁年龄分布拒绝增加的原因，很常见的一种是进件客群发生了变化，针对客群发生突然变化的情况，如何将分析结果指导决策执行，是策略分析最后且最重要的一步。 5.分析指导决策# 仍以上述案例为例，通过一系列聚焦分析发现，18-25岁的进件客群变化是引起整体通过率下降的核心因素。实际业务场景中，并不会因为此时通过率突降就进行策略规则的调整，更多的是通过聚焦分析后，结果进一步细分两个参照要素：进件渠道的进件量分布和最大进件渠道的年龄准入拒绝分布。 5.1.进件渠道分布分析 既然是客群的变化引起了整体审批通过率的下降，从进件的所有渠道数据中进行分布排序，定位到渠道进件量A段和B段都最大的一个进件渠道C。 5.2.最大进件渠道的年龄准入拒绝分布 通过进件渠道进件量分析，从众多进件渠道中定位到最大进件渠道C。此时分析主要拒绝规则-年龄准入拒绝的渠道C的分布情况，是否满足条件：B段与A段年龄18-25岁的波动变高。 从上图示例8中分析发现，渠道C年龄在18-25岁的客群进件量在B段比A段上升明显，即从渠道进件前段业务确定出引起通过率降低的主要进件渠道C。至此，可以进行策略分析决策建议。 5.3.决策建议 将策略分析结果应用于前段业务指导和决策，提醒前端业务人员在渠道C可以适当缩紧18-25岁客群的进件需求，以此共同维护金融公司整体风控通过率，这才是风控策略分析工作者最终的使命和义务。 逾期率上升的策略调整# 当逾期升高时，如何进行策略调优。 真实案例背景（数据已脱敏）： 通过PQR监控报表发现，某XX贷产品的MOB报表自2019年5月开始，后续放款月资产逾期呈上升趋势，既DPD30+逐月上升，且上升速度逐步增快（MOB期数逐渐缩短）。在2019年11月放款的客户里，MOB=4的DPD30+等于2.49%。如下图1所示。 通过将MOB制作成Vintage报表，可以观测到某XX贷产品的风险自2019年5月到11月的DPD30+平均值位于6%的水平，如下图2所示。 往期DPD30+表现出的风险水平逐月快速上升现象，意味着如果不做相应的策略调整，之后的放款月风险将会更快的暴露。 针对此时逾期快速上升的背景下，如何分析策略，进行策略调整呢？ 策略分析方法 第一步：确定存量还是新增客户导致逾期上升# 信贷业务每个月发生授信和放款的客户可以分成新增客户和存量客户。从上图示例2中Vintage报表展现的数据，反映出资产逾期呈上升趋势。那我们首先需要将2019年5月到2019年11月（可观测到DPD30+）的Vintage分成新增客户的Vintage1和存量客户的Vintage2，如下图3。 从上图3的Vintage1（新客户）和Vintage2（存量客户）标注的红色椭圆框可以观测到，新客户的DPD30+平均处于6%，存量客户的DPD30+平均处于5%。与图示1对比可以分析出，导致资产逾期上升的主要原因是新增客户资产变差的影响。 至此阶段的分析结论：我们可以确定出需要调整的策略规则是贷前规则。 解释如下：往期放款月中，新客户是由贷前规则通过后，给予授信并放款的，存量客户的复借是由贷中规则决定。通过Vintage1和2的分析比对，引起资产逾期上升的主要原因是新客户的逾期上升。 第二步：多维度分析，找出最主要影响规则# 通过第一步的分析确定出核心要调整的是贷前策略后，我们接下来要通过分析不同的规则变量，找出对目标变量（DPD30+）影响最大的维度变量。 这里提供分析主要影响变量的两个思路，具体实践过程就不在这里多讲，文末推荐阅读有链接。 思路一：自上而下地按照A类策略调优方法，从贷前策略节点到节点里的规则集，再细分到具体规则，逐步分析出影响较大的规则变量（文末推荐阅读给出具体分析的往期文链接） 思路二：自下而上地将所有规则变量与目标变量拟合分析，通过IV的降序排序，找出影响较大的规则变量。 分析得出，城市等级是影响逾期目标上升的主要变量。通过分析2019年5月至11月的城市等级Vintage曲线，可以发现“其他城市”较“一线城市”、“二线城市”、“三线城市“对逾期的影响较大，如下图。 第三步：制定策略调整方案# 通过上述数据分析，发现贷前风控规则里的“城市等级”规则”其他城市“是导致逾期升高的主要原因。此时容易出现的一个错误决策是拒绝“其他城市”的进件。 原因很简单：这种决策会导致大量的申请被拒绝，对通过率的影响比较大。 最优的策略调整方案思路是：从“坏客户”中挑选出“最坏”的一批客户，且这批客户的占比较少，然后加以拒绝。 按照上述思路，我们可以制定出如下的策略优化方案： 1、进一步分析“其他城市”里，哪一些的城市逾期较高； 2、挑选部分逾期较高的城市做贷前准入规则。 以上，就是逾期升高情况下，策略调优的分析方法。 信用多头策略# 金融风险管理中，对于一个借款人还款能力的评估十分重视。如果一个人的资产负债比过大，一旦发生资不抵债的现象，金融机构继续对其发放贷款发生违约的风险是极大的。 在体现借款人甚至借款企业还款能力的众多指标中，多头借贷是一项核心指标。 1.什么是多头借贷# 多头借贷是指单个借款人向2家或2家以上的金融机构提出借贷需求的行为。多头借贷数据一般至少会粗分成银行类多头借贷、非银类多头借贷。按时间跨度可以分为近7天、近15天、近1个月、近3个月、近6个月、近12个月。 多头借贷除了会统计申请次数，还会统计申请机构数、申请最大间隔天数、申请最小间隔天数、申请记录月份、平均每月申请次数(有申请月份平均)、最大月申请次数、最小月申请次数等。 由于单个用户的偿还能力是有限的，向多方借贷必然蕴含着较高的风险。一般来说，当借贷人出现了多头借贷的情况，说明该借贷人资金出现了较大困难，有理由怀疑其还款能力。 2.多头借贷数据的分析方法# 由于多头借贷可以比较有效的反应借款人的还款能力，所以在对借款人信用风险、欺诈风险评估上，基本都有使用多头借贷数据。 多头借贷作为一个衡量借款人的维度特征，可以结合一些逾期指标进行分析。 上图示例1中，对近7天非银机构申请机构平台数进行分析，对申请不同平台数的客户，分别统计客群的分布占比、FPD30%、FPD30-DPD90+%、通过单量、FPD30单量、DPD90+单量以及DPD90+%。通过统计后的数据，分析近7天申请N平台数的客户，其不同逾期指标的变化趋势，如上图示例1中FPD30%的增幅，进一步用于寻找策略切点或者豁免客群的回顾分析。 3.多头借贷数据为何少用于模型# 多头借贷少出现在模型变量中，主要有两个方面原因。 第一，多头借贷数据往往被策略同事应用于规则中。 数据建模的目的是从金融弱变量中通过特征工程方法，提炼出有效区分变量，构建评分模型。所以对于多头借贷数据，既然已经运用在策略规则中，实在没必要加入到模型变量。如果读者朋友们看到提交的评分模型报告中有多头借贷变量，那么建模的同事要么没有事先了解已上线运行的策略规则集，要么就是为了模型表现指标（如KS、AR、AUC）好看强行使用。 第二，多头借贷数据往往覆盖度不全。 多头借贷虽然是一个与风险强关联的维度，但其查得率一直被人所诟病。 举一个例子，借款人一个月内在多家机构贷款，作为一个特征，很有可能出现某个人虽然频繁贷款，但并没有被多头供应商捕捉到。一旦这个特征作为模型变量，那么这个变量的噪声就很大了。反而如果做成反欺诈策略，就不需要担心噪声问题，直接选取拒绝线进行截断，最大的影响，也就是没有拒绝掉足够多的用户，而这个影响我们还可以用噪声较小的模型进行弥补。 4.多头借贷数据在策略规则上的应用# 多头借贷在策略上一般作为一条策略规则，一个拒绝维度参与到整个风控流程中。不同机构，不同信贷产品，不同场景，对于多头借贷的拒绝线划分都是不一样的。如何找到当下最适合的多头借贷拒绝线，对于风控策略分析人员，是风控工作的核心任务。 仍以上图示例1为例，假设当前对于7天多平台数规则的拒绝线划分在6，即如果7天多平台数&gt;=7则拒绝。如果我们现在希望通过7天多平台数规则豁免一部分客群提升整体通过率，此时的拒绝线cutoff应该划分在哪里呢？ 如果不是应对紧急调整通过率的情况，我们可以事先豁免7天多平台数7-10的客户，作为测试样本，用以产生7-10客群通过单量的分布，之后将拒绝线调回6。既可以生成如下统计分析表： 上图示例2中的桔色部分都是通过分析预测出来，比如通过上图示例1中不同多平台数FPD30%的平均增幅0.7%，预测出7-10的FPD30%。 预估计算公式8FPD30%=7FPD30%+0.7%。进一步计算出FPD30量、DPD90量等其他指标。 提醒读者朋友们，因为我们对于资产风险管控最关心的逾期指标还是不良率，所以我们通过FPD30-DPD90+%的迁徙率预测出不同7天多平台数的DPD90+%。对于7-10的FPD30-DPD90+%预估，可以采用MAX(0-6的FPD30-DPD90+%)的预估方法。 在这之后，我们对于不同7天多平台数测算出拒绝线Cutoff的FPD%和DPD%，如下图所示： 对比示例图1和图3的Cutoff_DPD%可以发现，规则拒绝线设定在&gt;=7时DPD%=3.0%，设定在&gt;=8时DPD%=3.0%，设定在&gt;=9时DPD%=3.3%。规则拒绝线设定在&gt;=8的DPD%并没有增加。此时可以尝试建议将7天多平台数的拒绝线调整到7。 当然，这种策略分析方法仍有一些纰漏，比如此方法需要有测试样本进行观测，无法满足快速调整通过率的需求；7天多平台数的FPD30%的增幅实际情况并非线性增长，有经验的策略分析师知道，FPD30%一定会在某一个节点指数级增长。 但正是因为策略分析师通过不断地按照上述方法进行样本测试对照，根据实际情况回顾分析结果，才能不断的积累策略调整经验，才会对规则分布具有一定敏感性。 评分的策略应用# 评分卡模型的运用，主要是为了解决两大问题：# 1、线上借贷业务量逐渐增加的情景下，策略规则已经无法满足更细的切分需求； 2、对于策略无法有效识别的大量灰色客群，需要使用评分卡进行风险判断； 现如今业界使用评分卡模型，更多的是为了解决第二个问题。 从金融机构自身业务发展历程来看，评分卡模型介入风险管理流程常常取决于两个重要的时机： 1、业务快速发展阶段 在金融机构业务发展的早期阶段，因为业务量小、样本少、风险控制严格等一些主客观原因，使用风控策略规则足以开展业务，所以在业务发展早期评分模型基本没有任何用武之地。 但随着信贷产品的测试期结束，金融机构要加快业务发展，此时不论是大量的客群样本、逾期表现的积累，还是风险控制的政策放松，都因为风险策略无法精准细分的局限性，而需要评分模型的介入，评分卡的应用场景更适用于人工分流。 此阶段的评分模型，常常表现不稳定，比如KS波动较大，Lift下降较快，PSI时常过0.1。此阶段评分模型的优化更多在于分析波动原因，快速重新开发迭代。 2、业务发展稳定阶段 一旦金融机构度过了新产品的早期和发展期，此时产品市场表现已经趋向稳定，反应在客群分析上，表现出稳定层级的客户画像，此阶段是评分模型介入2.0阶段。 在这个阶段评分模型会在风控流程节点上进行一些调整，比如申请卡模型会进一步的前置，担当部分客群豁免的功能。同时，此时评分模型介入2.0阶段也会降低一些外部征信数据调用成本，控制因三方数据有误而引起的误杀。 此阶段的评分模型，表现较为稳定，KS、Lift、PSI等指标波动较小，对于评分卡的迭代开发需求降低，评分卡的应用更加与业务需求、金融政策以及企业发展战略相关，在保证评分模型稳定性及相对精准度的前提下，使用模型调整系数进行全局模型的调整是此阶段的主要优化办法。 评分模型的cutoff# 评分卡分数转换出来，在不同业务发展阶段如何合理的制定评分的cutoff，是评分应用重要的一步。 一般将评分等分后，会有两种方式对评分进行cutoff：一种是参照KS和Cum % bad rate,另一种根据等分后的累计净收益。 第一种参照Max KS和累积bad rate理论上是可以尽可能的将坏客户剔除，对好客群进行授信，但无法根据业务发展需要保证收益最大化。参照不同业务发展阶段的需求，根据评分对收益损失预估，最终确定评分cutoff，我认为这才是精细化的评分应用策略。 第二种制定评分的cutoff，需要联动分析以下图示的一些指标 通过逆向累计净收入指标的分析，结合当下风控政策，综合评定评分的cutoff，将之应用在风控策略上，这样才是更接近业务的评分cutoff。 模型与策略的关系# 评分模型在金融信贷风控领域的应用非常广泛，模型的开发、监控也趋于标准化。 评分模型可以为每一位观测对象打出一个评分分数，理论上实现风险与定价的绝对对等，实现个体差异化的风险管理，在这点上，风险策略规则是远不可及的。 模型是否可以替代所有的策略规则?# 此时就有了风险策略与模型之间的争议：模型是否可以替代所有的策略规则？（排除政策准入规则） 想要回答上述的争议，首先需要了解目前策略规则与模型在风控决策体系里的应用架构。目前我所见到有两种主流的风控决策应用架构：策略规则+评分模型 &amp; 策略规则+模型规则。 策略规则+评分模型# 前者策略规则和评分模型是分开的，一般风控流程是先进行策略规则的风险判断，再进入评分模型的风险识别； 策略规则+模型规则# 后者是将评分模型的预测概率（或分数）转变为一个策略规则，与其他策略规则融合在一起进行风险决策。 策略规则的粗放式管理# 策略规则作为一种风险识别的方法，其自身具有直观、易用等特性。对于新产品上线前的风险决策，因为没有数据样本的原因，策略规则在风险决策初期起到不可替代作用。但也因为策略规则的设定原理，其自身很难做到风险决策的精细化管理。 以上图风险决策B为例，可以看出策略规则都是XXXX&gt;xxx，这种单维度的风险判断是存在一定的取舍。比如某金融机构的一条多头借贷策略规则设定为：多头借贷平台数&gt;5则执行拒绝，那多头借贷=6的申请客户，就一定会违约吗？ 说到这里可能会有读者朋友质疑：我可以设定一些策略规则组合起来判断。没错，这也是风险决策体系下策略规则应用的一种方式，但不论多少维度的组合判断，都必然会对单一维度策略规则进行True or False判断。比如上例中的策略规则变为：多头借贷&gt;5 或 多头借贷&gt;6且性别为男性，则执行拒绝。此时对于多头借贷=6的女性不会拒绝，但对于多头借贷=7且有一定储蓄的男性，就一定会违约吗？ 可以看出，如果希望通过策略规则的组合实现精细化的风险管理，就会不断地增加策略规则，最终导致策略规则的复杂和冗余，对于策略优化、回顾并没有正向的影响，这与策略规则的易用、直观等特性产生了矛盾。 评分模型的常见三种盲区# 由于策略规则的先天性缺陷，评分模型的出现可以恰当的弥补策略规则的不足，但并不意味着评分模型可以完全替代所有的策略规则。其原因有风控流程的考虑、业务发展的考虑等，在本文我为大家从模型自身的盲区为大家作解释。 建模数据集与实际贷款人之间存在偏差# 在中国因为征信体系的不完善，金融机构的模型一般以实际贷款人作为模型数据集，而申请人母集到贷款人子集往往发生较大变化（就算是大家熟知的拒绝推断也只能尽量弥补但不能完全拒绝这方面的误差），模型的判断就会出现一些偏差，此时需要根据策略维度的一些拒绝线，对模型进行一些矫正和保护。 模型数据集来自历史，与未来实际情况存在偏差# 模型是基于历史数据找到数据之间的逻辑规律后，对未来事件进行预测。对于具有周期性的金融行业，如果用处于上升期的数据模型预测金融衰退期的事件，必然会与实际情况发生偏差。 举个例子，比如在经济上升或者繁荣期，消费者不仅有工作的单一收入，消费者可以从一些兼职等渠道获取额外的收入来源，此时即使有较高负债收入比的客群仍然可以维持较好的信用表现；但当经济开始进入下滑时期，未来消费者很难继续从其他渠道获取资金，即使历史数据告诉模型、模型告诉决策人，此时的借贷申请人有还款能力和意愿，但商业风险决策者应考虑收紧对于较高负债收入比人群的贷款。 模型对于目标变量的界定与实际商业目标存在偏差# 模型为了权衡观察期的代表性和表现期的时效性，在建模时为了囊括最近的贷款数据，在界定“坏账”定义时，仅考虑前12个月的还款表现（有时仅考虑前6个月），此时对于一些中额长期的信贷产品（比如24个月、36个月），模型目标变量的界定与实际商业目标就发生了偏差。 综上，从反面辩证性的角度分析模型与策略，二者缺一不可，谁也不可能完全替代对方。通过科学地搭配，共同构架起严谨的风险决策体系。","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/tags/risk/"},{"name":"strategy","slug":"strategy","permalink":"https://blog.sofunnyai.com/tags/strategy/"}]},{"title":"互联网金融资产质量评估指标---fpd、vintage、rollrate和迁移率等等","slug":"vintage-rollrate","date":"2020-03-21T17:25:33.000Z","updated":"2020-05-25T06:57:03.990Z","comments":true,"path":"article/vintage_rollrate_fpd.html","link":"","permalink":"https://blog.sofunnyai.com/article/vintage_rollrate_fpd.html","excerpt":"","text":"目录# 概述 基础概念 风险分析有常见的5要素： 其他的相关概念 延滞率 即期指标（coincidental）： 递延指标（lagged）： 账龄(Month of Book，MOB) FPD 首逾率（反欺诈相关） 入催率 逾期时间 vintage 成熟期 观察点与表现期： vintage举例 roll rate滚动率 滚动率定义—状态变化 如何确定bad和good标签的账龄 vintage和roll rate的区别： roll rate已经确定了bad为什么还需要通过Vintage分析来确定表现期？ Vintage里所有的账户，我们的目的是抓住尽可能多的坏客户。 Flow Rate迁移率 坏账准备金 坏账准备金的概念----各期逾期余额乘以各自准备金率 准备金比例 资产组合管理相关 参考文章链接： 概述# 想写一个vintage和roll rate的文章，查到求是汪大佬写的非常详细，图文并茂。直接偷懒摘录了一个脱水版，想看原文的在这里。下面开始干货。 本文主要讲述账龄vantage、滚动率roll rate、迁移率flow rate三个指标的关系。 账龄分析（Vintage Analysis）：用以分析账户成熟期、变化规律等。 滚动率分析（Roll Rate Analysis）：用以定义账户好坏程度。 迁移率分析（Flow Rate Analysis）：用以分析不同逾期状态之间的转化率。 基础概念# 风险分析有常见的5要素：# 下单月： 观察月： 放款额（GMV）：就是零售业说的“流水”，成交总额包括销售额、取消订单金额、拒收订单 金额和退货订单金额。 在贷余额（Balance）/ ENR：至某时点借款人尚未偿还的本金 逾期天数（DPD） 其他的相关概念# C,M1,M2,M3…的贷款余额：根据逾期期数(C,M1,M2,M3…)，计算每条借款的当时的贷款余额。（贷款余额 = 放款时合同额 –已还本金） 核销金额: 贷款逾期M7+（坏账）后经审核进行销帐，核销金额即在核销日期当天的贷款余额。 回收金额 Recovery：来自历史所有已核销合同的全部实收金额。（核销后又回收的部分） 净坏账 NCL：当月新增核销金额 – 当月回收金额（坏账减去回收） 延滞率# 延滞率（delinquent%）的计算可分为coincidental以及lagged两种方式，除了各bucket延滞率之外，也会观察特定bucket以上的延滞率，如M2+lagged%以及M4+lagged%等指标，以M2+lagged%为例，分母为两个月前应收账款，分子为本月M2（含）以上尚未转呆账的逾期金额。 在消费金融风险管理上，M2以及M4为两个重要的观测点，原因是客户可能因为一时忙碌或疏忽造成账款逾期，但若经过M1催收仍旧落入M2以上，几乎可以确认为无力缴款或者蓄意拖欠。另外依据经验，客户一旦落入M4，事后转呆账几率非常高。 下面部分来自知乎京东白条的回复： 逾期率有两种方法：即期逾期率指标Coin(X)%和递延逾期率指标Lagged(X)% 这个指标分子 = 时点逾期余额，分母 = 时点透支余额。逾期率最直观，但也最容易被“操控”： 分子会受到统计粒度的影响（以客户/账户/贷款单/贷款分期单哪个粒度来计算差异很大，尤其是偏重分期的产品），也会受到核销等资产处置的影响（是否有核销处理、统计时是否包含）。 分母会受到当期时点规模的影响，季末/年末冲量或特殊的营销时点上，都会导致规模的激增，人为拉低时点的逾期率。 在产品高速发展时期，规模增长迅速，而风险滞后释放，导致对风险的低估和滞后判断；而在产品成熟和衰退期，导致对风险的高估，容易误导风险策略的制定。 由于上述原因的存在，一般逾期率只能说明累积的整体风险水平如何。如果根据时点的不良率判断近期风险水平，存在高估/低估的可能。-------------逾期率只能是整体一个粗略的观察，具体来说逾期的结构更重要。 如果一定要用时点余额来判断近期的风险，建议使用延滞率或逾期的净生成率： Mi延滞率=当期Mi/i月前的M0 Mi净生成率=(当期Mi-i月前的Mi)/i月前的透支余额 这两个指标至少能在一定程度上排除当期时点规模、历史存量的影响，能更真实反映近期的风险水平。 新增客户/资产的风险水平如何？# 整体的逾期率并不一定能回答或甄别近期客户/资产的风险水平。需要通过VINTAGE拆解客户和资产，观察相同的表现期后不同客群/资产的逾期占比，例如激活或放款后1~24个月各月月末时点的0+/30+/90+贷款户数和金额或余额的占比。 通过对比不同激活月或放款月在相同的表现窗口后的逾期水平，能观察不同激活月/放款月（对应了不同的策略或人群）的风险走势，更合理评价不同时点人群/资产的情况和策略的效果。 如果运营是针对的客户的，按照激活时间划分客群统计VINTAGE更通用一些；如果是针对资产进行运营，按照贷款的放款月划分资产统计VINTAGE更通用一些。 存量资产的迁移情况？# 除了需要时刻关注新增的风险外，也需要掌握已经逾期资产的迁移/退出情况，也就是滚动率(或者迁徙率、迁移率)。 滚动率一方面体现了客群和资产的质量，也能反映催收运营的状况。 常见的滚动率一般是当期账龄余额与上一期上一账龄余额的比值，用百分比表示。账龄越高，滚动率越高，表示资产回收的可能性越低，进入下一期高账龄的概率越高。 滚动率也可以进一步细分为向上/向下滚动，一般默认的滚动率都是向上滚动，即从低账龄滚到高账龄。向上/向下滚动需要锁定月末时点某一账龄的客户/资产，在下月底观察锁定的这部分客户或资产，统计向上/向下滚动的占比，能排除统计粒度和分期带来的降期影响。 另外，滚动率与产品、前中后的运营等诸多因素有关，短期容易波动，可以计算复合滚动率，例如M0-&gt;M4的滚动率，能从长周期来观察资产质量和运营的稳定水平。 即期指标（coincidental）：# 计算延滞率时常用的两种方法之一，以当期各bucket延滞金额÷应收账款（AR）。 如逾期率Coin©%、Coin(M1)%、Coin(M2)%、Coin(M3)%等等： 当月不同逾期期数的贷款余额/当月底总贷款余额 例： Coin©%=当月C贷款余额/当月底贷款余额(C-M6)-------------------正常用户余额占所有贷款余额 Coin(M1)%=当月M1贷款余额/当月底贷款余额(C-M6) Coin(M1+)%=当月M1−M6贷款余额/当月底贷款余额(C-M6)------------------逾期M1以上的用户余额占所有贷款余额 递延指标（lagged）：# 计算延滞率时常用的两种方法之一，延滞金额÷上月应收账款。若单纯想了解各月资产质量结构，可使用coindental，但若想精准溯及逾放源头的话，建议采用lagged。 与coincident相同也是计算延滞率的一个指标，区别是lagged的分母为产生逾期金额的那一期的应收账款。Lagged观察的是放贷当期所产生的逾期比率，所以不受本期应收账款的起伏所影响。 逾期率Lagged(M1)%、Lagged(M2)%、Lagged(M3)%、Lagged(M4)%、Lagged(M5)%、Lagged(M6)% Lagged DPD30+ = 当前逾期&gt;=30天的客户的本金余额 / 30天前的累计放款本金 当月不同逾期期数的贷款余额/往前推N个月的总贷款余额可以提出当前时点的影响。 例: Lagged(M1)%=当月M1的贷款余额/上个月底时点的贷款余额 -----------------其实就是平台当月M1/1月前的M0 Lagged(M4)%=当月M4的贷款余额/往前推四期的总贷款余额 Lagged(M4+)%=当月M4的贷款余额/往前推四期的总贷款余额 + 当月M5的贷款余额/往前推五期的总贷款余额 + 当月M6的贷款余额/往前推六期的总贷款余额 逾期结算# 实际风险有两种结算方式： Month end：月底结算 （常用方式，主要以自然月月底的逾期指标为主） Cycle end：期末结算（单个借款人还款日时间不同，在月底结算的数据不准确，所以一般设置20日还款，留出10天给催收部门） 早期逾期多数为借款人忘记还款，或短时间资金周转不周，这是与策略密切相关的。通过借款人债偿能力评估识别出借款人有足够资金，可以不做提醒，以获取滞纳金，对于借款人资产表现不好的，可以设置提前10天提醒还款。 逾期天数90-119天，为资产M4阶段。M4-M6的阶段都称之为不良。M4是一个重要的节点，因为消金公司，上报给银监会，或上市公司披露财务数据、风险数据时，都会选择披露不良率。如果有些公司要在审计认可这个方法论时，会对M4做一些调整。 通常180天以上都作为坏账处理，坏账也是被披露的数据之一，还包含一些特别的计提。 账龄(Month of Book，MOB)# 指资产放款月份。放款日截止观察点的月数。如： MOB0：放款日至当月月底 MOB1：放款后第二个完整的月份 MOB2：放款后第三个完整的月份 FPD 首逾率（反欺诈相关）# FPD是指首期逾期率，是说在某一个还款日，仅第一期到期的客户中有多少没有按时还款。与入催率的差别在于，入催率包含了第一期、第二期、第三期等等所有到期的M0。FPD一般用来做反欺诈，因为欺诈用户他第一期是根本不会还款的。 用户授信通过后，首笔需要还款的账单，在最后还款日后7天内未还款且未办理延期的客户比例即为FPD 7，分子为观察周期里下单且已发生7日以上逾期的用户数，分母为当期所有首笔下单且满足还款日后7天，在观察周期里的用户数。常用的FPD指标还有FPD 30。 举例： 假设用户在10.1日授信通过，在10.5日通过分期借款产生了首笔分3期的借款，且设置每月8日为还款日。则11.08是第一笔账单的还款日，出账日后，还款日结束前还款则不算逾期。如11.16仍未还款，则算入10.1-10.30周期的FPD7的分子内。通常逾期几天的用户可能是忘了还款或一时手头紧张，但FPD 7 指标可以用户来评价授信人群的信用风险，对未来资产的健康度进行预估。 与FPD 7 类似，FPD 30也是对用户首笔待还账单逾期情况进行观察的指标。对于逾期30天内的用户，可以通过加大催收力度挽回一些损失，对于逾期30天以上的用户，催收回款的几率就大幅下降了，可能进行委外催收。如果一段时间内的用户FPD 7较高，且较少催收回款大多落入了FPD 30 内，则证明这批用户群的non-starter比例高，借款时压根就没想还，反之则说明用户群的信用风险更严重。 入催率# 有了前面的铺垫，入催率就比较简单了。它指的是在某一个还款日，客户从M0变成M1的比例。比如说，今天，有N个M0客户到了还款日，里面有M个客户按时还款了，那么今天的入催率就是（N-M）/N。它与上面的FPD是有区别的。 逾期时间# DPD、M0（未逾期）、M1（逾期一个月类）、M2（逾期两个月内）。。。 一般M3+就要委外了，M6+(180天以上)就要记为坏账了。 vintage 成熟期# 其实就是逾期率随着账龄变化的趋势图。常见的作用有： 逾期率：vintage的纵轴随着横轴账龄的增大肯定是变大的，最终的平稳后的逾期率（最大值）就是逾期率。（有资产逾期率、账户逾期率两种口径） 欺诈：如果前两期逾期率陡增，短期风险没处理好，是欺诈（特别是第一期就违约的） 信用风险：如果一直上升、很久不拐，说明信用风险控制不太好。 成熟期： 因素判断：风险策略变化、客群变化、市场环境、政策法规变化时，资产质量的变化。（看vintage曲线的波动） 观察点与表现期：# 观察点、观察期、表现期：通常是在整个MOB中选取一个月份作为观察点，前面的期限是观察期，后面的期限是表现期。也就是在时间轴上选取一个点，这个点是观察点。前面的是观察期，后面的是表现期。 表现期越长，信用风险暴露将越彻底，但意味着观察期离当前越远，用以提取样本特征的历史数据将越陈旧，建模样本和未来样本的差异也越大。(模型PSI高) 反之，表现期越短，风险还未暴露完全，但好处是能用到更近的样本。（模型PSI低） vintage举例# 下面是求是汪大佬的一个例子： 对于一个12期分期还款的信贷产品，理论上当用户在12期结束，并还清所有的钱后，我们才能定义为绝对的好客户；反之，我们只能说到目前为止是一个好客户，但并不能知道未来几期用户会不会逾期不还钱。 汪大佬的这个图中可以看到： 账龄最长为12个月，代表产品期限为12期。 根据2018年5月放贷的订单完全走完账龄生命周期，而2018年6月却没走完，说明数据统计时间为2019年6月初。 账龄MOB1、MOB2、MOB3的逾期率都为0，说明逾期指标为M4+（逾期超过90天）风险。 由放贷月份从2018年1月～12月的账户的最终逾期率都在降低，说明资产质量在不断提升，可能是因为风控水平在不断提升。 2018年5月相对于2018年1～4月的逾期率大幅度下降，说明该阶段风控策略提升明显。 不同月份放款的M4+在经过9个MOB后开始趋于稳定（后面违约率不再大幅上升），说明账户成熟期是9个月。 roll rate滚动率# 滚动率定义—状态变化# 滚动率：就是从某个观察点之前的一段时间**（观察期）的最坏的状态，向观察点之后的一段时间（表现期）的最坏的**状态的发展变化情况。（就是说从上一状态向下一状态发展的一个度量，说最坏是因为可能用户逾期多笔） 滚动率分析的具体操作步骤为： step 1. 确定数据源。一般利用客户还款计划表（repayment schedule）。 step 2. 选择观察点，以观察点为截止时间，统计客户在观察期（如过去6个月）的最长逾期期数，按最坏逾期状态将用户分为几个层次，如C（未逾期）、M1、M2、M3、M4+。 step 3. 以观察点为起始时间，统计客户在表现期（如未来6个月）的最长逾期期数，按最坏逾期状态将用户分为几个层次，如C、M1、M2、M3、M4+。 step 4. 交叉统计每个格子里的客户数，如图6中表1所示。 step 5. 统计每个格子里的客户占比，如图6中表2所示。 step 6. 为了排除观察点选择时的随机影响，一般会选择多个观察点。重复step1 ～5。 上面的图说明： 逾期状态为M0的客户，在未来6个月里，有96%会继续保持正常状态，4%会恶化为M1和M2； 逾期状态为M1的客户，未来有81%会回到正常状态，即从良率为81%，有7%会恶化，13%会保持M1状态； 逾期状态为M2的客户，从良率为23%，有39%会恶化为M3和M4+； 逾期状态为M3的客户，从良率为14.7%，有60.7%会恶化为M4+； 逾期状态为M4+的客户，从良率仅为4%，有80%会继续保持此状态。 因此，我们认为历史逾期状态为M4+的客户已经坏透了，几乎不会从良。为了让风控模型有更好的区分能力，需要将客户好坏界限尽可能清晰(也就是从良率最剧烈减少的点开始)，可以定义： 坏用户（bad）= 逾期状态为M4+（即逾期超过90天） 如何确定bad和good标签的账龄# vintage和roll rate的区别：# 滚动率分析用于定义客户的好坏程度。(定义标签bad和good) Vintage分析用于确定合适的表现期。（找到一个合适的观测点，前面的该逾期的已经逾期了，充分暴露了） 定义目标客户到底是good还是bad的具体操作步骤为： step 1. 利用滚动率分析定义坏客户（找到不会再从良的那个账龄点），例如上文案例中定义：M4+为坏客户。（先找到bad和good） step 2. 以M4+作为资产质量指标（上一步找到定义了bad还是good），统计Vintage数据表，绘制Vintage曲线。目的是分析账户成熟期（逾期率不再明显增加），例如上文案例确定：账户成熟期是9个月。 也有根据迁徙率确定bad还是good的，下面是FAL提到的一个例子： 由下表可以看出，M2以上的迁徙率将近90%，所以确定当前逾期31天以上为区分好坏客户的标准，及后续分析的目标变量。 roll rate已经确定了bad为什么还需要通过Vintage分析来确定表现期？# 这是因为：虽然滚动率分析确定了M4+作为坏的程度（从良率最低），但是对于12期的产品，有些账户是在前4期MOB（也就是MOB1 ~ MOB4，经过4个表现期）就达到M4+，有些是在（观测点前）后几期才达到M4+。而这很重要。 Vintage里所有的账户，我们的目的是抓住尽可能多的坏客户。# 现在进一步补充Vintage曲线的绘制过程：如图8所示，对于这10,000个账户，以MOB1为起点，把前N个MOB作为一个窗口，滑窗统计坏客户率，得到图5-表1中的Vintage数据，并绘制Vintage曲线。我们可以发现：经过9期，我们几乎能够抓住所有的坏客户。（也就是前9期该逾期的都逾期了，充分暴露了） 下图是每个用户逾期的不同起止情况举例： 因此，我们将两者结合起来，定义： Bad = 账户经过9期表现期后，逾期状态为M4+（逾期超过90天）。此时 Y=1。 Good = 经过9期表现期，但未达到M4+逾期状态。此时Y=0。 Intermediate = 未进入9期表现期，账户还未成熟，无法定义好坏，也就是不定样本。 有时候也考虑到这么干的话，bad用户会太少，会往上移动到M3,同时因为前面的good用户要和bad做一个截断。比如M1以内的都是good，m3+的都是bad，m2的忽略截断。 Flow Rate迁移率# 展示客户贷款账户在整个生命周期中的变化轨迹，也是预测未来坏账损失的最常用的方法。 其核心假设为：处于某一逾期状态（如M2）的账户，一个月后，要么从良为M0账户，要么恶化为更坏的下一个逾期状态（如M3）。 迁移率 = 前一期逾期金额到下一期逾期金额的转化率 一般缩写为M0-M1、M4-M5等形式，例如： M0-M1 = 当月进入M1的贷款余额 / 上月末M0的贷款余额 M2-M3 = 当月进入M3的贷款余额 / 上月末M2的贷款余额 迁移率分析的具体操作步骤为： step 1. 定义逾期状态，如前文所述的M0、M1、M2等。 step 2. 计算各逾期状态之间的迁移率，如M0-M1、M2-M3等。 step 3. 计算不同月份（也可称为Vintage）的平均迁移率。目的是对本平台在不同时期的资产的迁移率有整体的认知。 step 4. 根据平均迁移率和不良资产回收率，计算净坏账损失率。 接下来，我们以数值案例（非真实业务数据）展示上述过程。 下面表1，每一列代表截止当月放款的总额M0一直到M6的情况，每一行代表1-7月的各个月对应周期的违约率,所以斜线是前后时间序列关系： 上图表2中，2月份的逾期M1资产只能从1月份的正常M0资产滚动而来（斜线迁移），因此从逾期M0资产向M1的转化率为: 2373381007844=23.55%\\frac{237338}{1007844}=23.55\\% ​1007844​​237338​​=23.55% 截止1月末，正常M0资产为 1007844 元，这是起点。 截止2月末，1月末的正常M0资产中有2373381007844=23.55%\\frac{237338}{1007844}=23.55\\%​1007844​​237338​​=23.55% 恶化为逾期M1资产。【较低，因为有不小心逾期的】 截止3月末，2月末的逾期M1资产中有 \\frac{55362}{237338}=23.33%恶化为逾期M2资产。【较低，因为有不小心逾期的】 截止4月末，3月末的逾期M2资产中有 \\frac{25144}{55362}=45.32% 恶化为逾期M3资产。【翻倍上升了】 截止5月末，4月末的逾期M4资产中有83.38%恶化为逾期M5资产。此时已过催收黄金期（90天以内）。【大幅上升！】 截止6月末，5月末的逾期M5资产中有49.37% 恶化为逾期M6资产。这可能采用了委外催收、司法手段等催收策略，效果显著。【从80+%下降到49%】 截止7月末，6月末的逾期M5资产中有82.7% 恶化为逾期M7资产。此时将视为不良资产，打包转卖给第三方公司，这样就能回收部分不良资产，减少损失【没救了】 我们从横向比较每个月的迁移率，发现不完全一样。这是因为随着时间推移、外在宏观经济环境、用户渠道、内部政策、资产质量等变化而产生一定的波动。我们可以利用这些数据： 观察迁移率的发展轨迹，监控坏账的发展倾向和催收效果。 通过对多个月份的迁移率计算平均值，从而使迁移率更加稳定。 坏账准备金# 坏账准备金的概念----各期逾期余额乘以各自准备金率# 呆帐风险是信贷机构必须面对的风险，主要来源于信用风险和欺诈风险等。为了应对未来呆帐的可能，信贷机构一般都会设定一个储备资金，这就是**坏账准备金（Bad Debt Reserve）。**那么我们该如何计算坏账准备金？ 一般做法是，把未清偿贷款余额乘以一定的**准备金比例（Reserve Ratio）**所得。可以理解，资产逾期等级越高（越差），准备金比例也应该越高，因为恶化为呆帐的可能性也更高。如图10所示，正常M0资产恶化为呆帐的可能性最低，因此我们预留的准备金比例也就最少。 我们总结下计算坏账准备金的步骤为： step 1. 统计未清偿贷款金额的分布，也就是M0~M6状态分别对应的资产余额。 step 2. 为每个逾期状态的资产分配一个准备金比例。 step 3. 每个子项目的准备金金额 = 未清偿贷款余额 x 准备金比例。 step 4. 每个子项目的准备金金额相加，得到最终的准备金。 准备金比例# 准备金比例是如何给出的？ 由于坏账准备金是用来覆盖预期的未来呆帐损失的，准备金比例必须等于处于各个逾期状态的资产未来演变为呆帐的比例。 回到上一节的迁移率分析中，我们发现从正常M0资产迁移至逾期M7资产（呆帐）需经过7次迁移，如图11所示。那么，我们只要把各个状态之间的转化率相乘，不就得到准备金比例了？ 因此，我们定义正常M0资产对应的毛坏账损失率，也就是迁移到呆帐的转化率为： 毛坏账损失率 = (M0-M1)×(M1-M2)×(M2-M3)...×(M6-M7) 也就是从M0一直到M7的平均迁移率的乘积。 在本案例中，正常M0资产对应的毛坏账损失率为上上图表2最左侧截止M6-M7的平均迁移率88.03%上面所有的乘起来：0.60% 在实际中，信贷机构会将不良资产打包转卖给第三方公司，这样就能回收部分不良资产，减少损失。因此，我们定义净坏账损失率为： 净坏账损失率 = 毛坏账损失率 - 不良资产外卖回收率 由于M7不良资产的平均回收率为 10.79%，则可计算净坏账损失率为： 0.60%×(1-10.79%)=0.54% 同理，我们可以计算正常资产到不同逾期状态资产的毛损失率和净损失率如下： 根据图12所示的损失率表，我们定义： 当月应计拨备额 = SUM(净坏账损失率 * 月末应收账款余额) 拨备率 = 当月应计拨备额 / 总资产金额 其中，拨备率是用来预防不良资产的发生而准备的金额的比例。拨备率应越低越好。拨备率越高说明风险越大，损失越大，利润越小。 在本案例中，当月应计拨备额为65421元，如图13所示。拨备率为： 654212625091=2.49%\\frac{65421}{2625091}=2.49\\% ​2625091​​65421​​=2.49% 资产组合管理相关# 根据风控成因分类：信用风险、欺诈风险。信用风险主要是用户因为各种原因导致逾期而存在的风险，欺诈风险就是黑产欺诈团队的攻击对公司造成的风险，通过设置规则来拦截高风险用户。 生命周期分为三类： 拓展客户期（学校刚成立时，既要招生，又要有教材支撑） 审批客户期（学习成绩、平时表现） 管理客户期（对学生进行管理） 拓展客户期需要三个方面的支持 目标用户： 适用于拨备segment的风险分级或用户画像支持（拨备与财务挂钩） 目标产品： 风险分级对应期数、利率支持 资产配置有效性分析 资金成本、获客成本、运营成本，在放贷还没开始的时候，就已经由资产管理部门估算确定下来了。后续需要技术来创造价值的，主要是风控的坏账成本，所以资产管理部会用拨备工具来给予支持。 在一个产品刚产生的时候，资产管理部门需要给出关于目标客户的年龄身份，期数，利率的建议；放款后，又需要从其他金融机构拉资金，债权转让等。每一个公司的要求都不一样，我们需要给出推荐，哪一些标的推荐给哪一些公司，如何进行资源组合配置。 审批客户期 主要由贷前策略实施，资产组合管理部门可提供盈利性测算支持，并做好监控、预测、预警系统，当准入用户风险状况超阈值，需提出干预。 资金成本、获客成本、运营成本，在放贷还没开始的时候，就已经由资产管理部门估算确定下来了。后续需要技术来创造价值的，主要是风控的坏账成本，所以资产管理部会用拨备工具来给予支持。 在一个产品刚产生的时候，**资产管理部门需要给出关于目标客户的年龄身份，期数，利率的建议；**放款后，又需要从其他金融机构拉资金，债权转让等。每一个公司的要求都不一样，我们需要给出推荐，哪一些标的推荐给哪一些公司，如何进行资源组合配置。 审批客户期 主要由贷前策略实施，资产组合管理部门可提供盈利性测算支持，并做好监控、预测、预警系统，当准入用户风险状况超阈值，需提出干预。 管理客户期 1.指标方面：新增/存量、风险/规模指标 风险 规模 新增 vintage、FPD GMV 存量 roll rate、coincident dpd、lagging dpd、badrate 在贷余额 2.策略方面：主要由贷中贷后策略实施，可提供盈利性测算支持，并做好监控、预测、预警系统，风险状况超阈值，需提出干预。 资产组合管理作为支撑部门，支撑什么？ 风险计量 策略规则上线 模型效力验证 向CRO提供各种专题类或临时性分析 … 风险计量主要是数据分析，报表，专题性报告，为了规避、减少风险，策略实施者和策略制定者需要分为2个部门。资产管理部门接到业务部门提交的需求，然后根据内容做一些空跑，监控。同时大的模型开发与模型验证也是两个部门，需要资产管理部对模型做持续的监控与评估。统筹贷前、贷中、贷后的数据给到CRO。 资产组合管理方法？ 1.拨备准备金 思考：实际风险与名义风险的区别？ 2.风险分级(用户画像) 思考：有了评分卡模型为什么还要做风险分级? 3.监控、预测、预警系统 思考：资产组合管理报表和业务部门（贷前、中、后）的不同点？ 本次分享总结 1.资产组合管理部门不同于传统的风控业务部门，而是直属于CRO的信息整合部门； 2.资产组合管理贯穿于客户及产品的全生命周期，需要从业者极强的沟通能力； 3.作为支撑部门，资产组合管理部需要运用数据分析把控公司全局资产质量，除此之外还需要以降低作业风险的目的为模型或策略设置二次防线。 4.资产组合管理部门是小白进入金融风控核心岗位的捷径，可以快速的积累风控经验，之后如果转岗策略或模型，都比较容易。 参考文章链接：# https://zhuanlan.zhihu.com/p/81027037/ https://blog.csdn.net/liulj_0803/article/details/52964473 https://www.zhihu.com/question/51583052 这里也有很多干货","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"},{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/tags/risk/"}]},{"title":"let's-encrypt配置网站免费SSL证书","slug":"lets-encrypt","date":"2019-07-13T18:44:23.000Z","updated":"2020-05-24T12:08:50.002Z","comments":true,"path":"article/lets-encrypt.html","link":"","permalink":"https://blog.sofunnyai.com/article/lets-encrypt.html","excerpt":"","text":"前言 厂商选择 下载安装cert-bot 安装cert-bot 获取证书 直接安装到nginx 只生成证书 测试自动更新证书 纯手动的certonly 参考链接 前言# 相信看到这里的对SSL/TSL都有一定了解，链式信任、防劫持、防隐私泄露、安全可信，这些关键字大家脑海里都很熟悉。具体SSL细节就不啰嗦了，感兴趣可以去看看阮一峰的博客或者网上资料，本文主要是实操。 厂商选择# 除了域名统配的高端证书之外，一般我们的博客或者小型网站可以考虑使用免费厂商提供的证书。和大厂商的主要区别就是公信力了，不过理论上都是同等安全的。比如： https://letsencrypt.org/ 在chrome等浏览器厂商的努力支持下，这些之前看起来小点的证书厂商现在兼容性也非常好了。 本文就以let's encrypt和nginx为例。 下载安装cert-bot# 废话少说，现在let's encrypt是推荐在server上使用cert-bot来安装、更新我们的证书，https://certbot.eff.org/ 所以： 安装cert-bot# 1yum install certbot python2-certbot-nginx 获取证书# 首先把我们的域名解析到当前机器的nginx上，80可以正常访问。 然后获取证书有两种方式：1.直接自动安装到nginx，并由cert-bot管理nginx配置文件。 2.获取证书，但手动修改nginx配置文件 直接安装到nginx# 配置环境变量： 123 ln -s /main/server/nginx/sbin/nginx /usr/bin/nginxln -s /main/server/nginx/conf/ /etc/nginxcertbot --nginx 会自动识别nginx配置文件，生成nginx的证书，并修改nginx文件。这是最简单的方式。 只生成证书# 只生成证书： 1certbot certonly --nginx 会让你输入邮箱、域名等信息 测试自动更新证书# 配置自动更新 1echo \"0 0,12 * * * root python -c 'import random; import time; time.sleep(random.random() * 3600)' &amp;&amp; certbot renew -q\" | sudo tee -a /etc/crontab &gt; /dev/null 测试一下： 1certbot renew -q --dry-run 如果报错一个ASCII错误问题，是因为nginx的配置文件有中文。。。所以还是建议只生成证书，手动去配置nginx比较好。 纯手动的certonly# 适用于上面的certonly报错的时候 certbot certonly --manual --email xxx@xxx.com -d *.domain.com 参考链接# https://certbot.eff.org/lets-encrypt/centosrhel7-nginx https://www.jianshu.com/p/6ea81a7b768f https://www.jianshu.com/p/a1cc68c7d916","categories":[{"name":"network","slug":"network","permalink":"https://blog.sofunnyai.com/categories/network/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"},{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"运维","slug":"运维","permalink":"https://blog.sofunnyai.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"IO基础：socket和TCP","slug":"selector-Epoll","date":"2018-09-12T12:12:26.000Z","updated":"2020-05-22T07:38:16.341Z","comments":true,"path":"article/io-basic-socket-tcp.html","link":"","permalink":"https://blog.sofunnyai.com/article/io-basic-socket-tcp.html","excerpt":"","text":"IO# OSI基础模型# 提到IO，首先是OSI参考模型，计算机网络基础，一共七层 这7层是一个虚的东西，是一个规范。TCP/IP协议给精简到4层，把上面的应用层-表示层-会话层统一归结到新的应用层是用户称，把下面的传输控制层-网络层-链路层-物理层视为内核层。 OSI七层网络模型 TCP/IP四层概念模型 对应网络协议 应用层（Application） 应 HTTP、TFTP, FTP, NFS, WAIS、SMTP 表示层（Presentation） 用 Telnet, Rlogin, SNMP, Gopher 会话层（Session） 层 SMTP, DNS 传输层（Transport） 传输层 TCP, UDP 网络层（Network） 网络层 IP, ICMP, ARP, RARP, AKP, UUCP 数据链路层（Data Link） 数据 FDDI, Ethernet, Arpanet, PDN, SLIP, PPP 物理层（Physical） 链路层 IEEE 802.1A, IEEE 802.2到IEEE 802.11 linux命令测试讲解TCP# 创建一个到baidu的文件描述符（内核层）# 执行一个bash命令创建一个到baidu的socket，放到当前进程的8号文件描述符中：exec 8&lt;&gt; /dev/tcp/www.baidu.com/80 linux一切皆文件，上面面创建了一个“8”文件，是一个socket指向了百度， 8是文件描述符fd(就像代码的变量)，&lt;&gt;是一个双向输入输出流，可以看到 echo $$ 16199 # 打印当前命令行的进程号 # 也可以ps -ef 然后grep出来 tree 16199 9368 0 4月15 pts/1 00:00:01 /bin/bash 123456789101112- 可以去当前进程的目录看一眼- &#96;&#96;&#96;bash cd &#x2F;proc&#x2F;16199&#x2F;fd # 进入当前进程的fd目录 ls # 看一眼 lrwx------ 1 tree tree 64 5月 21 18:31 0 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 1 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 2 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 255 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 8 -&gt; &#39;socket:[1037956]&#39; # 每个进程都有0,1,2三个fd文件描述符。分别是stdin、stdout、stderr 向文件描述符中写东西通信（用户层态）# 123456echo -e \"GET / HTTP/1.0\\n\" 1&gt;&amp; 8 # 打印一个字符串到标准输出（所以是1）重定向&gt;到文件描述符(所以是&amp;，重定向到文件不用&amp;)8中cat 0&lt;&amp; 8# 从文件描述符(所以是&amp;，文件的话不用&amp;)8中标准输入&lt;# 。。。。。下面打印一大堆百度的html 传输控制层TCP协议# 什么是socket套接字？# ip+port &lt;---------&gt; ip+port 是一【套】，客户端和服务端的ip+port 4个要素决定唯一的一个socket 客户端的ip是B，可以和baidu建立多少个链接？65535个 此时客户端B还能继续和163建立链接吗？也可以继续再次建立65535个，因为socket是【一套】4个要素，server换了就是另外一个socket了。 对于类似如下netstat -anp出来的socket链接，每一个established都有一个文件描述符(fd目录下)数字和他对应并交给一个进程。程序只用和这个文件描述符进行读写就可以进行socket通信了。【如果多个socket对应一个进程：就是多路复用器selector或者epoll】 什么是TCP协议？# 是一个面向连接的可靠的传输协议。因为三次握手保证了可靠传输。 三次握手的细节？# C-----------syn-----------&gt;S # “我要跟你连接了，标识是syn” C&lt;----------syn+ack-------S # “好的，我知道了” 让客户端知道Server已经响应了 C------------ack-----------&gt;S # 好的，我知道你知道了。让Server知道发出的消息客户端收到了 三次握手完毕后，双方才有资源开辟，才能开始传输。 tcpdump 四次分手的细节，为啥要四次？# 因为握手是三次，开辟了资源。分手释放资源是双方的，所以是四次（双方都要同时释放，不能轻易单方面释放了） 分手的C只是先说断开的人 C-----------fin-----------&gt;S # “我要跟你分手了，标识是fin”给Server一个结束标识 C&lt;----------fin+ack-------S # “好的，我知道了” 让客户端知道Server已经响应了（但是我要确认一下真的没事儿了） C&lt;-----------fin------------S # “好吧，分吧，标识是fin”确认真的没事儿了，给客户端一个结束标识 C------------ack-----------&gt;S # “好的，”让Server知道发出的消息客户端收到了 三次握手和四次分手是不可分割的最小粒度# LVS作为一个工作在四层的负载均衡，是无法知晓数据包的具体内容的！ LVS是否可以随意把数据给后端进行负载？-可以负载，但是受制于协议约束！ C ----- lvs ----- S1/S2 的时候，LVS必须要把握手的三次给到一对C—S，不能给到另外一个S，否则无法建立连接。 网络和路由# 网络设置要ip、gateway、mask、dns4个东西","categories":[{"name":"IO","slug":"IO","permalink":"https://blog.sofunnyai.com/categories/IO/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"基础","slug":"基础","permalink":"https://blog.sofunnyai.com/tags/%E5%9F%BA%E7%A1%80/"}]},{"title":"深入理解woe和iv","slug":"woe-iv","date":"2018-01-14T03:10:14.000Z","updated":"2020-05-22T07:41:28.841Z","comments":true,"path":"article/woe-iv.html","link":"","permalink":"https://blog.sofunnyai.com/article/woe-iv.html","excerpt":"","text":"WOE(Weight of Evidence) 证据权重 WOE的定义 Woe公式理解 WOE回顾： IV值：可以认为是WOE的加权 计算woe和IV的步骤 计算注意点 WOE和IV的比较----为什么不用WOE，而是用IV值 通用WOE计算实现 WOE(Weight of Evidence) 证据权重# https://blog.csdn.net/kevin7658/article/details/50780391 https://zhuanlan.zhihu.com/p/80134853 https://www.cnblogs.com/hanxiaosheng/p/9831838.html https://www.cnblogs.com/hanxiaosheng/p/9831964.html https://blog.csdn.net/PbGc396Dwxjb77F2je/article/details/99687952 WOE的定义# WOE是一种对原始自变量进行编码的格式，可以屏蔽极值增强鲁棒性。（树模型一般只对离散变量进行编码，对极值不敏感） 要对一个变量进行WOE编码，需要首先把这个变量进行分组处理/离散化处理（等宽切割，等频切割，卡方分箱，或者利用决策树来切割）。 分组后，对于第i组，WOE的计算公式如下： woei=lnpyipni=lnpy1py0=ln(BadiBad/GoodiGood)=ln(BadiBad)−ln(GoodiGood)woe_i = ln\\frac{p_{yi}}{p_{ni}} = ln\\frac{p_{y1}}{p_{y0}} = ln(\\frac{Bad_i}{Bad}/\\frac{Good_i}{Good}) = ln(\\frac{Bad_i}{Bad})-ln(\\frac{Good_i}{Good}) woe​i​​=ln​p​ni​​​​p​yi​​​​=ln​p​y0​​​​p​y1​​​​=ln(​Bad​​Bad​i​​​​/​Good​​Good​i​​​​)=ln(​Bad​​Bad​i​​​​)−ln(​Good​​Good​i​​​​) 其中：pyi为坏样本占所有坏样本的比例，py0好样本占所有好样本的比例； Bad为坏样本总数，Badi为变量i对应的坏样本个数，Good为好样本总数，Goodi为变量i对应的好样本个数 ； 将模型目标变量y为1记为违约用户（坏样本），对于目标变量为0记为正常用户（好样本） Woe公式理解# 基础模式 woei=ln(BadiBad)−ln(GoodiGood) woe_i = ln(\\frac{Bad_i}{Bad})-ln(\\frac{Good_i}{Good}) woe​i​​=ln(​Bad​​Bad​i​​​​)−ln(​Good​​Good​i​​​​) 即 WOE = ln (第i个分箱的坏人数 / 总坏人数) - ln (第i个分箱的好人数 / 总好人数) 此时可以理解为：每个分箱里的坏人(响应)分布相对于好人(未响应)分布之间的差异性。 变换模式 woei=ln(BadiGoodi)−ln(BadGood)woe_i = ln(\\frac{Bad_i}{Good_i})-ln(\\frac{Bad}{Good}) woe​i​​=ln(​Good​i​​​​Bad​i​​​​)−ln(​Good​​Bad​​) WOE = ln (第i个分箱的坏人数 / 第i个分箱的好人数) - ln (总坏人数 / 总好人数) 此时可以理解为：每个分箱里的坏好比(Odds)相对于总体的坏好比之间的差异性。 WOE回顾：# 当前分组中，差异越大，响应的比例越大，WOE值越大； 反应的是特征的重要性，woe的绝对值越大，说明越重要。 当前分组WOE的正负，由当前分组响应和未响应的比例，与样本整体响应和未响应的比例的大小关系决定，当前分组的比例小于样本整体比例时，WOE为负，当前分组的比例大于整体比例时，WOE为正，当前分组的比例和整体比例相等时，WOE为0。 WOE的取值范围是全体实数。(所以就不方便，需要IV缩放) WOE其实描述了变量当前这个分组，对判断个体是否会响应（或者说属于哪个类）所起到影响方向和大小，当WOE为正时，变量当前取值对判断个体是否会响应起到的正向的影响，当WOE为负时，起到了负向影响。而WOE值的大小，则是这个影响的大小的体现。 做完woe之后，LR系数不再代表特征的重要程度。 woe后LR的时候要保证系数全都是正数！ woe的符号代表特征对模型贡献的方向，系数如果不是正数就会改变这个方向。 但是做BiVar的时候已经分析了这个woe特征的贡献方向，如果LR再负数会扭曲推翻之前BiVar的分析。 优点：数值型转化为WOE可以增强鲁棒性，屏蔽极值的影响（极小值和极大值也被分组了） 但是树模型对极值不敏感，只用处理字符型即可 note：如果特征做了WOE，那么LR的系数不能代表特征重要性权重。（WOE绝对值大小已经是特征重要性了，LR的系数仅仅是拟合系数而已） 核心——分箱逻辑： 实现WOE最重要的是分箱逻辑，不同的分箱会带来不同的WOE。金融常使用“基于负样本占比差异最大化”原则来分箱 一般是5箱内最好，通常最多不超过10箱 每一箱的负样本占比差值尽可能大（箱合并原则） 每一箱的样本量不少于总体5%（不要太小，不要小于三五百个样本） 通过控制划分后的总箱数，来迭代进行分箱合并 IV值：可以认为是WOE的加权# 某个分箱的IV值： IVi=(pyi−pni)∗WOEi=(BadiBadt−GoodiGoodt)∗WOEi=(BadiBadt−GoodiGoodt)∗ln(BadiBadt/GoodiGoodt)IV_i =(p_{yi}-p_{ni}) * WOE_i= (\\frac{Bad_i}{Bad_t}-\\frac{Good_i}{Good_t}) * WOE_i = (\\frac{Bad_i}{Bad_t}-\\frac{Good_i}{Good_t}) * ln(\\frac{Bad_i}{Bad_t}/\\frac{Good_i}{Good_t}) IV​i​​=(p​yi​​−p​ni​​)∗WOE​i​​=(​Bad​t​​​​Bad​i​​​​−​Good​t​​​​Good​i​​​​)∗WOE​i​​=(​Bad​t​​​​Bad​i​​​​−​Good​t​​​​Good​i​​​​)∗ln(​Bad​t​​​​Bad​i​​​​/​Good​t​​​​Good​i​​​​) 有了一个变量各分组的IV值，我们就可以计算整个变量的IV值： IV=∑inIViIV = \\sum_i^n{IV_i} IV=​i​∑​n​​IV​i​​ n是分箱的数量 对于变量的一个分组，这个分组的响应和未响应的比例与样本整体响应和未响应的比例相差越大，IV值越大，否则，IV值越小； 极端情况下，当前分组的响应和未响应的比例和样本整体的响应和未响应的比例相等时，IV值为0； IV值的取值范围是[0,+∞) ，且，当当前分组中只包含响应客户或者未响应客户时，IV = +∞。 故可以计算多个特征的IV值，按照从大到小排序来决定采用哪些特征更容易响应。（类似信息增益或者基尼指数的感觉） IV比如要大于0.05才比较好用 谨慎的时候会要求IV大于0.02就可以先留着，也就是说IV在0.02-0.5之间 超过0.5的特征会被直接拿去作为策略-------------&gt;IV太大的值可能会把模型其他特征的信息覆盖掉，也可能会造成过拟合。（如果这个特征以后抖动，造成线上效果波动） 计算woe和IV的步骤# step 1. 对于连续型变量，进行分箱（binning），可以选择等频、等距，或者自定义间隔；对于离散型变量，如果分箱太多，则进行分箱合并。 step 2. 统计每个分箱里的好人数(bin_goods)和坏人数(bin_bads)。 step 3. 分别除以总的好人数(total_goods)和坏人数(total_bads)，得到每个分箱内的边际好人占比(margin_good_rate)和边际坏人占比(margin_bad_rate)。 step 4. 计算每个分箱里的WOE [公式] step 5. 检查每个分箱（除null分箱外）里woe值是否满足单调性（bivar），若不满足，返回step1。注意⚠️：null分箱由于有明确的业务解释，因此不需要考虑满足单调性。 step 6. 计算每个分箱里的IV，最终求和，即得到最终的IV。 备注：好人 = 正常用户，坏人 = 逾期用户 计算注意点# 分箱时需要注意样本量充足，保证统计意义。 若相邻分箱的WOE值相同(非常相近)，则将其合并为一个分箱。 当一个分箱内只有好人或坏人时（会出现∞），可对WOE公式进行修正如下： Woei=ln(Badi+0.5Badt+0.5/GoodiGoodt)Woe_i = ln(\\frac{Bad_i+0.5}{Bad_t+0.5}/\\frac{Good_i}{Good_t}) Woe​i​​=ln(​Bad​t​​+0.5​​Bad​i​​+0.5​​/​Good​t​​​​Good​i​​​​) 在实践中，我们还需跨数据集检验WOE分箱的单调性。如果在训练集上保持单调，但在验证集和测试集上发生翻转而不单调，那么说明分箱并不合理，需要再次调整。（BIVAR） 或者当分箱中只有好人或坏人的时候，也可以这么做： 如果可能，直接把这个分组做成一个规则，作为模型的前置条件或补充条件；（即不允许这种分箱存在） 重新对变量进行离散化或分组，使每个分组的响应比例都不为0且不为100%，尤其是当一个分组个体数很小时（比如小于100个），强烈建议这样做，因为本身把一个分组个体数弄得很小就不是太合理。 如果上面两种方法都无法使用，建议人工把该分组的响应数和非响应的数量进行一定的调整。如果响应数原本为0，可以人工调整响应数为1，如果非响应数原本为0，可以人工调整非响应数为1.（或者按照上面进行修正，分子分母都加0.5） WOE和IV的比较----为什么不用WOE，而是用IV值# 变量各分组的WOE和IV都隐含着这个分组对目标变量的预测能力这样的意义，但是有以下问题： 1. 各个组的WOE有正有负 解释： 假设构造一个$ WOE=\\sum_i^n{WOE_i} ，那么因为里面的WOE_i$有正有负，所以求和不好表征。 2.每个组的WOE没有考虑到这个各个组在总体的占比 解释： 即使构造一个WOE=∑in∣WOEi∣WOE=\\sum_i^n{|WOE_i|}WOE=∑​i​n​​∣WOE​i​​∣规避上面的负数问题，但是每个组WOEiWOE_iWOE​i​​的信息含量（泛化能力？）是不相同的，比如某个组WOEiWOE_iWOE​i​​很高但是这个组只有很少的样本，把他直接和另外一个很多样本但很低的WOEjWOE_jWOE​j​​相加是很不合适的。 假设某特征A分两组，从这个表我们可以看到，变量取1时，响应比达到90%，对应的WOE很高，但对应的IV却很低，原因就在于IV在WOE的前面乘以了一个系数(pyi−pni)(p_{yi}-p_{ni})(p​yi​​−p​ni​​) 而这个系数很好的考虑了这个分组中样本占整体样本的比例，比例越低，这个分组对变量整体预测能力的贡献越低。 相反，如果直接用WOE的绝对值加和，会得到一个很高的指标，这是不合理的。 通用WOE计算实现# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187# -*- coding: utf-8 -*-import mathimport pandas as pdimport numpy as npfrom pandas import DataFramefrom pandas.core.dtypes import dtypesfrom pandas.core.dtypes.common import is_numeric_dtypefrom sklearn.linear_model import LogisticRegressionfrom sklearn.tree import DecisionTreeRegressor# 自定义实现的离散型变量woeclass charWoe(object): def __init__(self, datases: dict, dep, weight, vars: list): # 数据字典&#123;'dev':xxx,'val':xxx,'off':xxx&#125; 训练集，测试集，时间外样本集 3个dataframe self.datases = datases self.devf = datases.get('dev', '') self.valf = datases.get('val', '') self.offf = datases.get('off', '') self.dep = dep # 标签 self.weight = weight # 样本权重 self.vars = vars # 特征名 self.nrows, self.ncols = self.devf.shape # 样本数，特征数 def char_woe(self): # 得到每一类样本的个数，且加入平滑项是的bad和good都不为0 dic = dict(self.devf.groupby(self.dep).size()) # 根据标签去group，变成&#123;1:xxx,0:yyy&#125;字典 good = dic.get(0, 0) + 1e-10 # 平滑防止组内为0，计算失败 bad = dic.get(1, 0) + 1e-10 # 对每一个特征进行处理 for col in self.vars: # df[[sex,bad]].groupby(['sex','bad']).size() 会得到一个series， # 直接转成字典：&#123;(男, 0): 10553, (男, 1): 518, (女, 0): 233, (女, 1): 3&#125; # key的第一个代表特征值，第二个代表标签值 data = dict(self.devf[[col, self.dep]].groupby([col, self.dep]).size()) ''' 特征值+分类组合超过100的时候，跳过当前取值 假设二分类，dep是0,、1，则这个特征只能有50个特征值 &#123;(col特征值A,0):25,(col特征值A,1):10,(col特征值B,0):33,(col特征值B,1):21...&#125; 因为特征值过多时，WOE分箱效率低，建议进行特征截断 出现频率过低的特征就统一赋值，放到同一个箱里 ''' if len(data) &gt; 100: print(col, '有太多的特征值，建议手动进行特征截断，即将跳过此特征...') continue # 打印特征取取值个数 print('特征【%s】的取值个数是【%d】' % (col, len(data))) dic = dict() # &#123;(男, 0): 10553, (男, 1): 518, (女, 0): 233, (女, 1): 3&#125; # key的第一个代表特征值，第二个代表标签值 for (k, v) in data.items(): fea_value, dp = k # 拿出key中的特征值和标签(fea_value=男，dp=0，v=10553) dic.setdefault(fea_value, &#123;&#125;) # 给对应key设置为一个空字典（如果没有找到的话，找到的话说明之前已经设置过了） #&#123;(男, 0): 10553, (男, 1): 518&#125; ==&gt; &#123;男:&#123;1 = 518，0 = 10553&#125; , 女:&#123;...&#125; &#125; dic[fea_value][int(dp)] = v # 字典中嵌套字典 for(k, v) in dic.items(): # 计算cnt和badrate # 循环上面的嵌套字典，k=男，v=&#123;1 = xxx，0 = yyy&#125;。 # 拿出内部嵌套的字典k1 = 1 v1=xxx,生成---&gt;：&#123;‘男’：&#123; '0': 10553, '1': 518&#125;&#125; dic[k] = &#123;str(int(k1)):v1 for (k1, v1) in v.items()&#125; # 所有正负样本的和v.values(): [10553,518] dic[k]['cnt'] = sum(v.values()) # 4舍5入求bad_rate bad_rate = round(v.get(1,0)/dic[k]['cnt'], 5) dic[k][\"bad_rate\"] = bad_rate # 利用定义的函数进行合并分箱。 dic=&#123;'男': &#123;'cnt': xxx, '0': yy, '1': zz, 'bad_rate': 0.xx&#125;, 'B': &#123;'cnt': xxx, '0': yyy, '1': zz, 'bad_rate': 0.zz&#125;&#125; dic = self.combine_box_char(dic) # 对每个特征计算WOE和IV值 for (k,v) in dic.items(): a = v.get('0', 1) / good+1e-10 b = v.get('1', 1) / bad+1e-10 dic[k]['Good'] = v.get('0',0) dic[k]['Bad'] = v.get('1',0) # 下面两个是 a/b 还是 b/a？ 按照定义应该是ln(pi/pn) = ln(p_bad/p_good)? dic[k]['woe'] = round(math.log(b/a),5) dic[k]['iv'] = round((b-a)*dic[k]['woe'],5) ''' 按照分箱后的点进行分割， 计算得到每一个特征值的WOE值， 将原始特征名加上'_woe'后缀，并赋予WOE值。 ''' for (klis, v) in dic.items(): # 把分箱合并后的key切开 for k in str(klis).split(','): # 数字类型处理一下 if is_numeric_dtype(self.devf[col]): k = float(k) if '.' in k else int(k) # 训练集进行替换 self.devf.loc[self.devf[col] == k, \"%s_woe\" % col] = v[\"woe\"] self.devf.loc[self.devf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 测试集进行替换 if not isinstance(self.valf, str): self.valf.loc[self.valf[col] == k,\"%s_woe\" % col] = v[\"woe\"] self.valf.loc[self.valf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 跨时间验证集进行替换 if not isinstance(self.offf, str): self.offf.loc[self.offf[col] == k,\"%s_woe\" % col] = v[\"woe\"] self.offf.loc[self.offf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 返回新的字典，其中包含三个数据集。 return &#123;\"dev\": self.devf, \"val\": self.valf, \"off\": self.offf&#125; def combine_box_char(self, dic): ''' 实施两种分箱策略（规则）： 1.不同箱之间负样本占比(bad_rate)差异最大化。----各个特征值按照badrate从小到大排序，分别用后面一个减去前面每一个，计算badrate差值。找到差值最小的两箱合并之 2.每一箱的样本量不能过少。----当有某箱样本小于总样本的0.05，或总箱数&gt;5的时候，还是按照badrate差异最大化原则：按badrate排序后，把最小的一箱和前后比较，与差值较小的一箱合并 :param dic: 等待分箱的数据 :return: ''' # 首先合并至10箱以内。按照每一箱负样本占比差异最大化原则进行分箱。----各个特征值按照badrate从小到大排序，分别用后面一个减去前面每一个，计算badrate差值。找到差值最小的两箱合并之 while len(dic) &gt;= 10: # 拿出所有的特征和badrate，k是特征值，v['bad_rate']是负样本占比 bad_rate_dic = &#123;k:v['bad_rate'] for (k,v) in dic.items()&#125; # 按照负样本占比排序。因为离散型变量是无序的（比如学历、渠道类型） # 可以直接写成负样本占比递增的形式。(所有的dict按照value升序排序) # 得到一堆tuple的list，是(特征值，bad_rate)的一个list bad_rate_sorted = sorted(bad_rate_dic.items(), key=lambda x: x[1]) # 计算每两箱之间的负样本占比差值。 bad_rate_diff = [bad_rate_sorted[i + 1][1] - bad_rate_sorted[i][1] for i in range(len(bad_rate_sorted) - 1)] # 找到差值最小的那个，准备将其进行合并。 min_diff_index = bad_rate_diff.index(min(bad_rate_diff)) # 找到k1和k2，即差值最小的两箱的key. k1, k2 = bad_rate_sorted[min_diff_index][0], bad_rate_sorted[min_diff_index + 1][0] # 得到重新划分后的字典，箱的个数比之前少一 直接改了dic，给他里面插入一个新的分箱。key是两个key的组合！ dic[\"%s,%s\" % (k1, k2)] = dict() # 重新统计新箱的正负样本数（合并两个key的） dic[\"%s,%s\" % (k1, k2)][\"0\"] = dic[k1].get(\"0\", 0) + dic[k2].get(\"0\", 0) dic[\"%s,%s\" % (k1, k2)][\"1\"] = dic[k1].get(\"1\", 0) + dic[k2].get(\"1\", 0) # 重新统计新箱的cnt dic[\"%s,%s\" % (k1, k2)][\"cnt\"] = dic[k1][\"cnt\"] + dic[k2][\"cnt\"] # 重新计算新分箱的bad_rate dic[\"%s,%s\" % (k1, k2)][\"bad_rate\"] = round(dic[\"%s,%s\" % (k1, k2)][\"1\"] / dic[\"%s,%s\" % (k1, k2)][\"cnt\"],5) # 删除之前两个老的分箱 del dic[k1], dic[k2] ''' 结束循环后，箱的个数应该少于10。 下面实施第二种分箱策略规则：每个分箱的样本不能太少！ 将样本数量少的箱合并至其他箱中，以保证每一箱的样本数量不要太少。 ''' # 找出最少样本数的分箱 min_cnt = min([v['cnt'] for (k, v) in dic.items()]) # 当样本数量小于总样本的5%或者总箱的个数大于5的时候，对箱进行合并 【这里的5% 和 5是经验值】 while min_cnt &lt; self.nrows*0.05 or len(dic) &gt; 5: # 可能找到多个符合min_cnt的list，取第一个 min_key = [k for (k,v) in dic.items() if v['cnt'] == min_cnt][0] bad_rate_dic = &#123;k:v['bad_rate'] for (k,v) in dic.items()&#125; # 根据bad_rate升序 bad_rate_sorted = sorted(bad_rate_dic.items(),key=lambda x:x[1]) keys = [item[0] for item in bad_rate_sorted] min_key_index = keys.index(min_key) ''' 不能直接把样本数最小的两个分箱合并，因为 同样想保持合并后箱之间的负样本占比差异最大化。 由于箱的位置不同，按照三种不同情况进行分类讨论。 ''' # 如果是第一箱、第二箱 if min_key_index == 0: k1,k2 = keys[:2] elif min_key_index == len(keys)-1: # 如果是最后一箱，和倒数第二箱合并 k1,k2 = keys[-2:] else: # 如果是中间箱，前后相比和bad_rate值相差最小的箱合并 # 和前面的比 bef_bad_rate = dic[min_key]['bad_rate'] - dic[keys[min_key_index-1]]['bad_rate'] # 后面的当前比（keys是按照bad_rate升序的，不减出负数） aft_bad_rate = dic[keys[min_key_index+1]]['bad_rate'] - dic[min_key]['bad_rate'] if bef_bad_rate &lt;= aft_bad_rate: k1,k2 = keys[min_key_index-1], min_key else: k1,k2 = min_key, keys[min_key_index+1] # 找到k1，k2后合并之，同上 # 新增一个合并后的分箱 dic[\"%s,%s\" % (k1, k2)] = dict() # 重新计算cnt，bad_rate，正负样本数 dic[\"%s,%s\" % (k1, k2)][\"0\"] = dic[k1].get(\"0\", 0) + dic[k2].get(\"0\", 0) dic[\"%s,%s\" % (k1, k2)][\"1\"] = dic[k1].get(\"1\", 0) + dic[k2].get(\"1\", 0) dic[\"%s,%s\" % (k1, k2)][\"cnt\"] = dic[k1][\"cnt\"] + dic[k2][\"cnt\"] dic[\"%s,%s\" % (k1, k2)][\"bad_rate\"] = round(dic[\"%s,%s\" % (k1, k2)][\"1\"] /dic[\"%s,%s\" % (k1, k2)][\"cnt\"], 5) # 删除旧的分箱 del dic[k1], dic[k2] # 重新计算当前最小的箱的样本个数，进入下次循环继续合并分箱 min_cnt = min([v[\"cnt\"] for v in dic.values()]) return dic","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"}]},{"title":"模型评价指标KS和PSI","slug":"ks-psi","date":"2018-01-12T05:21:10.000Z","updated":"2020-05-23T14:51:07.319Z","comments":true,"path":"article/ks_psi.html","link":"","permalink":"https://blog.sofunnyai.com/article/ks_psi.html","excerpt":"","text":"KS指标 KS值定义 回顾TPR(True Positive Rate)和FPR(False Positive Rate) 模型的KS值 KS(Kolmogorov-Smirnov)计算步骤： KS和ROC的区别 模型评价时: PSI群体稳定性指标 PSI(Population Stability Index)的定义 KS指标# KS值定义# 回顾TPR(True Positive Rate)和FPR(False Positive Rate)# 混淆矩阵，横着的P、N是预测结果阳性还是阴性。竖着的是说预测是否正确。 Positive Negtive T TP TN F FP FN TP：预测为正向（P），实际上预测正确（T），即判断为正向的正确率 TN：预测为负向（N），实际上预测正确（T），即判断为负向的正确率 FP：预测为正向（P），实际上预测错误（F），误报率，即把负向判断成了正向 FN：预测为负向（N），实际上预测错误（F），漏报率，即把正向判断称了负向 准确率Accuracy=（TP+TN） / （TP+FP+TN+FN）， 即预测正确的比上全部的数据 精确率、查准率 Precision=TP / （TP+FP），即在预测为正向的数据中，有多少预测正确了 召回率、查全率 Recall=TP / （TP+FN），即在所有正向的数据中，有多少预测出来了 TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。(就是召回率，正样本被召回的比例) 【金融里面，分母是所有的good_cnt】 Recall=TPR=TPTP+FNRecall = TPR = \\frac{TP}{TP+FN} Recall=TPR=​TP+FN​​TP​​ FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。（就是漏掉的阴性或判断错的阳性，占总阴性的比例) 【金融里面，分母是所有的bad_cnt】 FPR=FPFP+TNFPR = \\frac{FP}{FP + TN} FPR=​FP+TN​​FP​​ 更多关于TPR： /02_ml/01_THEORY/00_theory.ipynb#TPR(True-Positive-Rate) 模型的KS值# 最理想的模型，是TPR尽量高而FPR尽量低（召回尽可能多的坏人，漏掉尽可能少的好人），然而任何模型在提高正确预测概率的同时，也会难以避免地增加误判率。 我们训练出来的模型，一般不是直接给出是正类还是负类的结果，给的是为正类的概率，我们还需要选择一个阈值，实例通过模型得到的概率大于阈值，判断为正类，小于阈值判断为负类。也就是说阈值的不同，以上的各个指标的值也是不同的。每一个阈值对应一对TPR和FPR。把阈值看成自变量，以上TPR、和FPR看成因变量，在二维坐标系里面做∣FPT−FPR∣|FPT-FPR|∣FPT−FPR∣关系曲线，这就是KS曲线。 KS曲线实操的时候是可以把将概率的阈值从小到大进行排序，取10%的值为间隔， 同理将10%*k(k=1,…9)处值作为阈值，计算不同的FPR和TPR， 以10%*k（k=1,…9）为横坐标，同时分别以TPR和FPR为纵坐标画出两条曲线就是KS曲线。 KS值是KS曲线的最大值，也就是TPR和FPR差异的最大点 KS值=max(|TPR-FPR|) KS值是在模型中用于区分预测正负样本分隔程度的评价指标。 需要计算每一箱的KS，然后max是在所有分箱的KS上取最大值 一般来说，KS大比较好。但是也不是越大越好，尤其征信行业 业内认为AUC更能体现模型的【整体的】区分能力，但是KS关注的是区分能力的最大值。 我们做的是拒绝模型，关注的是最大值的点取在哪里的。会做一个截断，小于这个值的都拒绝了。关注在最大值之前误杀了多少人。（相比于AUC注重局部而不是全局） KS(Kolmogorov-Smirnov)计算步骤：# KS用于模型风险区分能力进行评估，指标衡量的是好坏样本累计分部之间的差值。 好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强。 KS的计算步骤如下： 计算每个评分区间的好坏账户数。 计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的K-S值。 KS值：是和AUC强相关的，但是样本很小的时候KS大，AUC不一定大。 A卡的KS： 714那种最差的一般也至少要25%， 正常的p2p公司，客户质量稍微好一点会到30%-40%左右。 最好那些有场景的分期产品最多也就不到50%，所以一般是在25%-50%之间。 B卡的KS： 至少也有40%，最高80% 一般60%左右。 各个数据集如dev和oft的KS差值不要太大，否则模型不稳定，跨时间稳定性差。 一般dev和oft的KS差值只能在5%以内，比较求稳的公司要求在3%以内。 正负样本： 逾期样本/正常样本=1%-5%（也有能做到1/1000的） 5%个点就是比较高的了，是很不均衡的。 要是坏账5%，会亏很多钱。badrte 3%以下才可能赚钱。 欺诈样本/正常样本=1/10w 欺诈用户是极少的 https://www.zhihu.com/question/37405102/answer/106668941 KS和ROC的区别# KS值对模型的评价不受样本不均衡问题的干扰，但仅限于模型评价。 模型评价时:# ROC曲线# 描绘的是不同的截断点（判断好人坏人的阈值）时，以FPR和TPR为横纵坐标轴，描述随着截断点的变化，TPR随着FPR的变化。 纵轴：TPR=正例分对的概率 = TP/(TP+FN)，其实就是查全率 横轴：FPR=负例分错的概率 = FP/(FP+TN) 作图步骤： 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）-----这就是截断点依次选取的顺序 按顺序选取截断点，并计算TPR和FPR—也可以只选取n个截断点，分别在1/n，2/n，3/n等位置 连接所有的点（TPR，FPR）即为ROC图 KS值# 作图步骤： 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）-----这就是截断点依次选取的顺序 按顺序选取截断点，并计算TPR和FPR —也可以只选取n个截断点，分别在1/n，2/n，3/n等位置 横轴为样本的占比百分比（最大100%），纵轴分别为TPR和FPR，计算|TPR-FPR|的ks值，可以得到KS曲线 TPR和FPR曲线分隔最开的位置就是最好的“截断点”，最大间隔距离就是KS值，通常&gt;0.2即可认为模型有比较好的预测准确性 123456789101112131415161718192021222324252627282930313233343536# 模型预测会返回概率，两列，第一列是0的概率，第二列是1的概率proba = lr_model.predict_proba(x)proba# train_thresholds 是阈值，每一个阈值对应roc曲线上的一点train_fpr,train_tpr,train_thresholds = roc_curve(y,proba[:,1])train_ks_arr = abs(train_fpr-train_tpr)train_ks = train_ks_arr.max()print('train KS:',train_ks)# 验证集的ksoft_fpr, oft_tpr,oft_thresholds = roc_curve(oft_y, lr_model.predict_proba(oft_x)[:,1])oft_ks_arr = abs(oft_fpr - oft_tpr)oft_ks = oft_ks_arr.max()print('oft KS:',oft_ks)# 最大值ks对应的下标（画图用）i = train_ks_arr.tolist().index(train_ks)j = oft_ks_arr.tolist().index(oft_ks)import matplotlib.pyplot as pltfrom matplotlib import pyplot as pltplt.plot(train_fpr,train_tpr,label='train roc')plt.plot(train_fpr,abs(train_fpr-train_tpr),label='train ks')plt.scatter(train_fpr[i],abs(train_fpr-train_tpr)[i])plt.plot(oft_fpr, oft_tpr,label='out of time roc')plt.plot(oft_fpr, abs(oft_fpr-oft_tpr),label='out of time ks')plt.scatter(oft_fpr[j],abs(oft_fpr-oft_tpr)[j])plt.plot([0,1],[0,1],'p-.')plt.xlabel('FPR')plt.ylabel('TPR')plt.legend(loc='best')plt.title('ROC Curve')plt.show() PSI群体稳定性指标# PSI(Population Stability Index)的定义# 群体稳定性指标PSI(Population Stability Index)是衡量模型的预测值与实际值偏差大小的指标。 PSI用于评估模型在训练集和时间外样本集上的稳定性指标。 给予的假设是：如果模型是稳定和有效的，那么在几个数据集上人群的分布也应该是稳定的 风控行业常用PSI指标衡量模型或者特征的稳定性，同时也是一种模型效果监控的指标。 PSI = sum[（实际占比-预期占比）* ln（实际占比/预期占比）] 举例： 比如训练一个logistic回归模型，预测时候会有个概率输出p。 以dev为基准，dev上的输出设定为p1，将这个概率值从小到大排序后10等分（实际中等频分箱优于等距分箱）。 现在用这个模型去对新的样本（val或oft）进行预测，预测结果叫p2，按p1的区间也划分为10等分。 实际占比就是p2上在各区间的用户占比，预期占比就是p1上各区间的用户占比。【如果模型是有效的，那么根据p1的区间划分出来的人群占总比和p2划分出来的各个区间的人群占总比应该是大体一致的】 意义就是如果模型跟稳定，那么p1和p2上各区间的用户应该是相近的，占比不会变动很大，也就是预测出来的概率不会差距很大。 仔细想想，PSI就像是两个分布直方图，求了差值后再求和！越小说明模型在不同数据集上预测结果趋于一致，越稳定！ 一般认为PSI小于0.1时候模型稳定性很高，一般认为0.2以下还ok。0.1-0.25一般，大于0.25模型稳定性差，建议重做。 分箱每一箱的样本要大致相同，否则若某一箱太少，造成PSI计算时里面的占比会波动，带来不准确 PS：除了按概率值大小等距十等分外，还可以对概率排序后按数量十等分，两种方法计算得到的psi可能有所区别但数值相差不大。 应用： 样本外测试： 针对不同的样本测试一下模型稳定度，比如训练集与测试集，也能看出模型的训练情况，我理解是看出模型的方差情况。 时间外测试： 测试基准日与建模基准日相隔越远，测试样本的风险特征和建模样本的差异可能就越大，因此PSI值通常较高。至此也可以看出模型建的时间太长了，是不是需要重新用新样本建模了。 模型监控： 模型部署上线后，模型的拒绝率越高，线上的KS越低，也就无法体现模型的真实效果，所以常用PSI值监控线上模型与线下模型的差异，从侧面展示模型真实效果与预期效果的偏差。 特征评估： 将PSI上面第一步的十等分逻辑换成特征取值的分布，对特征进行分箱 在val、oft，或者跨时间段计算PSI 可以评估这个特征随着时间的推移，他的分布是否稳定，考虑是否能将特征代入模型。","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"}]},{"title":"给hexo的博文添加图床、博文加密","slug":"hexo-blog-img-password","date":"2018-01-07T07:59:42.000Z","updated":"2020-05-23T08:22:38.607Z","comments":true,"path":"article/hexo-blog-img-password.html","link":"","permalink":"https://blog.sofunnyai.com/article/hexo-blog-img-password.html","excerpt":"","text":"关于博客的图片 关于博文加密 关于博客的图片# 1.少量图片可以丢到根文件的source/images文件夹下，算是可以解决。 2.多一点的图片可以丢到当前文件的同目录同名文件夹下。在_config.yml打开这个注释post_asset_folder: true 就会在hero new xxx的时候自动创建xxx目录放静态资源。（但是费劲，url变化后有问题） hexo新版不支持![img](image_url)的正确渲染了，无法保证路径可以渲染成功。官方推荐用他的标签: 123&#123;% asset_path slug %&#125;&#123;% asset_img slug [title] %&#125;&#123;% asset_link slug [title] %&#125; 更多见 https://hexo.io/zh-cn/docs/asset-folders.html 但是这种方式不是标准markdown语法，无法在我们的markdown编辑器里面正确显示，真是太low了！ 3.所以我建议使用图床神器：ipic、和picgo 戳这里：https://github.com/Molunerfinn/PicGo 大体原理就是可以一键自动上传图片到github或者gitee图床，妈妈再也不用担心我们的图片了。下面是picgo和typora编辑器配合的配置，爽到爆： 关于博文加密# 个别私有博文不方便暴露，需要给博文添加密码，因为我们没有动态服务器去存储密码，只能是在渲染的时候加密，浏览的时候前台js解密。 经过搜寻找到一个工具叫做hexo-blog-encrypt，在Github这里。它会使用对称加密把博文的内容真正加密成密文，只有用户输入密码正确后才会解密成功。 中文介绍在这里，使用起来也很简单，在hexo的主目录安装加密插件： 1cnpm install --save hexo-blog-encrypt 安装完插件后，在hexo的主目录配置一下这个插件_config.yml，添加加密的安全配置： 1234567# Securityencrypt: # hexo-blog-encrypt abstract: 本文为加密的内容, 请输入密码后查看。 message: Password Here： template: &lt;div id=\"hexo-blog-encrypt\" data-wpm=\"&#123;&#123;hbeWrongPassMessage&#125;&#125;\" data-whm=\"&#123;&#123;hbeWrongHashMessage&#125;&#125;\"&gt;&lt;div class=\"hbe-input-container\"&gt;&lt;input type=\"password\" id=\"hbePass\" placeholder=\"&#123;&#123;hbeMessage&#125;&#125;\" /&gt;&lt;label&gt;&#123;&#123;hbeMessage&#125;&#125;&lt;/label&gt;&lt;div class=\"bottom-line\"&gt;&lt;/div&gt;&lt;/div&gt;&lt;script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"&#123;&#123;hbeHmacDigest&#125;&#125;\"&gt;&#123;&#123;hbeEncryptedData&#125;&#125;&lt;/script&gt;&lt;/div&gt; wrong_pass_message: wrong password, try again! wrong_hash_message: 抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容. 然后编辑一下博文的模板文件，把密码字段加到头上： 1vim scaffolds/post.md 就像下面这样，password框里如果是空的就不会加密，否则就会加密： 123456789101112131415---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:- tag1- tag2categories:- xxurlname: 修改我xxxx.htmlpassword:---&lt;!--此处生成目录--&gt;&lt;!-- toc --&gt;&lt;!--下面是latex渲染框架katex样式所需的css，不使用latex的话可以删掉--&gt;&lt;link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"&gt; 这样在列表的时候摘要会显示上面的abstract中的内容，输入框提示message消息。","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"},{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"}]},{"title":"Hexo+Github+自定义域名+CDN搭建博客系统（附namesilo优惠码）","slug":"build-a-blog-base-hexo-github","date":"2018-01-06T05:05:26.000Z","updated":"2020-05-23T08:26:59.245Z","comments":true,"path":"article/build-a-blog-base-on-hexo-github.html","link":"","permalink":"https://blog.sofunnyai.com/article/build-a-blog-base-on-hexo-github.html","excerpt":"","text":"Why What How Details 安装Hexo 选择主题 gayhub托管 自定义域名[可选] Others 生成目录 评论管理 关于latex公式显示 在blog根目录给hexo安装hexo-renderer-markdown-it-plus插件 CDN加速[可选] FAQ Why# 之前分别在csdn和cnblogs写了一些文章，csdn的广告越来越过分实在忍不了。然而cnblogs的markdown编辑器又太弱，一直也没什么更新，所以就再造一个轮子。 What# Hexo是个啥，这一套是怎么工作的？ Hexo是一个基于Nodejs的渲染引擎，可以集成多个主题和插件，实现了内容和样式分离，可以根据喜好快速换装。 用户可以撰写一个markdown格式的博客文件，使用Hexo渲染为html格式 然后将html部署到github（或者自有服务器/vps等等） 使用github的pages服务（或者自有服务器的IP）即可访问我们的博客 可选：接着可以用我们的自有域名解析到github的pages服务即可（或者我们服务器的IP） 搭建好了怎么写博客？ 本地写markdown格式，安利下typora，巨好用。 写完执行一个命令会自动渲染成html，再执行一个命令会自动部署到github，相当简单。 How# 把大象关进冰箱需要三步，搭建基于Hexo的博客也需要三步： 安装Hexo，跑起来 搞一个Gayhub的repo，弄一个page.io 搞一个域名，DNS解析即可（如果需要加速，在CDN配置一下） Details# 安装Hexo# 首选需要安装nodejs，安装cnpm 选择操作系统的发行版: https://nodejs.org/en/download/ 我是linux，下载解压，配置环境变量，source一把即可。 windows用户更简单，下载后各种next即可。 mac和linux类似 npm加速，安装cnpm： npm install -g cnpm --registry=https://registry.npm.taobao.org 安装Hexo：cnpm install -g hexo 会自动从gayhub下载hexo并安装 然后就进入目录去配置_conifg.yml,包括博客title、作者、语言等等 运行 hexo s，然后去http://localhost:4000就能看到了。默认样式会有点丑，别着急看下一节。 选择主题# 先戳这里，官方有巨多主题： https://hexo.io/themes/ 也可以去gayhub自己搜hexo-theme即可，也有n多 我一个老年大叔，选择了一个简单一点的主题hexo-theme-pure，这个https://github.com/cofess/hexo-theme-pure 主题的中文说明：https://github.com/cofess/hexo-theme-pure/blob/master/README.cn.md 按照主题说明，clone到hexo的theme文件夹内，然后修改一下hexo的_config.yml文件中的主题theme: pure 按照主题说明，安装主题渲染所需的nodejs插件。无非就是几个cnpm install xxxx即可 按照主题说明，配置主题的配置文件，一般在主题文件夹./hexo/theme/pure下的_config.yml（无非是颜色、元素是否显示、布局之类的），很简单看一眼就知道。 运行渲染hexo clean &amp;&amp; hexo g &amp;&amp; hexo s，分别是清理、生成、运行，然后再去http://localhost:4000看一眼，主题就生效了。 gayhub托管# 我们hexo g渲染生成的静态文件在public文件夹内，需要把它丢到一个web容器内运行就可以了。gayhub提供githubpages服务可以托管静态文件，并可以http浏览。 所以去github新建一个repo，repo名字为xxxx.github.io,这个xxxx必须和你的github用户名一致! 然后回到hexo中配置deploy模式为git，配置仓库地址为上面的repo地址。更多参见https://hexo.io/zh-cn/docs/github-pages 配置完毕hexo d输入github账号密码即可push到服务器（如果本机没有保存，或者服务器配置秘钥的话，具体github配置公钥上网查找） 然后可以访问我们的博客了https://xxxx.github.io` 自定义域名[可选]# 上面虽然博客可以访问了，但是github.io看起来有点low，而且国内访问速度也很慢。 所以，我建议撸一个域名，挂博客，搞微信开发，内网穿透，扶墙等等用处多多。。。而且最好是境外服务商域名，境内的域名要备案、年检，非常非常麻烦。 目前最便宜的是戳这个：namesilo官网，优势： 他家的.com域名只要7.99刀，.xyy和.online域名只要0.99刀，简直白送！关键是续费便宜没有坑，别家有首年很便宜，后面续费巨贵的。 永久免费的whois隐私保护，其他家这个功能还要收费。 支持支付宝收款，不用别家还要信用卡或者PayPal 所以戳链接进去官网： www.namesilo.com/ 进入官网后，右上角注册sign up，输入用户名，邮箱，密码即可。 然后register，选择域名进行注册，第一次会让你填写信息（以免域名丢失找回，或者服务商后续通知一些域名相关事项） 输入你想注册的域名，搜索，看看有没有被注册过： 假如你选择的没有被占用。点击下面的add加入购物车，然后checkout结算,我这里用.com的8.99刀域名举例（你也可以用下面0.99刀的，简直便宜到几乎白送！） 结算页面，按图上选择即可，然后下面的打折码输入**cutoff** ，点击submit即可享受打折优惠！ 下一步就是支付宝扫码付款即可。 付完款去account个人中心，点击domain manager域名管理，会出来你的域名列表。点击设置dns 设置DNS,点击CNAME，会出来一条解析，可以根据喜好设置为www的主域名，还是blog.xxx.com的二级域名。目标设置我们上面个人的xxxxxx.github.io，提交即可。 搞定你以为大功告成了？还需要在github的repo里面设置这个域名，否则github会阻止域名解析，导致404。看下一节 github配置域名： 在那个custom domain填写你的域名，save一下 然后在你本地的hexo/source目录下创建个CNAME文件夹，写上你的域名 最后，重新hexo g &amp; hexo d 此时即可用我们的域名访问。 Others# 生成目录# 为博客生成toc目录 使用插件cnpm install hexo-toc --save 然后配置一下最大深度等 123456789toc: maxdepth: 3 class: toc slugify: transliteration decodeEntities: false anchor: position: after symbol: '#' style: header-anchor 评论管理# 关于博客的评论，一般来说是需要一个数据库的。但是我们是纯静态服务，所以有人搞了类似gitalk、gitment 这样的东西。只用前台引用js即可，一般都不用我们管，主题已经集成好了。只用按照说明进行配置几个参数即可。 关于latex公式显示# latex会显示失败，按照pure主题的解决方案： 数学公式# Hexo默认使用&quot;hexo-renderer-marked&quot;引擎渲染网页，该引擎会把一些特殊的markdown符号转换为相应的html标签 解决方案# 解决方案有很多，可以网上搜下，为了节省大家的时间，这里只提供亲身测试过的方法。 更换Hexo的markdown渲染引擎，hexo-renderer-markdown-it-plus引擎替换默认的渲染引擎hexo-renderer-marked即可。 在blog根目录给hexo安装hexo-renderer-markdown-it-plus插件# 123cnpm un hexo-renderer-marked --save # 卸载cnpm i hexo-renderer-markdown-it-plus --save # 安装新的渲染框架cnpm i markdown-it-katex --save # 安装katex渲染latex 配置# 安装插件后，如果未正常渲染LaTeX数学公式，在博客根目录配置文件_config.yml中添加 12345678910111213141516markdown_it_plus: highlight: true html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: “”‘’ plugins: - plugin: name: markdown-it-katex enable: true - plugin: name: markdown-it-mark enable: false 文章启用mathjax（不用设置true也可以）# 12title: Hello Worldmathjax: true 按照上面操作了还是不行，元素错位。看了下面这个解决了： 还错位或者显示元素不准的话，需要引入一个katex的css# 1&lt;link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"&gt; https://blog.csdn.net/u014792304/article/details/78687859 katex和latex大部分命令是相通的，不同的略微差别见下面： https://khan.github.io/KaTeX/function-support.html CDN加速[可选]# 想继续折腾访问速度的往下看： 首先，不推荐国内的CDN供应商和域名解析商，因为他们动不动就有合规要求。会折腾客户去备案（不是所有的） 然后，推荐cloudflare，也很简单，注册一个账号，在namesilo里面把CDN服务迁移到cloudflare即可。上网搜索巨多资料。 FAQ# 为啥配置好了域名无法访问？ 等待域名解析，尝试DNS那里的TTL设置小一点，刷新本地DNS缓存。 为啥速度不一般？ 因为是国外DNS，可能第一次访问有点慢。有精力的尝试迁移到cloudflare，还有CDN加速，https，爽歪歪。戳这里：https://www.cloudflare.com/","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"},{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"}]}],"categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"},{"name":"network","slug":"network","permalink":"https://blog.sofunnyai.com/categories/network/"},{"name":"IO","slug":"IO","permalink":"https://blog.sofunnyai.com/categories/IO/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/tags/risk/"},{"name":"strategy","slug":"strategy","permalink":"https://blog.sofunnyai.com/tags/strategy/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"},{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"运维","slug":"运维","permalink":"https://blog.sofunnyai.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"基础","slug":"基础","permalink":"https://blog.sofunnyai.com/tags/%E5%9F%BA%E7%A1%80/"},{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"}]}