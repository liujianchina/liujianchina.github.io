{"meta":{"title":"树先生的金融风控工程师博客","subtitle":"","description":"","author":"树先生","url":"https://blog.sofunnyai.com","root":"/"},"pages":[{"title":"categories-博文分类","date":"2018-03-21T08:35:01.000Z","updated":"2020-05-20T08:46:34.397Z","comments":true,"path":"categories/index.html","permalink":"https://blog.sofunnyai.com/categories/index.html","excerpt":"","text":""},{"title":"tags-标签文章","date":"2018-03-21T08:41:37.000Z","updated":"2020-05-20T08:46:25.013Z","comments":true,"path":"tags/index.html","permalink":"https://blog.sofunnyai.com/tags/index.html","excerpt":"","text":""},{"title":"about-关于我","date":"2018-03-21T08:41:44.000Z","updated":"2020-05-20T08:46:47.021Z","comments":true,"path":"about/index.html","permalink":"https://blog.sofunnyai.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"IO基础：socket和TCP","slug":"selector-Epoll","date":"2018-09-12T12:12:26.000Z","updated":"2020-05-22T07:38:16.341Z","comments":true,"path":"article/io-basic-socket-tcp.html","link":"","permalink":"https://blog.sofunnyai.com/article/io-basic-socket-tcp.html","excerpt":"","text":"IO# OSI基础模型# 提到IO，首先是OSI参考模型，计算机网络基础，一共七层 这7层是一个虚的东西，是一个规范。TCP/IP协议给精简到4层，把上面的应用层-表示层-会话层统一归结到新的应用层是用户称，把下面的传输控制层-网络层-链路层-物理层视为内核层。 OSI七层网络模型 TCP/IP四层概念模型 对应网络协议 应用层（Application） 应 HTTP、TFTP, FTP, NFS, WAIS、SMTP 表示层（Presentation） 用 Telnet, Rlogin, SNMP, Gopher 会话层（Session） 层 SMTP, DNS 传输层（Transport） 传输层 TCP, UDP 网络层（Network） 网络层 IP, ICMP, ARP, RARP, AKP, UUCP 数据链路层（Data Link） 数据 FDDI, Ethernet, Arpanet, PDN, SLIP, PPP 物理层（Physical） 链路层 IEEE 802.1A, IEEE 802.2到IEEE 802.11 linux命令测试讲解TCP# 创建一个到baidu的文件描述符（内核层）# 执行一个bash命令创建一个到baidu的socket，放到当前进程的8号文件描述符中：exec 8&lt;&gt; /dev/tcp/www.baidu.com/80 linux一切皆文件，上面面创建了一个“8”文件，是一个socket指向了百度， 8是文件描述符fd(就像代码的变量)，&lt;&gt;是一个双向输入输出流，可以看到 echo $$ 16199 # 打印当前命令行的进程号 # 也可以ps -ef 然后grep出来 tree 16199 9368 0 4月15 pts/1 00:00:01 /bin/bash 123456789101112- 可以去当前进程的目录看一眼- &#96;&#96;&#96;bash cd &#x2F;proc&#x2F;16199&#x2F;fd # 进入当前进程的fd目录 ls # 看一眼 lrwx------ 1 tree tree 64 5月 21 18:31 0 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 1 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 2 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 255 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 8 -&gt; &#39;socket:[1037956]&#39; # 每个进程都有0,1,2三个fd文件描述符。分别是stdin、stdout、stderr 向文件描述符中写东西通信（用户层态）# 123456echo -e \"GET / HTTP/1.0\\n\" 1&gt;&amp; 8 # 打印一个字符串到标准输出（所以是1）重定向&gt;到文件描述符(所以是&amp;，重定向到文件不用&amp;)8中cat 0&lt;&amp; 8# 从文件描述符(所以是&amp;，文件的话不用&amp;)8中标准输入&lt;# 。。。。。下面打印一大堆百度的html 传输控制层TCP协议# 什么是socket套接字？# ip+port &lt;---------&gt; ip+port 是一【套】，客户端和服务端的ip+port 4个要素决定唯一的一个socket 客户端的ip是B，可以和baidu建立多少个链接？65535个 此时客户端B还能继续和163建立链接吗？也可以继续再次建立65535个，因为socket是【一套】4个要素，server换了就是另外一个socket了。 对于类似如下netstat -anp出来的socket链接，每一个established都有一个文件描述符(fd目录下)数字和他对应并交给一个进程。程序只用和这个文件描述符进行读写就可以进行socket通信了。【如果多个socket对应一个进程：就是多路复用器selector或者epoll】 什么是TCP协议？# 是一个面向连接的可靠的传输协议。因为三次握手保证了可靠传输。 三次握手的细节？# C-----------syn-----------&gt;S # “我要跟你连接了，标识是syn” C&lt;----------syn+ack-------S # “好的，我知道了” 让客户端知道Server已经响应了 C------------ack-----------&gt;S # 好的，我知道你知道了。让Server知道发出的消息客户端收到了 三次握手完毕后，双方才有资源开辟，才能开始传输。 tcpdump 四次分手的细节，为啥要四次？# 因为握手是三次，开辟了资源。分手释放资源是双方的，所以是四次（双方都要同时释放，不能轻易单方面释放了） 分手的C只是先说断开的人 C-----------fin-----------&gt;S # “我要跟你分手了，标识是fin”给Server一个结束标识 C&lt;----------fin+ack-------S # “好的，我知道了” 让客户端知道Server已经响应了（但是我要确认一下真的没事儿了） C&lt;-----------fin------------S # “好吧，分吧，标识是fin”确认真的没事儿了，给客户端一个结束标识 C------------ack-----------&gt;S # “好的，”让Server知道发出的消息客户端收到了 三次握手和四次分手是不可分割的最小粒度# LVS作为一个工作在四层的负载均衡，是无法知晓数据包的具体内容的！ LVS是否可以随意把数据给后端进行负载？-可以负载，但是受制于协议约束！ C ----- lvs ----- S1/S2 的时候，LVS必须要把握手的三次给到一对C—S，不能给到另外一个S，否则无法建立连接。 网络和路由# 网络设置要ip、gateway、mask、dns4个东西","categories":[{"name":"IO","slug":"IO","permalink":"https://blog.sofunnyai.com/categories/IO/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"基础","slug":"基础","permalink":"https://blog.sofunnyai.com/tags/%E5%9F%BA%E7%A1%80/"}]},{"title":"深入理解woe和iv","slug":"woe-iv","date":"2018-01-14T03:10:14.000Z","updated":"2020-05-22T07:41:28.841Z","comments":true,"path":"article/woe-iv.html","link":"","permalink":"https://blog.sofunnyai.com/article/woe-iv.html","excerpt":"","text":"WOE(Weight of Evidence) 证据权重 WOE的定义 Woe公式理解 WOE回顾： IV值：可以认为是WOE的加权 计算woe和IV的步骤 计算注意点 WOE和IV的比较----为什么不用WOE，而是用IV值 通用WOE计算实现 WOE(Weight of Evidence) 证据权重# https://blog.csdn.net/kevin7658/article/details/50780391 https://zhuanlan.zhihu.com/p/80134853 https://www.cnblogs.com/hanxiaosheng/p/9831838.html https://www.cnblogs.com/hanxiaosheng/p/9831964.html https://blog.csdn.net/PbGc396Dwxjb77F2je/article/details/99687952 WOE的定义# WOE是一种对原始自变量进行编码的格式，可以屏蔽极值增强鲁棒性。（树模型一般只对离散变量进行编码，对极值不敏感） 要对一个变量进行WOE编码，需要首先把这个变量进行分组处理/离散化处理（等宽切割，等频切割，卡方分箱，或者利用决策树来切割）。 分组后，对于第i组，WOE的计算公式如下： woei=lnpyipni=lnpy1py0=ln(BadiBad/GoodiGood)=ln(BadiBad)−ln(GoodiGood)woe_i = ln\\frac{p_{yi}}{p_{ni}} = ln\\frac{p_{y1}}{p_{y0}} = ln(\\frac{Bad_i}{Bad}/\\frac{Good_i}{Good}) = ln(\\frac{Bad_i}{Bad})-ln(\\frac{Good_i}{Good}) woe​i​​=ln​p​ni​​​​p​yi​​​​=ln​p​y0​​​​p​y1​​​​=ln(​Bad​​Bad​i​​​​/​Good​​Good​i​​​​)=ln(​Bad​​Bad​i​​​​)−ln(​Good​​Good​i​​​​) 其中：pyi为坏样本占所有坏样本的比例，py0好样本占所有好样本的比例； Bad为坏样本总数，Badi为变量i对应的坏样本个数，Good为好样本总数，Goodi为变量i对应的好样本个数 ； 将模型目标变量y为1记为违约用户（坏样本），对于目标变量为0记为正常用户（好样本） Woe公式理解# 基础模式 woei=ln(BadiBad)−ln(GoodiGood) woe_i = ln(\\frac{Bad_i}{Bad})-ln(\\frac{Good_i}{Good}) woe​i​​=ln(​Bad​​Bad​i​​​​)−ln(​Good​​Good​i​​​​) 即 WOE = ln (第i个分箱的坏人数 / 总坏人数) - ln (第i个分箱的好人数 / 总好人数) 此时可以理解为：每个分箱里的坏人(响应)分布相对于好人(未响应)分布之间的差异性。 变换模式 woei=ln(BadiGoodi)−ln(BadGood)woe_i = ln(\\frac{Bad_i}{Good_i})-ln(\\frac{Bad}{Good}) woe​i​​=ln(​Good​i​​​​Bad​i​​​​)−ln(​Good​​Bad​​) WOE = ln (第i个分箱的坏人数 / 第i个分箱的好人数) - ln (总坏人数 / 总好人数) 此时可以理解为：每个分箱里的坏好比(Odds)相对于总体的坏好比之间的差异性。 WOE回顾：# 当前分组中，差异越大，响应的比例越大，WOE值越大； 反应的是特征的重要性，woe的绝对值越大，说明越重要。 当前分组WOE的正负，由当前分组响应和未响应的比例，与样本整体响应和未响应的比例的大小关系决定，当前分组的比例小于样本整体比例时，WOE为负，当前分组的比例大于整体比例时，WOE为正，当前分组的比例和整体比例相等时，WOE为0。 WOE的取值范围是全体实数。(所以就不方便，需要IV缩放) WOE其实描述了变量当前这个分组，对判断个体是否会响应（或者说属于哪个类）所起到影响方向和大小，当WOE为正时，变量当前取值对判断个体是否会响应起到的正向的影响，当WOE为负时，起到了负向影响。而WOE值的大小，则是这个影响的大小的体现。 做完woe之后，LR系数不再代表特征的重要程度。 woe后LR的时候要保证系数全都是正数！ woe的符号代表特征对模型贡献的方向，系数如果不是正数就会改变这个方向。 但是做BiVar的时候已经分析了这个woe特征的贡献方向，如果LR再负数会扭曲推翻之前BiVar的分析。 优点：数值型转化为WOE可以增强鲁棒性，屏蔽极值的影响（极小值和极大值也被分组了） 但是树模型对极值不敏感，只用处理字符型即可 note：如果特征做了WOE，那么LR的系数不能代表特征重要性权重。（WOE绝对值大小已经是特征重要性了，LR的系数仅仅是拟合系数而已） 核心——分箱逻辑： 实现WOE最重要的是分箱逻辑，不同的分箱会带来不同的WOE。金融常使用“基于负样本占比差异最大化”原则来分箱 一般是5箱内最好，通常最多不超过10箱 每一箱的负样本占比差值尽可能大（箱合并原则） 每一箱的样本量不少于总体5%（不要太小，不要小于三五百个样本） 通过控制划分后的总箱数，来迭代进行分箱合并 IV值：可以认为是WOE的加权# 某个分箱的IV值： IVi=(pyi−pni)∗WOEi=(BadiBadt−GoodiGoodt)∗WOEi=(BadiBadt−GoodiGoodt)∗ln(BadiBadt/GoodiGoodt)IV_i =(p_{yi}-p_{ni}) * WOE_i= (\\frac{Bad_i}{Bad_t}-\\frac{Good_i}{Good_t}) * WOE_i = (\\frac{Bad_i}{Bad_t}-\\frac{Good_i}{Good_t}) * ln(\\frac{Bad_i}{Bad_t}/\\frac{Good_i}{Good_t}) IV​i​​=(p​yi​​−p​ni​​)∗WOE​i​​=(​Bad​t​​​​Bad​i​​​​−​Good​t​​​​Good​i​​​​)∗WOE​i​​=(​Bad​t​​​​Bad​i​​​​−​Good​t​​​​Good​i​​​​)∗ln(​Bad​t​​​​Bad​i​​​​/​Good​t​​​​Good​i​​​​) 有了一个变量各分组的IV值，我们就可以计算整个变量的IV值： IV=∑inIViIV = \\sum_i^n{IV_i} IV=​i​∑​n​​IV​i​​ n是分箱的数量 对于变量的一个分组，这个分组的响应和未响应的比例与样本整体响应和未响应的比例相差越大，IV值越大，否则，IV值越小； 极端情况下，当前分组的响应和未响应的比例和样本整体的响应和未响应的比例相等时，IV值为0； IV值的取值范围是[0,+∞) ，且，当当前分组中只包含响应客户或者未响应客户时，IV = +∞。 故可以计算多个特征的IV值，按照从大到小排序来决定采用哪些特征更容易响应。（类似信息增益或者基尼指数的感觉） IV比如要大于0.05才比较好用 谨慎的时候会要求IV大于0.02就可以先留着，也就是说IV在0.02-0.5之间 超过0.5的特征会被直接拿去作为策略-------------&gt;IV太大的值可能会把模型其他特征的信息覆盖掉，也可能会造成过拟合。（如果这个特征以后抖动，造成线上效果波动） 计算woe和IV的步骤# step 1. 对于连续型变量，进行分箱（binning），可以选择等频、等距，或者自定义间隔；对于离散型变量，如果分箱太多，则进行分箱合并。 step 2. 统计每个分箱里的好人数(bin_goods)和坏人数(bin_bads)。 step 3. 分别除以总的好人数(total_goods)和坏人数(total_bads)，得到每个分箱内的边际好人占比(margin_good_rate)和边际坏人占比(margin_bad_rate)。 step 4. 计算每个分箱里的WOE [公式] step 5. 检查每个分箱（除null分箱外）里woe值是否满足单调性（bivar），若不满足，返回step1。注意⚠️：null分箱由于有明确的业务解释，因此不需要考虑满足单调性。 step 6. 计算每个分箱里的IV，最终求和，即得到最终的IV。 备注：好人 = 正常用户，坏人 = 逾期用户 计算注意点# 分箱时需要注意样本量充足，保证统计意义。 若相邻分箱的WOE值相同(非常相近)，则将其合并为一个分箱。 当一个分箱内只有好人或坏人时（会出现∞），可对WOE公式进行修正如下： Woei=ln(Badi+0.5Badt+0.5/GoodiGoodt)Woe_i = ln(\\frac{Bad_i+0.5}{Bad_t+0.5}/\\frac{Good_i}{Good_t}) Woe​i​​=ln(​Bad​t​​+0.5​​Bad​i​​+0.5​​/​Good​t​​​​Good​i​​​​) 在实践中，我们还需跨数据集检验WOE分箱的单调性。如果在训练集上保持单调，但在验证集和测试集上发生翻转而不单调，那么说明分箱并不合理，需要再次调整。（BIVAR） 或者当分箱中只有好人或坏人的时候，也可以这么做： 如果可能，直接把这个分组做成一个规则，作为模型的前置条件或补充条件；（即不允许这种分箱存在） 重新对变量进行离散化或分组，使每个分组的响应比例都不为0且不为100%，尤其是当一个分组个体数很小时（比如小于100个），强烈建议这样做，因为本身把一个分组个体数弄得很小就不是太合理。 如果上面两种方法都无法使用，建议人工把该分组的响应数和非响应的数量进行一定的调整。如果响应数原本为0，可以人工调整响应数为1，如果非响应数原本为0，可以人工调整非响应数为1.（或者按照上面进行修正，分子分母都加0.5） WOE和IV的比较----为什么不用WOE，而是用IV值# 变量各分组的WOE和IV都隐含着这个分组对目标变量的预测能力这样的意义，但是有以下问题： 1. 各个组的WOE有正有负 解释： 假设构造一个$ WOE=\\sum_i^n{WOE_i} ，那么因为里面的WOE_i$有正有负，所以求和不好表征。 2.每个组的WOE没有考虑到这个各个组在总体的占比 解释： 即使构造一个WOE=∑in∣WOEi∣WOE=\\sum_i^n{|WOE_i|}WOE=∑​i​n​​∣WOE​i​​∣规避上面的负数问题，但是每个组WOEiWOE_iWOE​i​​的信息含量（泛化能力？）是不相同的，比如某个组WOEiWOE_iWOE​i​​很高但是这个组只有很少的样本，把他直接和另外一个很多样本但很低的WOEjWOE_jWOE​j​​相加是很不合适的。 假设某特征A分两组，从这个表我们可以看到，变量取1时，响应比达到90%，对应的WOE很高，但对应的IV却很低，原因就在于IV在WOE的前面乘以了一个系数(pyi−pni)(p_{yi}-p_{ni})(p​yi​​−p​ni​​) 而这个系数很好的考虑了这个分组中样本占整体样本的比例，比例越低，这个分组对变量整体预测能力的贡献越低。 相反，如果直接用WOE的绝对值加和，会得到一个很高的指标，这是不合理的。 通用WOE计算实现# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187# -*- coding: utf-8 -*-import mathimport pandas as pdimport numpy as npfrom pandas import DataFramefrom pandas.core.dtypes import dtypesfrom pandas.core.dtypes.common import is_numeric_dtypefrom sklearn.linear_model import LogisticRegressionfrom sklearn.tree import DecisionTreeRegressor# 自定义实现的离散型变量woeclass charWoe(object): def __init__(self, datases: dict, dep, weight, vars: list): # 数据字典&#123;'dev':xxx,'val':xxx,'off':xxx&#125; 训练集，测试集，时间外样本集 3个dataframe self.datases = datases self.devf = datases.get('dev', '') self.valf = datases.get('val', '') self.offf = datases.get('off', '') self.dep = dep # 标签 self.weight = weight # 样本权重 self.vars = vars # 特征名 self.nrows, self.ncols = self.devf.shape # 样本数，特征数 def char_woe(self): # 得到每一类样本的个数，且加入平滑项是的bad和good都不为0 dic = dict(self.devf.groupby(self.dep).size()) # 根据标签去group，变成&#123;1:xxx,0:yyy&#125;字典 good = dic.get(0, 0) + 1e-10 # 平滑防止组内为0，计算失败 bad = dic.get(1, 0) + 1e-10 # 对每一个特征进行处理 for col in self.vars: # df[[sex,bad]].groupby(['sex','bad']).size() 会得到一个series， # 直接转成字典：&#123;(男, 0): 10553, (男, 1): 518, (女, 0): 233, (女, 1): 3&#125; # key的第一个代表特征值，第二个代表标签值 data = dict(self.devf[[col, self.dep]].groupby([col, self.dep]).size()) ''' 特征值+分类组合超过100的时候，跳过当前取值 假设二分类，dep是0,、1，则这个特征只能有50个特征值 &#123;(col特征值A,0):25,(col特征值A,1):10,(col特征值B,0):33,(col特征值B,1):21...&#125; 因为特征值过多时，WOE分箱效率低，建议进行特征截断 出现频率过低的特征就统一赋值，放到同一个箱里 ''' if len(data) &gt; 100: print(col, '有太多的特征值，建议手动进行特征截断，即将跳过此特征...') continue # 打印特征取取值个数 print('特征【%s】的取值个数是【%d】' % (col, len(data))) dic = dict() # &#123;(男, 0): 10553, (男, 1): 518, (女, 0): 233, (女, 1): 3&#125; # key的第一个代表特征值，第二个代表标签值 for (k, v) in data.items(): fea_value, dp = k # 拿出key中的特征值和标签(fea_value=男，dp=0，v=10553) dic.setdefault(fea_value, &#123;&#125;) # 给对应key设置为一个空字典（如果没有找到的话，找到的话说明之前已经设置过了） #&#123;(男, 0): 10553, (男, 1): 518&#125; ==&gt; &#123;男:&#123;1 = 518，0 = 10553&#125; , 女:&#123;...&#125; &#125; dic[fea_value][int(dp)] = v # 字典中嵌套字典 for(k, v) in dic.items(): # 计算cnt和badrate # 循环上面的嵌套字典，k=男，v=&#123;1 = xxx，0 = yyy&#125;。 # 拿出内部嵌套的字典k1 = 1 v1=xxx,生成---&gt;：&#123;‘男’：&#123; '0': 10553, '1': 518&#125;&#125; dic[k] = &#123;str(int(k1)):v1 for (k1, v1) in v.items()&#125; # 所有正负样本的和v.values(): [10553,518] dic[k]['cnt'] = sum(v.values()) # 4舍5入求bad_rate bad_rate = round(v.get(1,0)/dic[k]['cnt'], 5) dic[k][\"bad_rate\"] = bad_rate # 利用定义的函数进行合并分箱。 dic=&#123;'男': &#123;'cnt': xxx, '0': yy, '1': zz, 'bad_rate': 0.xx&#125;, 'B': &#123;'cnt': xxx, '0': yyy, '1': zz, 'bad_rate': 0.zz&#125;&#125; dic = self.combine_box_char(dic) # 对每个特征计算WOE和IV值 for (k,v) in dic.items(): a = v.get('0', 1) / good+1e-10 b = v.get('1', 1) / bad+1e-10 dic[k]['Good'] = v.get('0',0) dic[k]['Bad'] = v.get('1',0) # 下面两个是 a/b 还是 b/a？ 按照定义应该是ln(pi/pn) = ln(p_bad/p_good)? dic[k]['woe'] = round(math.log(b/a),5) dic[k]['iv'] = round((b-a)*dic[k]['woe'],5) ''' 按照分箱后的点进行分割， 计算得到每一个特征值的WOE值， 将原始特征名加上'_woe'后缀，并赋予WOE值。 ''' for (klis, v) in dic.items(): # 把分箱合并后的key切开 for k in str(klis).split(','): # 数字类型处理一下 if is_numeric_dtype(self.devf[col]): k = float(k) if '.' in k else int(k) # 训练集进行替换 self.devf.loc[self.devf[col] == k, \"%s_woe\" % col] = v[\"woe\"] self.devf.loc[self.devf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 测试集进行替换 if not isinstance(self.valf, str): self.valf.loc[self.valf[col] == k,\"%s_woe\" % col] = v[\"woe\"] self.valf.loc[self.valf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 跨时间验证集进行替换 if not isinstance(self.offf, str): self.offf.loc[self.offf[col] == k,\"%s_woe\" % col] = v[\"woe\"] self.offf.loc[self.offf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 返回新的字典，其中包含三个数据集。 return &#123;\"dev\": self.devf, \"val\": self.valf, \"off\": self.offf&#125; def combine_box_char(self, dic): ''' 实施两种分箱策略（规则）： 1.不同箱之间负样本占比(bad_rate)差异最大化。----各个特征值按照badrate从小到大排序，分别用后面一个减去前面每一个，计算badrate差值。找到差值最小的两箱合并之 2.每一箱的样本量不能过少。----当有某箱样本小于总样本的0.05，或总箱数&gt;5的时候，还是按照badrate差异最大化原则：按badrate排序后，把最小的一箱和前后比较，与差值较小的一箱合并 :param dic: 等待分箱的数据 :return: ''' # 首先合并至10箱以内。按照每一箱负样本占比差异最大化原则进行分箱。----各个特征值按照badrate从小到大排序，分别用后面一个减去前面每一个，计算badrate差值。找到差值最小的两箱合并之 while len(dic) &gt;= 10: # 拿出所有的特征和badrate，k是特征值，v['bad_rate']是负样本占比 bad_rate_dic = &#123;k:v['bad_rate'] for (k,v) in dic.items()&#125; # 按照负样本占比排序。因为离散型变量是无序的（比如学历、渠道类型） # 可以直接写成负样本占比递增的形式。(所有的dict按照value升序排序) # 得到一堆tuple的list，是(特征值，bad_rate)的一个list bad_rate_sorted = sorted(bad_rate_dic.items(), key=lambda x: x[1]) # 计算每两箱之间的负样本占比差值。 bad_rate_diff = [bad_rate_sorted[i + 1][1] - bad_rate_sorted[i][1] for i in range(len(bad_rate_sorted) - 1)] # 找到差值最小的那个，准备将其进行合并。 min_diff_index = bad_rate_diff.index(min(bad_rate_diff)) # 找到k1和k2，即差值最小的两箱的key. k1, k2 = bad_rate_sorted[min_diff_index][0], bad_rate_sorted[min_diff_index + 1][0] # 得到重新划分后的字典，箱的个数比之前少一 直接改了dic，给他里面插入一个新的分箱。key是两个key的组合！ dic[\"%s,%s\" % (k1, k2)] = dict() # 重新统计新箱的正负样本数（合并两个key的） dic[\"%s,%s\" % (k1, k2)][\"0\"] = dic[k1].get(\"0\", 0) + dic[k2].get(\"0\", 0) dic[\"%s,%s\" % (k1, k2)][\"1\"] = dic[k1].get(\"1\", 0) + dic[k2].get(\"1\", 0) # 重新统计新箱的cnt dic[\"%s,%s\" % (k1, k2)][\"cnt\"] = dic[k1][\"cnt\"] + dic[k2][\"cnt\"] # 重新计算新分箱的bad_rate dic[\"%s,%s\" % (k1, k2)][\"bad_rate\"] = round(dic[\"%s,%s\" % (k1, k2)][\"1\"] / dic[\"%s,%s\" % (k1, k2)][\"cnt\"],5) # 删除之前两个老的分箱 del dic[k1], dic[k2] ''' 结束循环后，箱的个数应该少于10。 下面实施第二种分箱策略规则：每个分箱的样本不能太少！ 将样本数量少的箱合并至其他箱中，以保证每一箱的样本数量不要太少。 ''' # 找出最少样本数的分箱 min_cnt = min([v['cnt'] for (k, v) in dic.items()]) # 当样本数量小于总样本的5%或者总箱的个数大于5的时候，对箱进行合并 【这里的5% 和 5是经验值】 while min_cnt &lt; self.nrows*0.05 or len(dic) &gt; 5: # 可能找到多个符合min_cnt的list，取第一个 min_key = [k for (k,v) in dic.items() if v['cnt'] == min_cnt][0] bad_rate_dic = &#123;k:v['bad_rate'] for (k,v) in dic.items()&#125; # 根据bad_rate升序 bad_rate_sorted = sorted(bad_rate_dic.items(),key=lambda x:x[1]) keys = [item[0] for item in bad_rate_sorted] min_key_index = keys.index(min_key) ''' 不能直接把样本数最小的两个分箱合并，因为 同样想保持合并后箱之间的负样本占比差异最大化。 由于箱的位置不同，按照三种不同情况进行分类讨论。 ''' # 如果是第一箱、第二箱 if min_key_index == 0: k1,k2 = keys[:2] elif min_key_index == len(keys)-1: # 如果是最后一箱，和倒数第二箱合并 k1,k2 = keys[-2:] else: # 如果是中间箱，前后相比和bad_rate值相差最小的箱合并 # 和前面的比 bef_bad_rate = dic[min_key]['bad_rate'] - dic[keys[min_key_index-1]]['bad_rate'] # 后面的当前比（keys是按照bad_rate升序的，不减出负数） aft_bad_rate = dic[keys[min_key_index+1]]['bad_rate'] - dic[min_key]['bad_rate'] if bef_bad_rate &lt;= aft_bad_rate: k1,k2 = keys[min_key_index-1], min_key else: k1,k2 = min_key, keys[min_key_index+1] # 找到k1，k2后合并之，同上 # 新增一个合并后的分箱 dic[\"%s,%s\" % (k1, k2)] = dict() # 重新计算cnt，bad_rate，正负样本数 dic[\"%s,%s\" % (k1, k2)][\"0\"] = dic[k1].get(\"0\", 0) + dic[k2].get(\"0\", 0) dic[\"%s,%s\" % (k1, k2)][\"1\"] = dic[k1].get(\"1\", 0) + dic[k2].get(\"1\", 0) dic[\"%s,%s\" % (k1, k2)][\"cnt\"] = dic[k1][\"cnt\"] + dic[k2][\"cnt\"] dic[\"%s,%s\" % (k1, k2)][\"bad_rate\"] = round(dic[\"%s,%s\" % (k1, k2)][\"1\"] /dic[\"%s,%s\" % (k1, k2)][\"cnt\"], 5) # 删除旧的分箱 del dic[k1], dic[k2] # 重新计算当前最小的箱的样本个数，进入下次循环继续合并分箱 min_cnt = min([v[\"cnt\"] for v in dic.values()]) return dic","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"}]},{"title":"模型评价指标KS和PSI","slug":"ks-psi","date":"2018-01-12T05:21:10.000Z","updated":"2020-05-23T05:31:11.922Z","comments":true,"path":"article/ks_psi.html","link":"","permalink":"https://blog.sofunnyai.com/article/ks_psi.html","excerpt":"","text":"KS指标 KS值定义 回顾TPR(True Positive Rate)和FPR(False Positive Rate) 模型的KS值 KS(Kolmogorov-Smirnov)计算步骤： KS和ROC的区别 模型评价时: PSI群体稳定性指标 PSI(Population Stability Index)的定义 KS指标# KS值定义# 回顾TPR(True Positive Rate)和FPR(False Positive Rate)# 混淆矩阵，横着的P、N是预测结果阳性还是阴性。竖着的是说预测是否正确。 Positive Negtive T TP TN F FP FN TP：预测为正向（P），实际上预测正确（T），即判断为正向的正确率 TN：预测为负向（N），实际上预测正确（T），即判断为负向的正确率 FP：预测为正向（P），实际上预测错误（F），误报率，即把负向判断成了正向 FN：预测为负向（N），实际上预测错误（F），漏报率，即把正向判断称了负向 准确率Accuracy=（TP+TN） / （TP+FP+TN+FN）， 即预测正确的比上全部的数据 精确率、查准率 Precision=TP / （TP+FP），即在预测为正向的数据中，有多少预测正确了 召回率、查全率 Recall=TP / （TP+FN），即在所有正向的数据中，有多少预测出来了 TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。(就是召回率，正样本被召回的比例) 【金融里面，分母是所有的good_cnt】 Recall=TPR=TPTP+FNRecall = TPR = \\frac{TP}{TP+FN} Recall=TPR=​TP+FN​​TP​​ FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。（就是漏掉的阴性或判断错的阳性，占总阴性的比例) 【金融里面，分母是所有的bad_cnt】 FPR=FPFP+TNFPR = \\frac{FP}{FP + TN} FPR=​FP+TN​​FP​​ 更多关于TPR： /02_ml/01_THEORY/00_theory.ipynb#TPR(True-Positive-Rate) 模型的KS值# 最理想的模型，是TPR尽量高而FPR尽量低（召回尽可能多的坏人，漏掉尽可能少的好人），然而任何模型在提高正确预测概率的同时，也会难以避免地增加误判率。 我们训练出来的模型，一般不是直接给出是正类还是负类的结果，给的是为正类的概率，我们还需要选择一个阈值，实例通过模型得到的概率大于阈值，判断为正类，小于阈值判断为负类。也就是说阈值的不同，以上的各个指标的值也是不同的。每一个阈值对应一对TPR和FPR。把阈值看成自变量，以上TPR、和FPR看成因变量，在二维坐标系里面做∣FPT−FPR∣|FPT-FPR|∣FPT−FPR∣关系曲线，这就是KS曲线。 KS曲线实操的时候是可以把将概率的阈值从小到大进行排序，取10%的值为间隔， 同理将10%*k(k=1,…9)处值作为阈值，计算不同的FPR和TPR， 以10%*k（k=1,…9）为横坐标，同时分别以TPR和FPR为纵坐标画出两条曲线就是KS曲线。 KS值是KS曲线的最大值，也就是TPR和FPR差异的最大点 KS值=max(|TPR-FPR|) KS值是在模型中用于区分预测正负样本分隔程度的评价指标。 需要计算每一箱的KS，然后max是在所有分箱的KS上取最大值 一般来说，KS大比较好。但是也不是越大越好，尤其征信行业 业内认为AUC更能体现模型的【整体的】区分能力，但是KS关注的是区分能力的最大值。 我们做的是拒绝模型，关注的是最大值的点取在哪里的。会做一个截断，小于这个值的都拒绝了。关注在最大值之前误杀了多少人。（相比于AUC注重局部而不是全局） KS(Kolmogorov-Smirnov)计算步骤：# KS用于模型风险区分能力进行评估，指标衡量的是好坏样本累计分部之间的差值。 好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强。 KS的计算步骤如下： 计算每个评分区间的好坏账户数。 计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的K-S值。 KS值：是和AUC强相关的，但是样本很小的时候KS大，AUC不一定大。 A卡的KS： 714那种最差的一般也至少要25%， 正常的p2p公司，客户质量稍微好一点会到30%-40%左右。 最好那些有场景的分期产品最多也就不到50%，所以一般是在25%-50%之间。 B卡的KS： 至少也有40%，最高80% 一般60%左右。 各个数据集如dev和oft的KS差值不要太大，否则模型不稳定，跨时间稳定性差。 一般dev和oft的KS差值只能在5%以内，比较求稳的公司要求在3%以内。 正负样本： 逾期样本/正常样本=1%-5%（也有能做到1/1000的） 5%个点就是比较高的了，是很不均衡的。 要是坏账5%，会亏很多钱。badrte 3%以下才可能赚钱。 欺诈样本/正常样本=1/10w 欺诈用户是极少的 https://www.zhihu.com/question/37405102/answer/106668941 KS和ROC的区别# KS值对模型的评价不受样本不均衡问题的干扰，但仅限于模型评价。 模型评价时:# ROC曲线# 描绘的是不同的截断点（判断好人坏人的阈值）时，以FPR和TPR为横纵坐标轴，描述随着截断点的变化，TPR随着FPR的变化。 纵轴：TPR=正例分对的概率 = TP/(TP+FN)，其实就是查全率 横轴：FPR=负例分错的概率 = FP/(FP+TN) 作图步骤： 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）-----这就是截断点依次选取的顺序 按顺序选取截断点，并计算TPR和FPR—也可以只选取n个截断点，分别在1/n，2/n，3/n等位置 连接所有的点（TPR，FPR）即为ROC图 KS值# 作图步骤： 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）-----这就是截断点依次选取的顺序 按顺序选取截断点，并计算TPR和FPR —也可以只选取n个截断点，分别在1/n，2/n，3/n等位置 横轴为样本的占比百分比（最大100%），纵轴分别为TPR和FPR，计算|TPR-FPR|的ks值，可以得到KS曲线 TPR和FPR曲线分隔最开的位置就是最好的“截断点”，最大间隔距离就是KS值，通常&gt;0.2即可认为模型有比较好的预测准确性 123456789101112131415161718192021222324252627282930313233343536# 模型预测会返回概率，两列，第一列是0的概率，第二列是1的概率proba = lr_model.predict_proba(x)proba# train_thresholds 是阈值，每一个阈值对应roc曲线上的一点train_fpr,train_tpr,train_thresholds = roc_curve(y,proba[:,1])train_ks_arr = abs(train_fpr-train_tpr)train_ks = train_ks_arr.max()print('train KS:',train_ks)# 验证集的ksoft_fpr, oft_tpr,oft_thresholds = roc_curve(oft_y, lr_model.predict_proba(oft_x)[:,1])oft_ks_arr = abs(oft_fpr - oft_tpr)oft_ks = oft_ks_arr.max()print('oft KS:',oft_ks)# 最大值ks对应的下标（画图用）i = train_ks_arr.tolist().index(train_ks)j = oft_ks_arr.tolist().index(oft_ks)import matplotlib.pyplot as pltfrom matplotlib import pyplot as pltplt.plot(train_fpr,train_tpr,label='train roc')plt.plot(train_fpr,abs(train_fpr-train_tpr),label='train ks')plt.scatter(train_fpr[i],abs(train_fpr-train_tpr)[i])plt.plot(oft_fpr, oft_tpr,label='out of time roc')plt.plot(oft_fpr, abs(oft_fpr-oft_tpr),label='out of time ks')plt.scatter(oft_fpr[j],abs(oft_fpr-oft_tpr)[j])plt.plot([0,1],[0,1],'p-.')plt.xlabel('FPR')plt.ylabel('TPR')plt.legend(loc='best')plt.title('ROC Curve')plt.show() PSI群体稳定性指标# PSI(Population Stability Index)的定义# 群体稳定性指标PSI(Population Stability Index)是衡量模型的预测值与实际值偏差大小的指标。 PSI用于评估模型在训练集和时间外样本集上的稳定性指标。 给予的假设是：如果模型是稳定和有效的，那么在几个数据集上人群的分布也应该是稳定的 风控行业常用PSI指标衡量模型或者特征的稳定性，同时也是一种模型效果监控的指标。 PSI = sum[（实际占比-预期占比）* ln（实际占比/预期占比）] 举例： 比如训练一个logistic回归模型，预测时候会有个概率输出p。 以dev为基准，dev上的输出设定为p1，将这个概率值从小到大排序后10等分（实际中等频分箱优于等距分箱）。 现在用这个模型去对新的样本（val或oft）进行预测，预测结果叫p2，按p1的区间也划分为10等分。 实际占比就是p2上在各区间的用户占比，预期占比就是p1上各区间的用户占比。【如果模型是有效的，那么根据p1的区间划分出来的人群占总比和p2划分出来的各个区间的人群占总比应该是大体一致的】 意义就是如果模型跟稳定，那么p1和p2上各区间的用户应该是相近的，占比不会变动很大，也就是预测出来的概率不会差距很大。 仔细想想，PSI就像是两个分布直方图，求了差值后再求和！越小说明模型在不同数据集上预测结果趋于一致，越稳定！ 一般认为PSI小于0.1时候模型稳定性很高，一般认为0.2以下还ok。0.1-0.25一般，大于0.25模型稳定性差，建议重做。 分箱每一箱的样本要大致相同，否则若某一箱太少，造成PSI计算时里面的占比会波动，带来不准确 PS：除了按概率值大小等距十等分外，还可以对概率排序后按数量十等分，两种方法计算得到的psi可能有所区别但数值相差不大。 应用： 样本外测试： 针对不同的样本测试一下模型稳定度，比如训练集与测试集，也能看出模型的训练情况，我理解是看出模型的方差情况。 时间外测试： 测试基准日与建模基准日相隔越远，测试样本的风险特征和建模样本的差异可能就越大，因此PSI值通常较高。至此也可以看出模型建的时间太长了，是不是需要重新用新样本建模了。 模型监控： 模型部署上线后，模型的拒绝率越高，线上的KS越低，也就无法体现模型的真实效果，所以常用PSI值监控线上模型与线下模型的差异，从侧面展示模型真实效果与预期效果的偏差。 特征评估： 将PSI上面第一步的十等分逻辑换成特征取值的分布，对特征进行分箱 在val、oft，或者跨时间段计算PSI 可以评估这个特征随着时间的推移，他的分布是否稳定，考虑是否能将特征代入模型。","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"}]},{"title":"给hexo的博文添加图床、博文加密","slug":"hexo-blog-img-password","date":"2018-01-07T07:59:42.000Z","updated":"2020-05-23T08:22:38.607Z","comments":true,"path":"article/hexo-blog-img-password.html","link":"","permalink":"https://blog.sofunnyai.com/article/hexo-blog-img-password.html","excerpt":"","text":"关于博客的图片 关于博文加密 关于博客的图片# 1.少量图片可以丢到根文件的source/images文件夹下，算是可以解决。 2.多一点的图片可以丢到当前文件的同目录同名文件夹下。在_config.yml打开这个注释post_asset_folder: true 就会在hero new xxx的时候自动创建xxx目录放静态资源。（但是费劲，url变化后有问题） hexo新版不支持![img](image_url)的正确渲染了，无法保证路径可以渲染成功。官方推荐用他的标签: 123&#123;% asset_path slug %&#125;&#123;% asset_img slug [title] %&#125;&#123;% asset_link slug [title] %&#125; 更多见 https://hexo.io/zh-cn/docs/asset-folders.html 但是这种方式不是标准markdown语法，无法在我们的markdown编辑器里面正确显示，真是太low了！ 3.所以我建议使用图床神器：ipic、和picgo 戳这里：https://github.com/Molunerfinn/PicGo 大体原理就是可以一键自动上传图片到github或者gitee图床，妈妈再也不用担心我们的图片了。下面是picgo和typora编辑器配合的配置，爽到爆： 关于博文加密# 个别私有博文不方便暴露，需要给博文添加密码，因为我们没有动态服务器去存储密码，只能是在渲染的时候加密，浏览的时候前台js解密。 经过搜寻找到一个工具叫做hexo-blog-encrypt，在Github这里。它会使用对称加密把博文的内容真正加密成密文，只有用户输入密码正确后才会解密成功。 中文介绍在这里，使用起来也很简单，在hexo的主目录安装加密插件： 1cnpm install --save hexo-blog-encrypt 安装完插件后，在hexo的主目录配置一下这个插件_config.yml，添加加密的安全配置： 1234567# Securityencrypt: # hexo-blog-encrypt abstract: 本文为加密的内容, 请输入密码后查看。 message: Password Here： template: &lt;div id=\"hexo-blog-encrypt\" data-wpm=\"&#123;&#123;hbeWrongPassMessage&#125;&#125;\" data-whm=\"&#123;&#123;hbeWrongHashMessage&#125;&#125;\"&gt;&lt;div class=\"hbe-input-container\"&gt;&lt;input type=\"password\" id=\"hbePass\" placeholder=\"&#123;&#123;hbeMessage&#125;&#125;\" /&gt;&lt;label&gt;&#123;&#123;hbeMessage&#125;&#125;&lt;/label&gt;&lt;div class=\"bottom-line\"&gt;&lt;/div&gt;&lt;/div&gt;&lt;script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"&#123;&#123;hbeHmacDigest&#125;&#125;\"&gt;&#123;&#123;hbeEncryptedData&#125;&#125;&lt;/script&gt;&lt;/div&gt; wrong_pass_message: wrong password, try again! wrong_hash_message: 抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容. 然后编辑一下博文的模板文件，把密码字段加到头上： 1vim scaffolds/post.md 就像下面这样，password框里如果是空的就不会加密，否则就会加密： 123456789101112131415---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:- tag1- tag2categories:- xxurlname: 修改我xxxx.htmlpassword:---&lt;!--此处生成目录--&gt;&lt;!-- toc --&gt;&lt;!--下面是latex渲染框架katex样式所需的css，不使用latex的话可以删掉--&gt;&lt;link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"&gt; 这样在列表的时候摘要会显示上面的abstract中的内容，输入框提示message消息。","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"}]},{"title":"Hexo+Github+自定义域名+CDN搭建博客系统（附namesilo优惠码）","slug":"build-a-blog-base-hexo-github","date":"2018-01-06T05:05:26.000Z","updated":"2020-05-23T08:26:59.245Z","comments":true,"path":"article/build-a-blog-base-on-hexo-github.html","link":"","permalink":"https://blog.sofunnyai.com/article/build-a-blog-base-on-hexo-github.html","excerpt":"","text":"Why What How Details 安装Hexo 选择主题 gayhub托管 自定义域名[可选] Others 生成目录 评论管理 关于latex公式显示 在blog根目录给hexo安装hexo-renderer-markdown-it-plus插件 CDN加速[可选] FAQ Why# 之前分别在csdn和cnblogs写了一些文章，csdn的广告越来越过分实在忍不了。然而cnblogs的markdown编辑器又太弱，一直也没什么更新，所以就再造一个轮子。 What# Hexo是个啥，这一套是怎么工作的？ Hexo是一个基于Nodejs的渲染引擎，可以集成多个主题和插件，实现了内容和样式分离，可以根据喜好快速换装。 用户可以撰写一个markdown格式的博客文件，使用Hexo渲染为html格式 然后将html部署到github（或者自有服务器/vps等等） 使用github的pages服务（或者自有服务器的IP）即可访问我们的博客 可选：接着可以用我们的自有域名解析到github的pages服务即可（或者我们服务器的IP） 搭建好了怎么写博客？ 本地写markdown格式，安利下typora，巨好用。 写完执行一个命令会自动渲染成html，再执行一个命令会自动部署到github，相当简单。 How# 把大象关进冰箱需要三步，搭建基于Hexo的博客也需要三步： 安装Hexo，跑起来 搞一个Gayhub的repo，弄一个page.io 搞一个域名，DNS解析即可（如果需要加速，在CDN配置一下） Details# 安装Hexo# 首选需要安装nodejs，安装cnpm 选择操作系统的发行版: https://nodejs.org/en/download/ 我是linux，下载解压，配置环境变量，source一把即可。 windows用户更简单，下载后各种next即可。 mac和linux类似 npm加速，安装cnpm： npm install -g cnpm --registry=https://registry.npm.taobao.org 安装Hexo：cnpm install -g hexo 会自动从gayhub下载hexo并安装 然后就进入目录去配置_conifg.yml,包括博客title、作者、语言等等 运行 hexo s，然后去http://localhost:4000就能看到了。默认样式会有点丑，别着急看下一节。 选择主题# 先戳这里，官方有巨多主题： https://hexo.io/themes/ 也可以去gayhub自己搜hexo-theme即可，也有n多 我一个老年大叔，选择了一个简单一点的主题hexo-theme-pure，这个https://github.com/cofess/hexo-theme-pure 主题的中文说明：https://github.com/cofess/hexo-theme-pure/blob/master/README.cn.md 按照主题说明，clone到hexo的theme文件夹内，然后修改一下hexo的_config.yml文件中的主题theme: pure 按照主题说明，安装主题渲染所需的nodejs插件。无非就是几个cnpm install xxxx即可 按照主题说明，配置主题的配置文件，一般在主题文件夹./hexo/theme/pure下的_config.yml（无非是颜色、元素是否显示、布局之类的），很简单看一眼就知道。 运行渲染hexo clean &amp;&amp; hexo g &amp;&amp; hexo s，分别是清理、生成、运行，然后再去http://localhost:4000看一眼，主题就生效了。 gayhub托管# 我们hexo g渲染生成的静态文件在public文件夹内，需要把它丢到一个web容器内运行就可以了。gayhub提供githubpages服务可以托管静态文件，并可以http浏览。 所以去github新建一个repo，repo名字为xxxx.github.io,这个xxxx必须和你的github用户名一致! 然后回到hexo中配置deploy模式为git，配置仓库地址为上面的repo地址。更多参见https://hexo.io/zh-cn/docs/github-pages 配置完毕hexo d输入github账号密码即可push到服务器（如果本机没有保存，或者服务器配置秘钥的话，具体github配置公钥上网查找） 然后可以访问我们的博客了https://xxxx.github.io` 自定义域名[可选]# 上面虽然博客可以访问了，但是github.io看起来有点low，而且国内访问速度也很慢。 所以，我建议撸一个域名，挂博客，搞微信开发，内网穿透，扶墙等等用处多多。。。而且最好是境外服务商域名，境内的域名要备案、年检，非常非常麻烦。 目前最便宜的是戳这个：namesilo官网，优势： 他家的.com域名只要7.99刀，.xyy和.online域名只要0.99刀，简直白送！关键是续费便宜没有坑，别家有首年很便宜，后面续费巨贵的。 永久免费的whois隐私保护，其他家这个功能还要收费。 支持支付宝收款，不用别家还要信用卡或者PayPal 所以戳链接进去官网： www.namesilo.com/ 进入官网后，右上角注册sign up，输入用户名，邮箱，密码即可。 然后register，选择域名进行注册，第一次会让你填写信息（以免域名丢失找回，或者服务商后续通知一些域名相关事项） 输入你想注册的域名，搜索，看看有没有被注册过： 假如你选择的没有被占用。点击下面的add加入购物车，然后checkout结算,我这里用.com的8.99刀域名举例（你也可以用下面0.99刀的，简直便宜到几乎白送！） 结算页面，按图上选择即可，然后下面的打折码输入**cutoff** ，点击submit即可享受打折优惠！ 下一步就是支付宝扫码付款即可。 付完款去account个人中心，点击domain manager域名管理，会出来你的域名列表。点击设置dns 设置DNS,点击CNAME，会出来一条解析，可以根据喜好设置为www的主域名，还是blog.xxx.com的二级域名。目标设置我们上面个人的xxxxxx.github.io，提交即可。 搞定你以为大功告成了？还需要在github的repo里面设置这个域名，否则github会阻止域名解析，导致404。看下一节 github配置域名： 在那个custom domain填写你的域名，save一下 然后在你本地的hexo/source目录下创建个CNAME文件夹，写上你的域名 最后，重新hexo g &amp; hexo d 此时即可用我们的域名访问。 Others# 生成目录# 为博客生成toc目录 使用插件cnpm install hexo-toc --save 然后配置一下最大深度等 123456789toc: maxdepth: 3 class: toc slugify: transliteration decodeEntities: false anchor: position: after symbol: '#' style: header-anchor 评论管理# 关于博客的评论，一般来说是需要一个数据库的。但是我们是纯静态服务，所以有人搞了类似gitalk、gitment 这样的东西。只用前台引用js即可，一般都不用我们管，主题已经集成好了。只用按照说明进行配置几个参数即可。 关于latex公式显示# latex会显示失败，按照pure主题的解决方案： 数学公式# Hexo默认使用&quot;hexo-renderer-marked&quot;引擎渲染网页，该引擎会把一些特殊的markdown符号转换为相应的html标签 解决方案# 解决方案有很多，可以网上搜下，为了节省大家的时间，这里只提供亲身测试过的方法。 更换Hexo的markdown渲染引擎，hexo-renderer-markdown-it-plus引擎替换默认的渲染引擎hexo-renderer-marked即可。 在blog根目录给hexo安装hexo-renderer-markdown-it-plus插件# 123cnpm un hexo-renderer-marked --save # 卸载cnpm i hexo-renderer-markdown-it-plus --save # 安装新的渲染框架cnpm i markdown-it-katex --save # 安装katex渲染latex 配置# 安装插件后，如果未正常渲染LaTeX数学公式，在博客根目录配置文件_config.yml中添加 12345678910111213141516markdown_it_plus: highlight: true html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: “”‘’ plugins: - plugin: name: markdown-it-katex enable: true - plugin: name: markdown-it-mark enable: false 文章启用mathjax（不用设置true也可以）# 12title: Hello Worldmathjax: true 按照上面操作了还是不行，元素错位。看了下面这个解决了： 还错位或者显示元素不准的话，需要引入一个katex的css# 1&lt;link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"&gt; https://blog.csdn.net/u014792304/article/details/78687859 katex和latex大部分命令是相通的，不同的略微差别见下面： https://khan.github.io/KaTeX/function-support.html CDN加速[可选]# 想继续折腾访问速度的往下看： 首先，不推荐国内的CDN供应商和域名解析商，因为他们动不动就有合规要求。会折腾客户去备案（不是所有的） 然后，推荐cloudflare，也很简单，注册一个账号，在namesilo里面把CDN服务迁移到cloudflare即可。上网搜索巨多资料。 FAQ# 为啥配置好了域名无法访问？ 等待域名解析，尝试DNS那里的TTL设置小一点，刷新本地DNS缓存。 为啥速度不一般？ 因为是国外DNS，可能第一次访问有点慢。有精力的尝试迁移到cloudflare，还有CDN加速，https，爽歪歪。戳这里：https://www.cloudflare.com/","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"}]}],"categories":[{"name":"IO","slug":"IO","permalink":"https://blog.sofunnyai.com/categories/IO/"},{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"基础","slug":"基础","permalink":"https://blog.sofunnyai.com/tags/%E5%9F%BA%E7%A1%80/"},{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"},{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"}]}