{"meta":{"title":"树先生的金融风控工程师博客","subtitle":"","description":"","author":"树先生","url":"https://blog.sofunnyai.com","root":"/"},"pages":[{"title":"about-关于我","date":"2018-03-21T08:41:44.000Z","updated":"2020-05-20T08:46:47.021Z","comments":true,"path":"about/index.html","permalink":"https://blog.sofunnyai.com/about/index.html","excerpt":"","text":""},{"title":"categories-博文分类","date":"2018-03-21T08:35:01.000Z","updated":"2020-05-20T08:46:34.397Z","comments":true,"path":"categories/index.html","permalink":"https://blog.sofunnyai.com/categories/index.html","excerpt":"","text":""},{"title":"tags-标签文章","date":"2018-03-21T08:41:37.000Z","updated":"2020-05-20T08:46:25.013Z","comments":true,"path":"tags/index.html","permalink":"https://blog.sofunnyai.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"风控策略相关的一切","slug":"风控策略相关的一切","date":"2020-04-15T06:37:22.000Z","updated":"2020-05-26T05:06:31.825Z","comments":true,"path":"article/strategy.html","link":"","permalink":"https://blog.sofunnyai.com/article/strategy.html","excerpt":"","text":"风控策略概要 什么是风控审批策略 其中多维度数据的策略规则包括： 风控审批策略的目的 风控审批策略的作用 风控审批策略的类别 风控的基本量化指标 确定目标变量 制定风控审批策略 策略预估 策略监控 策略回顾 风控策略分析师 日常工作内容 必备技能 核心作用 策略分析常见工作场景与对应分析方法 三方数据测评 举例—黑名单数据评测 准入策略的制定 年龄准入策略 地区准入策略 白名单策略 黑名单策略 规则阈值cutoff如何设定 背景 第一步：通过评分找到风险被低估的区间 第二步，评估拟拒绝人群的收益/风险比 通过率下降的策略调整 1.寻找通过率下降的时间点或时间段 2.判断策略节点主次要拒绝影响 3.从节点聚焦到节点规则层深度分析 4.具体规则分布分析 5.分析指导决策 逾期率上升的策略调整 第一步：确定存量还是新增客户导致逾期上升 第二步：多维度分析，找出最主要影响规则 第三步：制定策略调整方案 信用多头策略 1.什么是多头借贷 2.多头借贷数据的分析方法 3.多头借贷数据为何少用于模型 4.多头借贷数据在策略规则上的应用 评分的策略应用 评分卡模型的运用，主要是为了解决两大问题： 评分模型的cutoff 模型与策略的关系 模型是否可以替代所有的策略规则? 策略规则+评分模型 策略规则+模型规则 策略规则的粗放式管理 评分模型的常见三种盲区 建模数据集与实际贷款人之间存在偏差 模型数据集来自历史，与未来实际情况存在偏差 模型对于目标变量的界定与实际商业目标存在偏差 精简摘录自微信公众号：金科应用研院 风控策略概要# 什么是风控审批策略# 基于数据分析在申请阶段制定各式各样多维度的策略和规则; 其中多维度数据的策略规则包括：# 社交及短信维度规则 移动设备维度规则 外部数据源（如：征信报告、各种黑名单来源）规则 多维度评分卡规则 行为数据(设备信息、注册时间、登陆时间)规则 风控审批策略的目的# 在贷前审批减少风险事件的发生的各种可能性，挽回风险事件时造成的损失。较大的程度上筛选过滤高风险客户，保留低风险客户予以营销。针对客群分级实行个性化的审批流程，提高审批效率。 风控审批策略的作用# 在保证业务量的同时降低业务坏账率、控制逾期风险，最终实现公司盈利。 风控审批策略的类别# 多维度数据分析呈现了借款人的用户画像，制定多维度完善的审批策略规则，具体策略规则包含： 1）经济能力维度(月收入、工资流水等信息) 2）app信息维度(贷款APP安装个数、短信命中高风险关键词) 3）基本信息维度(年龄、性别、工龄等信息) 4）信用历史(征信贷款信息、还款记录) 5）行为表现(活动轨迹、登陆时间、注册时间等信息) 风控的基本量化指标# FPDx：首期逾期，x对应天数 CPDx：当前逾期，x对应天数 逾期时间的长短来定义逾期的等级，C代表正常资产。M3-M6属于不良，M6+属于坏账。 迁移率、vintage账龄分析、滚动率见上一篇博客，这里：https://blog.sofunnyai.com/article/vintage_rollrate_fpd.html 确定目标变量# 根据催回率及迁徙率确定好坏客户（不过一般还是用滚动率比较多） 由上表可以看出，M2以上的迁徙率将近90%，所以确定当前逾期31天以上为区分好坏客户的标准，及后续分析的目标变量。 制定风控审批策略# 如以城市等级为例，城市等级与逾期的关系：城市等级越低，其对应的逾期率越高。 策略预估# 预估策略上线对生产运营阶段的影响，基于进件量、放款量、通过率的影响。 策略监控# 策略上线后，监控此策略的占比与预计的占比是否发生严重偏差，且在正常运行阶段是否全部执行。 策略回顾# 对上线后的策略，在一定时间后。对于有表现的数据进行策略回顾，看策略调整后的进件量、通过率及贷后表现。若是想及时的查看策略上线后的贷后表现可以针对FPD指标分不同的天数去观测，FPD4，FPD10，FPD30等。 若策略是调宽或者是放松时，可以针对性回顾下豁免出来的客户的进件情况、通过率及贷后表现。 若策略是调严或者收紧时，可以针对性回顾拒绝阈值边缘维度的贷后表现及拟定拒绝的客户数。 风控策略分析师# 风控策略分析师是完成上述P1部分所有分析，构架风控策略的人员。 日常工作内容# 贷前、贷中及贷后各环节的风险策略与流程，制订各项策略规则，具体包括准入、授信、定价、用信、还款、调额等信贷流程各阶段的策略规则 通过对各类风险指标与报表的分析，关注各类资产和客群的风险变动，对公司全渠道风险政策与策略进行跟踪评价，并及时优化调整相应的风险政策与策略 必备技能# 结合内外数据，通过统计分析方法，对不同风险点制定出不同类型的风险规则 完成整个贷前、贷中和贷后的风险规则架构，实现自动化风控 可以实现策略规则优化，不限于A、D类调优方法 规则的部署与监控预警 临时指标调整的项目经验 核心作用# 实现具体规则和流程的设计、开发、部署、监控与优化 策略分析常见工作场景与对应分析方法# 三方数据测评# 案例：现有1000个样本数据，分别测试2家黑名单，2家欺诈名单与2家多头，如何选择合适的第三方数据源？ 首先要专业科普选择第三方数据源重要考察的5大指标计算公式（以黑名单为例）： 查得率(Search rate)=查得数/样本量 覆盖率(Cover rate)=查得命中黑名单数/样本中命中黑名单量 误拒率(Error reject rate)=查得命中黑名单数/样本中通过且为Good量 有效差异率(Effective difference rate)=查得命中黑名单数/样本中通过且Bad量 无效差异率(Invalid difference rate)=查得命中黑名单数/样本中其他拒绝量 其中SR、CR、EDR指标越高越好，ERR越低越好，IDR与EDR结合起来观察，如果IDR和EDR都较高，反应的一种情况是数据源定义黑名单是广撒网式，黑名单质量相对不够精准。 其中前三个指标是重点考察，如果想更全面的测试第三方数据源，后面两个差异率指标也可以加入考核标准。 举例—黑名单数据评测# 1000个测试样本数据中，审批结果字段表示样本通过和拒绝，其中通过样本中有未逾期和发生逾期的客户样本，拒绝样本中有通过黑名单库拒绝客户，也有其他原因产生拒绝。比如，数据源1（黑名单）代表一家提供黑名单数据的数据供应商A，数据源2（黑名单）代表另一家提供黑名单数据的数据供应商B，以此类推。 对1000条测试数据返回结果进行整理可以总结出如上数据概要，对比看到数据源1的返回结果如下： 按照文章开始介绍的指标分析方法，对比数据源1和数据源2的测试结果可以得出如下结论： 数据供应商1的查得率、覆盖率高于数据供应商2大约5%、4%； 数据供应商1的误拒率低于数据供应商2大约0.3%； 数据供应商1的有效差异率低于数据供应商2大约8%，无效差异率低于数据供应商2大约7%； 依据五大指标分析标准，SR、CR、EDR指标越高越好，ERR越低越好，IDR与EDR结合起来观察，如果IDR和EDR都较高，反应的一种情况是数据源定义黑名单是广撒网式，黑名单质量相对不够精准！ 最终分析结论： 数据供应商2虽然覆盖的黑名单比数据供应商1的更广，但其不如数据供应商1精准，更偏向选择数据供应商1的黑名单数据。 准入策略的制定# 风控准入策略作为金融借贷机构评估一个借款人是否有机会获得授信的第一道门槛，是保卫金融机构的第一道护卫。 风控准入策略属于贷前风控策略体系的一部分，贷前风控策略包括基础认证、准入策略，贷前反欺诈策略，黑名单策略，特殊名单策略及信用风险策略。风控准入策略中的规则更多是由产品政策性规则构成。 针对不同信贷场景采取更适应业务的准入规则，设定科学的准入策略，对于风险的防范与降维有十分重要意义。合理的风险准入策略，也能对信贷业务的走向与风险倾向产生直接影响，进一步影响金融机构的最终盈亏。 为什么要设计风控准入策略 风控准入策略的规则属性全部为强拒绝规则（硬规则），借款人一旦不满足一条准入规则金融贷款机构都不会给予贷款的授信与发放；同时，风控准入规则不需要经过复杂的规则衍生，通常可以简单有效的判决借款人是否有资格进入之后的风控流程；最后，风控准入规则的策略理念是验证借款人依法合规未被政策限制。 风控准入策略模块 风控基础认证模块: 基础认证模块主要作用是验证借款此人是本人，也是以风控规则形式出现，规则大多为公允共认的规则。比如身份证信息验证，人脸信息验证、银行卡四要素验证、运营商三要素验证等。 在验证完借款人基础信息后，风控贷前流程才会进入准入策略模块。 准入策略模块主要分为年龄准入、地区准入、行业准入及其他。这些准入规则的根本设定原则是基于监管和金融机构产品政策性导向。 年龄准入策略# 对于年龄准入而言，中国银行业监督管理委员会令《个人贷款管理暂行办法》中指出个人贷款申请应具备以下条件： （一）借款人为具有完全民事行为能力的中华人民共和国公民或符合国家有关规定的境外自然人； （二）贷款用途明确合法； （三）贷款申请数额、期限和币种合理； （四）借款人具备还款意愿和还款能力； （五）借款人信用状况良好，无重大不良信用记录； （六）贷款人要求的其他条件。 其中借款人具有完全民事行为能力的中华人民共和国公民年龄范围在18-60岁。所以合规的金融机构信贷产品的借款人年龄准入策略中，年龄规则的设定是：年龄&gt;X &amp; 年龄&lt;X ，X属于18-60。有些贷款产品，则是根据贷款人的性别不同来限制年龄的。比如对于女性申请人的年龄限制是22周岁以上，而男性申请人的年龄限制为20周岁。 地区准入策略# 一般金融机构会按照风险热力地图将一些重灾风险区进行隔离或者进行“象征性”政策贷款发放。 地区准入规则的初始设定一般是风险集中度比较高、社会稳定性比较弱、地区经济GDP比较低，亦或是难催收的地区，比如新疆、东北等个别地域。 在之后随着信贷业务的开展，也会根据贷款回收率对地区准入规则进行一些策略调整，比如一些地区的贷款回收率长期观测较低，金融机构企业内部信贷战略调整后，可以将这些地区加入限制性地区里。 上图事例1中展示的是M1阶段的回收率热力分布地图，可以发现灰色区域的M1贷款回收率低于60%。如果需要进行地区准入策略的调整，还可以将M1回收率0-60%的区间划分的更细，比如0-15%的M1回收率，也可以将省维度拆成市级维度进行限制。 此处需要提醒，一旦加入到地区准入规则后的地域在之后将无法进行信贷业务，同时也会失去观测业务数据，所以此类的策略调整要谨慎设计。 地区准入策略的常用规则如户籍地址 in（x,x,x），单位地址 in （x,x,x）,家庭地址 in （x,x,x）等。 行业准入策略 行业准入策略的基础原则是对一些行业工作不稳定或无业的借款人禁止提供信贷业务。如禁止： 金融属性行业如投资、担保、理财、典当；政策性敏感娱乐行业如KTV、按摩院、会所等；无业和自由职业、学生、媒体工作者，检察院。 白名单策略# 白名以下两种业务场景： A.在存在自有存量数据的前提下，金融机构想开展信贷业务，前期需要通过白名单控制入口，此类场景多存在于业务初期，或者是内部员工贷的业务场景。(风控模型不完善的条件下，先把业务开展起来。同时，在这个展业的过程中，可以逐渐组建适合金融机构业务的风控策略和模型。) B.在业务开展中期，需要部分进件客户走特殊贷前审批流程，满足特殊审批的要求，此类场景多存在于较大的金融公司。(有着较好的信用、较好的资产亦或是较好的“背景”，通过一些特殊审批流程进行贷款的审核，最终满足“VIP”的借贷需求。) 综合来讲，白名单可以定义为，通过金融机构内部现有数据判断的“好客户”，或者经过一系列规则挖掘分析得出的“好客户”，由他们组成的借贷优质名单。 如何筛选出白名单 联合建模： 金融机构在有存量数据的前提下，自有数据是不缺乏X特征变量，主要缺乏相应业务场景有表现特征的目标Y变量。在这个时候可以通过引进一些外部机构进行联合建模，用以补充一些Y变量。 通过与外部机构联合建模得出评分，不论是将其用于内部客户分层，还是将评分分数直接做规则，都对筛选白名单有很好的帮助。 内部数据探索： 我们在筛选白名单的时候，除了通过联合建模弥补相应业务场景下目标变量的缺失，还可以通过内部数据探索，寻找分析一些对逾期违约表现相关性较强的一些特征规则，逐渐设定出白名单规则。这里面分为两种规则设定方式。 第一种是寻找与新开展业务相似模式和场景的已有产品，参照已有产品的风控策略规则对新业务场景数据进行比对分析，参照已有产品的策略规则制定出新业务场景的风控白名单规则。 另外一种方式是在更“艰苦”的环境下，没有任何可对比参照的已有产品，这个时候设定的白名单规则相对更严谨，同时对风控策略工作者的业务经验要求更高，可以认为是一种专家经验规则。 引入外部数据匹配： 工作单位、学历、社保缴费单位、公积金缴费单位、缴费基数等信息去筛选优质客户。 白名单的作用： 控制放量节奏：初期的时候用于控制节奏，整体调控。 降低风险 提高过审率 协助调整贷前策略：白名单筛选的过程就是贷前策略的一部分。 黑名单策略# 黑名单：性质极其恶劣的坏客户。无论是其还款能力，还款意愿，借款目的等都不能满足正常客户的标准。 有自建和外部引用两种。对于业务初期的金融机构通常调用三方数据接口查询行内黑名单客户，同时在自家展业过程中，通过贷后管理逐渐补充、完善自家黑名单库。 黑名单的使用：# 一般来说金融机构一旦触碰到黑名单规则，金融机构通常会全部拒绝。（全部拒绝黑名单前，会随机放过5%或者10%的触碰黑名单的客户，去测试黑名单数据有“多黑”，测试该黑名单客群是否适用于该机构。） 导流助贷机构可能会选择性放入一部分客群，结合客户评分，多头等数据综合判断，或者随机放过。（反正不是他兜底） 敞口测算# 假设一个场景：如果有一万块钱，借款一年，不考虑其他，综合年化36%的信贷产品，因为一个黑名单客户导致本金全部损失，那么实际上需要大约3个好客户才能弥补1个坏客户的损失。 如果我们加上资金的运营成本，人力成本，引流成本，实际成本等。 假设需要的综合年化是15%，那么实际上 ，也就是5个好客户才能覆盖一个坏客户的本金损失，同时还需要覆盖上述的各种成本 ，也就是说金融机构大约要用6个完全的好人才能替代一个完整的坏人。 如果是3期、6期产品，同时也包含资金占有率问题，实际上需要的用更多的好人去覆盖坏客户带来的损失。 假设5000 6期 36%，每个好人收益是5000×0.36/2 = 900，不算其他成本也需要5.5个人才能cover一个欺诈。（此时坏账率：1/6.5=15.4%） 实际同上假设人力、引流、IT，使得实际年华15%，每个好人收益是5000×0.15/2 = 375，需要13.3人才能cover。（坏账率1/14.3=6.99%） PS：助贷导流客户平均成本一般不会超过5毛钱，金融机构开展信贷业务所需风控数据成本也不会超过10元。 所以黑名单很重要，坏账很难搞。。。 自建黑名单# 黑名单一般的自建维度有参照回款表现、渠道、利率、各种公布失信类客户以及通过爬虫获得的一系列坏客户，黑名单的设定不一定仅限客户本身，也可以拓展为身份证、手机号、邮箱、银行卡、ip地址等，都可作为自建黑名单的参考维度。 和通讯记录、电话簿、二度通讯记录等联系起来。 自建黑名单命中率通常不会太高（相同客户再次注册的概率较低），且自建黑名单库需要长期的业务积累过程，因此金融信贷机构常常需要借助三方金融科技公司的黑名单库服务（特指三方数据供应商商以及其他金融信贷机构）。 大量p2p以及小贷机构接入百行征信，但我想要说明的是：滞后性和成本的增加使得黑名单需要更多的共享，只有共享才能更全面了解我们金融机构所接触的客群。 规则阈值cutoff如何设定# 风险策略拒绝线的设定，背后有严谨的分析逻辑，本文就以评分分数区间和年龄规则为例，为大家讲解审批策略拒绝线的内在分析方法。 背景# 评分模型，尤其是主流基于线性Logistic算法的评分模型，对于一些边际评分区间的风险，其实常常无法精准的预估到，势必会造成一些区间风险被低估的现象。如果不通过一些规则维度的拒绝补充，容易因为模型风险发生不必要的利益损失。 假设我们已经对评分模型分数分为T1-T5组，T1风险最低T5风险最大。年龄规则也使用单变量树模型初步分为5组区间。我们希望结合评分分数找到年龄规则这个核心策略维度的合理拒绝线。 第一步：通过评分找到风险被低估的区间# 本例中，首先将年龄与评分卡进行交叉矩阵分析，观测不同交叉区间里的用户违约概率。 一般策略规则多数组之间的趋势线是紧密相近的。从图示数据走线可以发现，年龄组[35,47)和[47,53)这两个年龄组的违约概率走线脱离了其他分组，尤其是年龄组[35,47)，其走线脱离其他“群体”过多。通过分析初步定位年龄组[35,47)和[47,53)可以是待确定的规则拒绝线。 第二步，评估拟拒绝人群的收益/风险比# 虽然经过评分与年龄的交叉对比，发现年龄规则的两个待确定高风险拒绝区间。但是实际拒绝线的划分要结合年龄分组区间人群的实际收益与风险进一步考虑。如果高风险的人群可以带来高收益，对于策略来讲也是可以接受的。 将年龄分组区间按照上图示例2横轴所示指标进行统计，假设年龄分组[35,47)的收益/风险大于[47,53)且为正，即表明虽然[35,47)年龄分组的人群违约率最高，但其收益同样也是最大。反而[47,53)年龄区间的人群为公司带来负收益。 本着收益覆盖风险的商业理念，此时对于年龄这一维度的策略最佳拒绝线，应该划分在[47,53)这一分组区间。 通过率下降的策略调整# 审批通过率和不良率是一对权衡指标，在新业务上线初期，维持一个较低的通过率可以保证最好的客群进去。随着业务规模做大和风控样本积累，此时需要在风险容忍度可接受范围内提升通过率，以保持收益的最大化。 如果某一天风控通过率忽然降低，这种情况下策略分析人员应该如何应对？ 1.寻找通过率下降的时间点或时间段# 在风控策略稳定之后，审批通过率一般稳定在某一小范围内波动，当监控每日通过率指标时发现，T-1、T-2时点的通过率明显下降，我们应该先通过监控报表迅速定位到具体时间点或时间段。 2019.6.23和6.24授信通过率下降。 Tip：上图示例通过率下降到6.9%、7.0%可以直接用肉眼分辨数据，但实际业务一般建议以通过率趋势图和PSI指标监控通过率下降。 2.判断策略节点主次要拒绝影响# 发现通过率下降的时间点或时间段之后，下一步先聚焦到策略节点。本文为FALers举例两个策略节点A（准入）和B（规则）。以6月23日为时间节点划分，对比数据分析，寻找拒绝率的波动差。 上图示例2中波动差按照B段A节点拒绝率-A段A节点拒绝率计算出来，以此类推。此时计算波动差仍然可以考虑加入PSI=(B-A)*LN(B/A)测算波动差,A节点的PSI为0.77%，B节点的PSI为0.01%。 按照波动差确定通过率的下降主要因为A节点的拒绝率上升引起，从而将通过率下降的影响因素从策略A和B两个节点问题进一步聚焦到A节点上。 3.从节点聚焦到节点规则层深度分析# 完成节点的聚焦分析，定位到引起通过率下降的主要原因节点A，接下来需要进一步分析节点A内包含的所有规则拒绝情况。 与节点聚焦分析一致，寻找引起拒绝率上升的主次要拒绝规则。在规则层确定主次要影响因子时，分析方法不仅结合数据同时也参考业务场景。 从上图示例4可以发现，按照波动差分析得出年龄准入拒绝和X3_准入拒绝是主要引起通过率下降的规则。 4.具体规则分布分析# 从步骤3确定出年龄准入拒绝是第一位引起通过率下降的规则后，第四步就从规则层聚焦到具体策略规则的分布上。 通过分析具体策略规则分布的波动差定位具体策略规则的某一分布，找出引起通过率下降的主要策略分布。 从上图示例6可以发现，年龄准入拒绝这一策略规则中，18-25岁的分布拒绝率在时间A段和时间B段的波动差最大，这个年龄分布的拒绝率上升可能是引起整个审批通过率下降的主要规则分布。 造成以上18-25岁年龄分布拒绝增加的原因，很常见的一种是进件客群发生了变化，针对客群发生突然变化的情况，如何将分析结果指导决策执行，是策略分析最后且最重要的一步。 5.分析指导决策# 仍以上述案例为例，通过一系列聚焦分析发现，18-25岁的进件客群变化是引起整体通过率下降的核心因素。实际业务场景中，并不会因为此时通过率突降就进行策略规则的调整，更多的是通过聚焦分析后，结果进一步细分两个参照要素：进件渠道的进件量分布和最大进件渠道的年龄准入拒绝分布。 5.1.进件渠道分布分析 既然是客群的变化引起了整体审批通过率的下降，从进件的所有渠道数据中进行分布排序，定位到渠道进件量A段和B段都最大的一个进件渠道C。 5.2.最大进件渠道的年龄准入拒绝分布 通过进件渠道进件量分析，从众多进件渠道中定位到最大进件渠道C。此时分析主要拒绝规则-年龄准入拒绝的渠道C的分布情况，是否满足条件：B段与A段年龄18-25岁的波动变高。 从上图示例8中分析发现，渠道C年龄在18-25岁的客群进件量在B段比A段上升明显，即从渠道进件前段业务确定出引起通过率降低的主要进件渠道C。至此，可以进行策略分析决策建议。 5.3.决策建议 将策略分析结果应用于前段业务指导和决策，提醒前端业务人员在渠道C可以适当缩紧18-25岁客群的进件需求，以此共同维护金融公司整体风控通过率，这才是风控策略分析工作者最终的使命和义务。 逾期率上升的策略调整# 当逾期升高时，如何进行策略调优。 真实案例背景（数据已脱敏）： 通过PQR监控报表发现，某XX贷产品的MOB报表自2019年5月开始，后续放款月资产逾期呈上升趋势，既DPD30+逐月上升，且上升速度逐步增快（MOB期数逐渐缩短）。在2019年11月放款的客户里，MOB=4的DPD30+等于2.49%。如下图1所示。 通过将MOB制作成Vintage报表，可以观测到某XX贷产品的风险自2019年5月到11月的DPD30+平均值位于6%的水平，如下图2所示。 往期DPD30+表现出的风险水平逐月快速上升现象，意味着如果不做相应的策略调整，之后的放款月风险将会更快的暴露。 针对此时逾期快速上升的背景下，如何分析策略，进行策略调整呢？ 策略分析方法 第一步：确定存量还是新增客户导致逾期上升# 信贷业务每个月发生授信和放款的客户可以分成新增客户和存量客户。从上图示例2中Vintage报表展现的数据，反映出资产逾期呈上升趋势。那我们首先需要将2019年5月到2019年11月（可观测到DPD30+）的Vintage分成新增客户的Vintage1和存量客户的Vintage2，如下图3。 从上图3的Vintage1（新客户）和Vintage2（存量客户）标注的红色椭圆框可以观测到，新客户的DPD30+平均处于6%，存量客户的DPD30+平均处于5%。与图示1对比可以分析出，导致资产逾期上升的主要原因是新增客户资产变差的影响。 至此阶段的分析结论：我们可以确定出需要调整的策略规则是贷前规则。 解释如下：往期放款月中，新客户是由贷前规则通过后，给予授信并放款的，存量客户的复借是由贷中规则决定。通过Vintage1和2的分析比对，引起资产逾期上升的主要原因是新客户的逾期上升。 第二步：多维度分析，找出最主要影响规则# 通过第一步的分析确定出核心要调整的是贷前策略后，我们接下来要通过分析不同的规则变量，找出对目标变量（DPD30+）影响最大的维度变量。 这里提供分析主要影响变量的两个思路，具体实践过程就不在这里多讲，文末推荐阅读有链接。 思路一：自上而下地按照A类策略调优方法，从贷前策略节点到节点里的规则集，再细分到具体规则，逐步分析出影响较大的规则变量（文末推荐阅读给出具体分析的往期文链接） 思路二：自下而上地将所有规则变量与目标变量拟合分析，通过IV的降序排序，找出影响较大的规则变量。 分析得出，城市等级是影响逾期目标上升的主要变量。通过分析2019年5月至11月的城市等级Vintage曲线，可以发现“其他城市”较“一线城市”、“二线城市”、“三线城市“对逾期的影响较大，如下图。 第三步：制定策略调整方案# 通过上述数据分析，发现贷前风控规则里的“城市等级”规则”其他城市“是导致逾期升高的主要原因。此时容易出现的一个错误决策是拒绝“其他城市”的进件。 原因很简单：这种决策会导致大量的申请被拒绝，对通过率的影响比较大。 最优的策略调整方案思路是：从“坏客户”中挑选出“最坏”的一批客户，且这批客户的占比较少，然后加以拒绝。 按照上述思路，我们可以制定出如下的策略优化方案： 1、进一步分析“其他城市”里，哪一些的城市逾期较高； 2、挑选部分逾期较高的城市做贷前准入规则。 以上，就是逾期升高情况下，策略调优的分析方法。 信用多头策略# 金融风险管理中，对于一个借款人还款能力的评估十分重视。如果一个人的资产负债比过大，一旦发生资不抵债的现象，金融机构继续对其发放贷款发生违约的风险是极大的。 在体现借款人甚至借款企业还款能力的众多指标中，多头借贷是一项核心指标。 1.什么是多头借贷# 多头借贷是指单个借款人向2家或2家以上的金融机构提出借贷需求的行为。多头借贷数据一般至少会粗分成银行类多头借贷、非银类多头借贷。按时间跨度可以分为近7天、近15天、近1个月、近3个月、近6个月、近12个月。 多头借贷除了会统计申请次数，还会统计申请机构数、申请最大间隔天数、申请最小间隔天数、申请记录月份、平均每月申请次数(有申请月份平均)、最大月申请次数、最小月申请次数等。 由于单个用户的偿还能力是有限的，向多方借贷必然蕴含着较高的风险。一般来说，当借贷人出现了多头借贷的情况，说明该借贷人资金出现了较大困难，有理由怀疑其还款能力。 2.多头借贷数据的分析方法# 由于多头借贷可以比较有效的反应借款人的还款能力，所以在对借款人信用风险、欺诈风险评估上，基本都有使用多头借贷数据。 多头借贷作为一个衡量借款人的维度特征，可以结合一些逾期指标进行分析。 上图示例1中，对近7天非银机构申请机构平台数进行分析，对申请不同平台数的客户，分别统计客群的分布占比、FPD30%、FPD30-DPD90+%、通过单量、FPD30单量、DPD90+单量以及DPD90+%。通过统计后的数据，分析近7天申请N平台数的客户，其不同逾期指标的变化趋势，如上图示例1中FPD30%的增幅，进一步用于寻找策略切点或者豁免客群的回顾分析。 3.多头借贷数据为何少用于模型# 多头借贷少出现在模型变量中，主要有两个方面原因。 第一，多头借贷数据往往被策略同事应用于规则中。 数据建模的目的是从金融弱变量中通过特征工程方法，提炼出有效区分变量，构建评分模型。所以对于多头借贷数据，既然已经运用在策略规则中，实在没必要加入到模型变量。如果读者朋友们看到提交的评分模型报告中有多头借贷变量，那么建模的同事要么没有事先了解已上线运行的策略规则集，要么就是为了模型表现指标（如KS、AR、AUC）好看强行使用。 第二，多头借贷数据往往覆盖度不全。 多头借贷虽然是一个与风险强关联的维度，但其查得率一直被人所诟病。 举一个例子，借款人一个月内在多家机构贷款，作为一个特征，很有可能出现某个人虽然频繁贷款，但并没有被多头供应商捕捉到。一旦这个特征作为模型变量，那么这个变量的噪声就很大了。反而如果做成反欺诈策略，就不需要担心噪声问题，直接选取拒绝线进行截断，最大的影响，也就是没有拒绝掉足够多的用户，而这个影响我们还可以用噪声较小的模型进行弥补。 4.多头借贷数据在策略规则上的应用# 多头借贷在策略上一般作为一条策略规则，一个拒绝维度参与到整个风控流程中。不同机构，不同信贷产品，不同场景，对于多头借贷的拒绝线划分都是不一样的。如何找到当下最适合的多头借贷拒绝线，对于风控策略分析人员，是风控工作的核心任务。 仍以上图示例1为例，假设当前对于7天多平台数规则的拒绝线划分在6，即如果7天多平台数&gt;=7则拒绝。如果我们现在希望通过7天多平台数规则豁免一部分客群提升整体通过率，此时的拒绝线cutoff应该划分在哪里呢？ 如果不是应对紧急调整通过率的情况，我们可以事先豁免7天多平台数7-10的客户，作为测试样本，用以产生7-10客群通过单量的分布，之后将拒绝线调回6。既可以生成如下统计分析表： 上图示例2中的桔色部分都是通过分析预测出来，比如通过上图示例1中不同多平台数FPD30%的平均增幅0.7%，预测出7-10的FPD30%。 预估计算公式8FPD30%=7FPD30%+0.7%。进一步计算出FPD30量、DPD90量等其他指标。 提醒读者朋友们，因为我们对于资产风险管控最关心的逾期指标还是不良率，所以我们通过FPD30-DPD90+%的迁徙率预测出不同7天多平台数的DPD90+%。对于7-10的FPD30-DPD90+%预估，可以采用MAX(0-6的FPD30-DPD90+%)的预估方法。 在这之后，我们对于不同7天多平台数测算出拒绝线Cutoff的FPD%和DPD%，如下图所示： 对比示例图1和图3的Cutoff_DPD%可以发现，规则拒绝线设定在&gt;=7时DPD%=3.0%，设定在&gt;=8时DPD%=3.0%，设定在&gt;=9时DPD%=3.3%。规则拒绝线设定在&gt;=8的DPD%并没有增加。此时可以尝试建议将7天多平台数的拒绝线调整到7。 当然，这种策略分析方法仍有一些纰漏，比如此方法需要有测试样本进行观测，无法满足快速调整通过率的需求；7天多平台数的FPD30%的增幅实际情况并非线性增长，有经验的策略分析师知道，FPD30%一定会在某一个节点指数级增长。 但正是因为策略分析师通过不断地按照上述方法进行样本测试对照，根据实际情况回顾分析结果，才能不断的积累策略调整经验，才会对规则分布具有一定敏感性。 评分的策略应用# 评分卡模型的运用，主要是为了解决两大问题：# 1、线上借贷业务量逐渐增加的情景下，策略规则已经无法满足更细的切分需求； 2、对于策略无法有效识别的大量灰色客群，需要使用评分卡进行风险判断； 现如今业界使用评分卡模型，更多的是为了解决第二个问题。 从金融机构自身业务发展历程来看，评分卡模型介入风险管理流程常常取决于两个重要的时机： 1、业务快速发展阶段 在金融机构业务发展的早期阶段，因为业务量小、样本少、风险控制严格等一些主客观原因，使用风控策略规则足以开展业务，所以在业务发展早期评分模型基本没有任何用武之地。 但随着信贷产品的测试期结束，金融机构要加快业务发展，此时不论是大量的客群样本、逾期表现的积累，还是风险控制的政策放松，都因为风险策略无法精准细分的局限性，而需要评分模型的介入，评分卡的应用场景更适用于人工分流。 此阶段的评分模型，常常表现不稳定，比如KS波动较大，Lift下降较快，PSI时常过0.1。此阶段评分模型的优化更多在于分析波动原因，快速重新开发迭代。 2、业务发展稳定阶段 一旦金融机构度过了新产品的早期和发展期，此时产品市场表现已经趋向稳定，反应在客群分析上，表现出稳定层级的客户画像，此阶段是评分模型介入2.0阶段。 在这个阶段评分模型会在风控流程节点上进行一些调整，比如申请卡模型会进一步的前置，担当部分客群豁免的功能。同时，此时评分模型介入2.0阶段也会降低一些外部征信数据调用成本，控制因三方数据有误而引起的误杀。 此阶段的评分模型，表现较为稳定，KS、Lift、PSI等指标波动较小，对于评分卡的迭代开发需求降低，评分卡的应用更加与业务需求、金融政策以及企业发展战略相关，在保证评分模型稳定性及相对精准度的前提下，使用模型调整系数进行全局模型的调整是此阶段的主要优化办法。 评分模型的cutoff# 评分卡分数转换出来，在不同业务发展阶段如何合理的制定评分的cutoff，是评分应用重要的一步。 一般将评分等分后，会有两种方式对评分进行cutoff：一种是参照KS和Cum % bad rate,另一种根据等分后的累计净收益。 第一种参照Max KS和累积bad rate理论上是可以尽可能的将坏客户剔除，对好客群进行授信，但无法根据业务发展需要保证收益最大化。参照不同业务发展阶段的需求，根据评分对收益损失预估，最终确定评分cutoff，我认为这才是精细化的评分应用策略。 第二种制定评分的cutoff，需要联动分析以下图示的一些指标 通过逆向累计净收入指标的分析，结合当下风控政策，综合评定评分的cutoff，将之应用在风控策略上，这样才是更接近业务的评分cutoff。 模型与策略的关系# 评分模型在金融信贷风控领域的应用非常广泛，模型的开发、监控也趋于标准化。 评分模型可以为每一位观测对象打出一个评分分数，理论上实现风险与定价的绝对对等，实现个体差异化的风险管理，在这点上，风险策略规则是远不可及的。 模型是否可以替代所有的策略规则?# 此时就有了风险策略与模型之间的争议：模型是否可以替代所有的策略规则？（排除政策准入规则） 想要回答上述的争议，首先需要了解目前策略规则与模型在风控决策体系里的应用架构。目前我所见到有两种主流的风控决策应用架构：策略规则+评分模型 &amp; 策略规则+模型规则。 策略规则+评分模型# 前者策略规则和评分模型是分开的，一般风控流程是先进行策略规则的风险判断，再进入评分模型的风险识别； 策略规则+模型规则# 后者是将评分模型的预测概率（或分数）转变为一个策略规则，与其他策略规则融合在一起进行风险决策。 策略规则的粗放式管理# 策略规则作为一种风险识别的方法，其自身具有直观、易用等特性。对于新产品上线前的风险决策，因为没有数据样本的原因，策略规则在风险决策初期起到不可替代作用。但也因为策略规则的设定原理，其自身很难做到风险决策的精细化管理。 以上图风险决策B为例，可以看出策略规则都是XXXX&gt;xxx，这种单维度的风险判断是存在一定的取舍。比如某金融机构的一条多头借贷策略规则设定为：多头借贷平台数&gt;5则执行拒绝，那多头借贷=6的申请客户，就一定会违约吗？ 说到这里可能会有读者朋友质疑：我可以设定一些策略规则组合起来判断。没错，这也是风险决策体系下策略规则应用的一种方式，但不论多少维度的组合判断，都必然会对单一维度策略规则进行True or False判断。比如上例中的策略规则变为：多头借贷&gt;5 或 多头借贷&gt;6且性别为男性，则执行拒绝。此时对于多头借贷=6的女性不会拒绝，但对于多头借贷=7且有一定储蓄的男性，就一定会违约吗？ 可以看出，如果希望通过策略规则的组合实现精细化的风险管理，就会不断地增加策略规则，最终导致策略规则的复杂和冗余，对于策略优化、回顾并没有正向的影响，这与策略规则的易用、直观等特性产生了矛盾。 评分模型的常见三种盲区# 由于策略规则的先天性缺陷，评分模型的出现可以恰当的弥补策略规则的不足，但并不意味着评分模型可以完全替代所有的策略规则。其原因有风控流程的考虑、业务发展的考虑等，在本文我为大家从模型自身的盲区为大家作解释。 建模数据集与实际贷款人之间存在偏差# 在中国因为征信体系的不完善，金融机构的模型一般以实际贷款人作为模型数据集，而申请人母集到贷款人子集往往发生较大变化（就算是大家熟知的拒绝推断也只能尽量弥补但不能完全拒绝这方面的误差），模型的判断就会出现一些偏差，此时需要根据策略维度的一些拒绝线，对模型进行一些矫正和保护。 模型数据集来自历史，与未来实际情况存在偏差# 模型是基于历史数据找到数据之间的逻辑规律后，对未来事件进行预测。对于具有周期性的金融行业，如果用处于上升期的数据模型预测金融衰退期的事件，必然会与实际情况发生偏差。 举个例子，比如在经济上升或者繁荣期，消费者不仅有工作的单一收入，消费者可以从一些兼职等渠道获取额外的收入来源，此时即使有较高负债收入比的客群仍然可以维持较好的信用表现；但当经济开始进入下滑时期，未来消费者很难继续从其他渠道获取资金，即使历史数据告诉模型、模型告诉决策人，此时的借贷申请人有还款能力和意愿，但商业风险决策者应考虑收紧对于较高负债收入比人群的贷款。 模型对于目标变量的界定与实际商业目标存在偏差# 模型为了权衡观察期的代表性和表现期的时效性，在建模时为了囊括最近的贷款数据，在界定“坏账”定义时，仅考虑前12个月的还款表现（有时仅考虑前6个月），此时对于一些中额长期的信贷产品（比如24个月、36个月），模型目标变量的界定与实际商业目标就发生了偏差。 综上，从反面辩证性的角度分析模型与策略，二者缺一不可，谁也不可能完全替代对方。通过科学地搭配，共同构架起严谨的风险决策体系。","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/tags/risk/"},{"name":"strategy","slug":"strategy","permalink":"https://blog.sofunnyai.com/tags/strategy/"}]},{"title":"SpringCloud组件03---Hystrix实践","slug":"springcloud03-hystrix","date":"2020-03-23T09:34:41.000Z","updated":"2020-06-15T03:13:17.201Z","comments":true,"path":"article/springcloud-H-03-hystrix.html","link":"","permalink":"https://blog.sofunnyai.com/article/springcloud-H-03-hystrix.html","excerpt":"","text":"RxJava快速入门 基本概念 创建流程 Observer观察者 Observable 被观察者(事件源) 简介 概念 服务熔断 服务降级 熔断、降级的关系 降级方式 服务限流 如何实现的： 上图的步骤 隔离的实现 线程池隔离模式： 信号量隔离模式： 熔断 Hystrix源码 HystrixCommand类图 HystrixObservableCommand类图 HystrixCommand和HystrixObservableCommand 断路器HystrixCircuitBreaker 隔离 配置参数 因为Hystrix大量使用到观察者模式和RxJava，所以需要补充相关知识。 观察者模式可以看这里：《》 下面是RxJava的快速入门 RxJava快速入门# 基本概念# RxJava 有四个基本概念： Observable (可观察者，即被观察者)、 Observer (观察者)、 subscribe (订阅)、Event事件。Observable 和 Observer 通过 subscribe() 方法实现订阅关系，从而 Observable 可以在需要的时候发出事件来通 知 Observer。这里的事件就是对依赖的服务进行调用。 一个Observable可以发出多个事件，直到结束或者发生异常。 Observable每次发出一个事件就会调用Subscriber对象的onNext()方法。 每一个Observable的执行，最后都会通过调用一个Subscriber.onComplete()或者Subscriber.onError()结束事件的操作流。 RxJava 的事件回调方法除了普通事件 onNext() （相当于 onClick() / onEvent()）之外，还定义了两个特殊的事件：onCompleted() 和 onError()。 onCompleted(): 事件队列完结。RxJava 不仅把每个事件单独处理，还会把它们看做一个队列。RxJava 规定，当不会再有新的 onNext() 发出时，需要触发 onCompleted() 方法作为标志。 onError(): 事件队列异常。在事件处理过程中出异常时，onError() 会被触发，同时队列自动终止，不允许再有事件发出。 在一个正确运行的事件序列中, onCompleted() 和 onError() 有且只有一个，并且是事件序列中的最后一个。需要注意的是，onCompleted() 和 onError() 二者也是互斥的，即在队列中调用了其中一个，就不应该再调用另一个。 创建流程# Observer观察者# 观察者，它决定事件触发的时候将有怎样的行为。有两种方式，直接创建Observer接口，或者从抽象类Subscriber实现 12345678910111213141516Observer&lt;String&gt; observer = new Observer&lt;String&gt;() &#123; @Override public void onNext(String s) &#123; Log.d(tag, \"Item: \" + s); &#125; @Override public void onCompleted() &#123; Log.d(tag, \"Completed!\"); &#125; @Override public void onError(Throwable e) &#123; Log.d(tag, \"Error!\"); &#125;&#125;; Subscriber和上面的Observer二者只是抽象类提供了更多的拓展方法（onStart和unsubscribe）而已，创建过程是一样的。 Observable 被观察者(事件源)# 决定什么时候触发事件以及触发怎样的事件。 RxJava 使用 create() 方法来创建一个 Observable ，并为它定义事件触发规则： 123456789Observable observable = Observable.create(new Observable.OnSubscribe&lt;String&gt;() &#123; @Override public void call(Subscriber&lt;? super String&gt; subscriber) &#123; subscriber.onNext(\"Hello\"); subscriber.onNext(\"Hi\"); subscriber.onNext(\"Aloha\"); subscriber.onCompleted(); &#125;&#125;); 可以看到，这里传入了一个 OnSubscribe 对象作为参数。OnSubscribe 会被存储在返回的 Observable 对象中，它的作用相当于一个计划表: 当 Observable 被订阅的时候，OnSubscribe 的 call() 方法会自动被调用 事件序列就会依照设定依次触发（对于上面的代码，就是观察者Subscriber 将会被调用三次 onNext() 和一次 onCompleted()）。 这样，由被观察者调用了观察者的回调方法，就实现了由被观察者向观察者的事件传递，即观察者模式。 这里只是最简单的一个例子，事件的内容是字符串，而不是一些复杂的对象；事件的内容是已经定好了的，而不像有的观察者模式一样是待确定的（例如网络请求的结果在请求返回之前是未知的）；所有事件在一瞬间被全部发送出去，而不是夹杂一些确定或不确定的时间间隔或者经过某种触发器来触发的。 简介# 官网 https://github.com/Netflix/hystrix 因为调用链路越来越长，当某个微服务挂了，可能造成整个调用链路的请求拥挤和挂起，导致更多服务down掉，最终形成服务雪崩。 Hystrix是用于处理分布式系统的延迟和容错开源库，在超时、异常等场景下，Hystrix保证在一个依赖出问题的情况下，不会导致整体集群集体失败、避免级联故障、提高分布式系统的弹性 断路器是一种开关装置。实现快速失败，服务失败后，通过服务的故障监控，向调用方发送一个预期的、可处理的备选FallBack反馈，而不是长时间挂起或者抛出异常。 这样保证了服务调用方的线程不会长时间挂起、不必要的等待，避免了故障的蔓延和雪崩。 造成雪崩原因可以归结为以下三个： 服务提供者不可用（硬件故障，程序Bug，缓存击穿，用户大量请求） 重试加大流量（用户重试，代码逻辑重试） 服务调用者不可用（同步等待造成的资源耗尽） 最终的结果就是一个服务不可用导致一系列服务的不可用，而往往这种后果往往无法预料的。 概念# 服务熔断# 一般是指软件系统中，由于某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用的一种保护措施，所以很多地方把熔断亦称为过载保护。 服务降级# 划分优先级，忍痛割爱。整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。对方不可用的时候，给一个可预期的备选兜底FallBack。 什么时候会降级：程序异常/超时/熔断触发/线程池、信号量打满 要在调用方做降级（不然那个微服务都down掉了再做降级也没什么意义了） 比如说我们 user 调用payment 那么就在user 做降级. 熔断、降级的关系# 二者的目标是一致的，目的都是保证上游服务的稳定性。但其关注的重点并不一样，融断对下层依赖的服务并不级（或者说孰轻孰重），一旦产生故障就断掉；而降级需要对下层依赖的业务分级，把产生故障的丢了，换一个轻量级的方案，是一种退而求其次的方法。 根据业务场景的不同，一般采用以下两种模式： 降级方式# 第一种（最常用）如果服务失败，则我们通过fallback进行降级，返回静态值。 fallback进行降级，返回静态值： 级联方式降级： 如果第一个服务失败，则调用备用服务，例如失败重试或者访问缓存失败再去取数据库。 服务级联的目的则是尽最大努力保证返回数据的成功性，但如果考虑不充分，则有可能导致级联的服务崩溃（比如，缓存失败了，把全部流量打到数据库，瞬间导致数据库挂掉）。 因此级联模式，也要慎用，增加了管理的难度。 Hystrix执行以下操作： 提供保护并控制通过第三方客户端库访问（通常是通过网络）的依赖项带来的延迟和失败。 停止复杂的分布式系统中的级联故障。 快速失败并快速恢复。 FallBack回退并在可能的情况下正常降级。 启用近乎实时的监视，警报和操作控制。 Hystrix的工作原理： 防止任何单个依赖项耗尽所有容器（例如Tomcat）用户线程。 减少负载并快速失败，而不是排队。 在可行的情况下提供备用，以保护用户免受故障的影响。 隔离：例如隔板bulkhead，泳道swimlane和断路器模式circuit breaker patterns，（线程池隔离和信号量隔离）限制调用分布式服务的资源使用，某一个调用的服务出现问题不会影响其他服务调用。 降级机制：超时降级、资源不足时(线程或信号量)降级，降级后可以配合降级接口返回托底数据。 融断：当失败率达到阀值自动触发降级(如因网络故障/超时造成的失败率高)，熔断器触发的快速失败会进行快速恢复。 缓存：提供了请求缓存、请求合并实现。 通过近实时监控指标，警报优化 服务限流# 秒杀等高并发场景，严禁一窝蜂，需要排队，一秒钟只能N个有序运行。 如何实现的：# 将对外部系统（或“依赖项”）的所有调用包装在通常在单独线程中执行的HystrixCommand或HystrixObservableCommand对象中（这是命令模式的示例）。 超时调用时间阈值。 有默认值，但可以自定义为超过99.5％的调用时间。 为每个依赖项维护一个小的线程池（或信号量）； 如果已满，发往该依赖项的请求将立即被拒绝，而不是排队。 测量成功，失败（客户端抛出的异常），超时和线程拒绝。 如果某个服务的错误百分比超过阈值，则使断路器跳闸，以在一段时间内手动或自动停止所有对特定服务的请求。 当请求失败，被拒绝，超时或短路时执行回退逻辑。 几乎实时监控指标和配置更改。 更多见： https://github.com/Netflix/Hystrix/wiki/How-it-Works#flow1 上图的步骤# 构造一个HystrixCommand或HystrixObservableCommand对象 执行命令，有四种方式。分别可以返回单个和多个返回。HystrixObservableCommand两个方法分别获取Hot和Cold的Observable。 响应是否已缓存：如果为此命令启用了请求缓存，并且如果对请求的响应在缓存中可用，则该缓存的响应将立即以的形式返回Observable。 断路器是否开启：当执行该命令时，Hystrix会检查断路器，以查看断路器是否断开。 如果断开（或“跳闸”），那么Hystrix将不执行命令，而是将流路由到（8）获取回退。如果电路是闭合的，则流程进行到（5），以检查是否有足够的容量来运行该命令。 线程池/队列/信号量是否已满：如果与该命令关联的线程池和队列（或信号量，如果未在线程中运行）已满，则Hystrix将不执行该命令，但会立即将流路由到（8）获取回退。 HystrixObservableCommand.construct()或HystrixCommand.run()，run返回单个响应或引发异常。construct返回一个Observable，它发出响应或发送onError通知。 计算电路健康度：Hystrix向断路器报告成功，失败，拒绝和超时，断路器保持滚动的一组计算统计信息的计数器。它使用这些统计信息来确定电路何时应“跳闸”，在此点它会将随后的所有请求短路，直到经过恢复期为止，在此之后，在首先检查某些运行状况检查之后，它将再次闭合电路。 获取后备：两个处理降级的类区别： construct或者run引发异常 断路器断开 线程池或者信号量满了 命令时间超时 HystrixCommand.getFallback()或者HystrixObservableCommand.resumeWithFallback()进行后备实现，最终的后备应该不依赖网络静态，否则会级联失败。 如果没准备后备，缺省抛出异常，会到OnError通知，非常糟糕要避免。 获取成功后的响应：参见 HystrixCommand和HystrixObservableCommand两个处理降级的类区别 这里有一个关联源码的动态序列图 https://design.codelytics.io/hystrix/how-it-works 降级出现的场景： 上图4，命令处于“熔断、短路”状态的时候 上图5，当前命令的线程池、请求队列或者信号量被占满的时候。 上图6，当HystrixObservableCommand.construct()或者HystrixCommand.run()发生异常的时候。 隔离的实现# 线程池隔离模式：# 使用一个线程池来存储当前的请求，线程池对请求作处理，设置任务返回处理超时时间，堆积的请求堆积入线程池队列。这种方式需要为每个依赖的服务申请线程池，有一定的资源消耗，好处是可以应对突发流量（流量洪峰来临时，处理不完可将数据存储到线程池队里慢慢处理） 信号量隔离模式：# 使用一个原子计数器（或信号量）来记录当前有多少个线程在运行，请求来先判断计数器的数值，若超过设置的最大线程个数则丢弃改类型的新请求，若不超过则执行计数操作请求来计数器+1，请求返回计数器-1。这种方式是严格的控制线程且立即返回模式，无法应对突发流量（流量洪峰来临时，处理的线程超过数量，其他的请求会直接返回，不继续去请求依赖的服务） 区别（两种隔离方式只能选其一）： 线程池隔离 信号量隔离 线程 与调用线程非相同线程 与调用线程相同（jetty线程） 开销 排队、调度、上下文开销等 无线程切换，开销低 异步 支持 不支持 并发支持 支持（最大线程池大小） 支持（最大信号量上限） 熔断# 正常状态下，电路处于关闭状态(Closed)，如果调用持续出错或者超时，电路被打开进入熔断状态(Open)，后续一段时间内的所有调用都会被拒绝(Fail Fast)，一段时间以后，保护器会尝试进入半熔断状态(Half-Open)，允许少量请求进来尝试，如果调用仍然失败，则回到熔断状态，如果调用成功，则回到电路闭合状态; HystrixCircuitBreaker（断路器的具体实现），下图是官网How-it-works里面的： 详细的工作流程： http://hot66hot.iteye.com/blog/2155036 Hystrix源码# HystrixCommand类图# 用于返回一个操作结果 类图，抽象类HystrixCommand继承了AbstractCommand，实现了三个核心接口HystrixExecutable、HystrixInvokableInfo、HystrixObservable HystrixObservableCommand类图# 用于返回多个操作结果对象 HystrixInvokableInfo是一个空接口，只是一个标记。 HystrixInvokable也一样，空接口是一个标记。 HystrixCommand和HystrixObservableCommand# 两个处理降级的类区别：# HystrixCommand有2个方法： public R execute()： 用于同步执行命令。其实是用queue()返回的Future.get()实现同步。会等待任务执行完毕。 public Future&lt;R&gt; queue()：用于异步执行命令。底层是通过 toObservable()拿到一个ColdObservable对象，通过toBlocking()转换为BlockingObservable，它可以把数据通过阻塞的方式发射出去。但是这里使用toFuture()转换成了一个Future返回，不会阻塞。使得消费者可以异步操作。这种转换要求只能发出一个数据，所以execute和queue都只能返回单一结果。 HystrixObservableCommand又提供了2个方法： public Observable&lt;R&gt; observe()：返回Observable对象，eagerly的。代表了操作的多个结果。订阅Observable，可用于通过回调异步执行命令。返回的是一个Hot Observable（不管是否有订阅者都会触发事件，每一个订阅者都可能是中途开始的，只看到整个操作的局部） public Observable&lt;R&gt; toObservable()：返回的也是Observable对象，lazily的。代表了操作的多个结果。返回的是一个Cold Observable（会等待，直到有订阅者才开始发布事件，对订阅者保证都是从一开始都看到整个操作的全程。） Observable可以发送过个数据，获取多个结果。 二者降级的方法也不同：# HystrixCommand：通过R getFallback()完成降级，直接返回业务R对象。 HystrixObservableCommand：通过Observable&lt;R&gt; resumeWithFallback()完成降级，返回Observable对象来发射一个或者多个降级结果。 如果我们没有为命令实现降级方法，缺省实现是抛异常。或者降级失败也会抛异常，最终会进入到onError()方法中因其命令失败，要避免。 在服务降级的逻辑中，我们需要一个通用的结果。通常是静态或从缓存中获取的兜底数据，而不是依赖于网络。如果一定要依赖网络，那么依赖的服务也必须放到Hystrix的命令中，级联降级。最终最后兜底的那个一定是一个不依赖于网络的，否则可能降级失败。 断路器HystrixCircuitBreaker# **关键词：**统计值、状态位、CAS、SingleTest、SleepWindow HystrixCircuitBreaker是一个接口，接口文件中有两个实现类HystrixCircuitBreakerImpl和NoOpCircuitBreaker，以及一个Factory。 Factory没啥意思，就是一个CurrentHashMap使用命令的key来缓存和实例化断路器。 来看一下缺省断路器实现类HystrixCircuitBreakerImpl就能搞定它的原理了，先大概描述一下再上代码： 有四个核心方法： allowRequest()：是否允许访问，主要判断超参数开关。参数设定强制断开、联通的话不回去判断断路器。否则才判断断路器isOpen或者singleTest。没啥意思。 isOpen(): true=断开，断开的立刻返回失败。没断开的判断窗口内是否超量(缺省10秒20)，没超量也返回ok。超量的看错误率(缺省50%)超标则标记失败状态(CAS标识和失败时间)并返回，否则返回ok。 allowSingleTest()：是否允许测一把，在上面isOpen里面如果错误量超标，会CAS标记断开，同时记录断开时间。然后当前请求时间&gt;断开时间+sleepWindow(缺省5秒)后属于半开状态，此时的请求只允许测试一次，成功就恢复，没成功继续修改断开时间。【也是CAS修改时间戳，保证只会发起一次测试】 markSuccess()：请求成功后就标记成功并清空计数器（CAS标记成功防止重复清空）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899static class HystrixCircuitBreakerImpl implements HystrixCircuitBreaker &#123; private final HystrixCommandProperties properties; //实例化的时候带进来的，一大堆配置参数和开关 private final HystrixCommandMetrics metrics; //实例化的时候带进来的，一堆指标 /* track whether this circuit is open/closed at any given point in time (default to false==closed) */ private AtomicBoolean circuitOpen = new AtomicBoolean(false); // true的时候就是open，也就是断路器断开了 /* when the circuit was marked open or was last allowed to try a 'singleTest' */ private AtomicLong circuitOpenedOrLastTestedTime = new AtomicLong(); // 一个时间戳 protected HystrixCircuitBreakerImpl(HystrixCommandKey key, HystrixCommandGroupKey commandGroup, HystrixCommandProperties properties, HystrixCommandMetrics metrics) &#123; this.properties = properties; this.metrics = metrics; &#125; // 标记成功 public void markSuccess() &#123; if (circuitOpen.get()) &#123; //true=open=断开 if (circuitOpen.compareAndSet(true, false)) &#123; // 注意使用了CAS避免并发问题，恢复断路器。 //win the thread race to reset metrics // CAS拿到了执行权 //Unsubscribe from the current stream to reset the health counts stream. This only affects the health counts view, //退订当前流以重置运行状况计数流。这只会影响健康计数相关的信息 //and all other metric consumers are unaffected by the reset //并且所有其他指标使用者均不受重置的影响 metrics.resetStream(); &#125; &#125; &#125; @Override public boolean allowRequest() &#123; if (properties.circuitBreakerForceOpen().get()) &#123; // 参数里面看看是不是强制断开的，是的话拒绝。 // properties have asked us to force the circuit open so we will allow NO requests return false; &#125; if (properties.circuitBreakerForceClosed().get()) &#123; // 参数里面是不是强制关闭的，是的话允许。 // we still want to allow isOpen() to perform it's calculations so we simulate normal behavior // 计数 isOpen(); // properties have asked us to ignore errors so we will ignore the results of isOpen and just allow all traffic through return true; &#125; return !isOpen() || allowSingleTest(); // 否则看是否闭合，或者是否允许单一测试（单一测试是挂了很久了，再来一个请求允许试一把看看恢复了没） &#125; // 挂了很久，测一把看看是否恢复了。 public boolean allowSingleTest() &#123; long timeCircuitOpenedOrWasLastTested = circuitOpenedOrLastTestedTime.get(); // 从Atomic时间戳了拿出来上次失败时间 // 1) if the circuit is open // 断路器断开了，而且已经断开了很久，超过了参数配置的睡眠窗口时间。就会允许测试一把 // 2) and it's been longer than 'sleepWindow' since we opened the circuit if (circuitOpen.get() &amp;&amp; System.currentTimeMillis() &gt; timeCircuitOpenedOrWasLastTested + properties.circuitBreakerSleepWindowInMilliseconds().get()) &#123; // 如果测试成功，就会把断路器合上，恢复服务。否则把失败时间往后赋值，再等下一次时间窗口后进行singleTest // We push the 'circuitOpenedTime' ahead by 'sleepWindow' since we have allowed one request to try. // If it succeeds the circuit will be closed, otherwise another singleTest will be allowed at the end of the 'sleepWindow'. if (circuitOpenedOrLastTestedTime.compareAndSet(timeCircuitOpenedOrWasLastTested, System.currentTimeMillis())) &#123; // if this returns true that means we set the time so we'll return true to allow the singleTest // if it returned false it means another thread raced us and allowed the singleTest before we did return true; // 允许 &#125; &#125; return false; // 另一个线程已经测试了 &#125; // 断路器是否闭合 @Override public boolean isOpen() &#123; if (circuitOpen.get()) &#123; // 如果是断开的(true)，我们会立即返回true断开，而不必费心尝试“关闭”自己，因为这允许allowSingleTest和随后的成功测试关闭 // if we're open we immediately return true and don't bother attempting to 'close' ourself as that is left to allowSingleTest and a subsequent successful test to close return true; &#125; // 如果我们是闭合的，看一眼是否有错误使我们跳闸，以便使电路断开 // we're closed, so let's see if errors have made us so we should trip the circuit open HealthCounts health = metrics.getHealthCounts(); // 检查是否超过总统计量的阈值参数，没有超过总量就立即返回false（没断开），不用计算别的 // check if we are past the statisticalWindowVolumeThreshold if (health.getTotalRequests() &lt; properties.circuitBreakerRequestVolumeThreshold().get()) &#123; // we are not past the minimum volume threshold for the statisticalWindow so we'll return false immediately and not calculate anything return false; &#125; // 如果超过了总量，再来计算错误比例 if (health.getErrorPercentage() &lt; properties.circuitBreakerErrorThresholdPercentage().get()) &#123; return false; // 错误比例没超标，直接返回ok的，没断开 &#125; else &#123; // our failure rate is too high, trip the circuit if (circuitOpen.compareAndSet(false, true)) &#123; // 错误率太高，CAS把断路器关闭掉。CAS成功的话 // if the previousValue was false then we want to set the currentTime circuitOpenedOrLastTestedTime.set(System.currentTimeMillis()); // 设置断路时间 return true; // 返回断路了 &#125; else &#123; // How could previousValue be true? If another thread was going through this code at the same time a race-condition could have // caused another thread to set it to true already even though we were in the process of doing the same // In this case, we know the circuit is open, so let the other thread set the currentTime and report back that the circuit is open return true; // 这里是被别的CAS抢占了，但是也要告诉当前的调用者这次是断开的。 &#125; &#125; &#125; &#125; 隔离# 配置参数# 很多参数，去这里查： https://github.com/Netflix/Hystrix/wiki/Configuration https://www.jianshu.com/p/e07661b9bae8 https://www.jianshu.com/p/3e11ac385c73uyi","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/tags/SpringCloud/"}]},{"title":"SpringCloud组件02---OpenFeign实践","slug":"springcloud02-openfeign","date":"2020-03-22T04:22:51.000Z","updated":"2020-06-02T06:37:51.174Z","comments":true,"path":"article/springcloud-H-02-open-feign.html","link":"","permalink":"https://blog.sofunnyai.com/article/springcloud-H-02-open-feign.html","excerpt":"","text":"OpenFeign简介 Ribbon和Feign的区别 Ribbon Feign OpenFeign 实践案例 Server端： 提供方 feign常见配置 超时控制 Feign日志控制 Feign更多 OpenFeign简介# Feign已经不再更新，进入维护状态。SpringCloud版本 OpenFeign作为后起之秀接替他。 Feign是声明性Web服务客户端。 它使编写Web服务客户端更加容易。 要使用Feign，请创建一个接口并对其进行注释。 它具有可插入的注释支持，包括Feign注释和JAX-RS注释。 Feign还支持可插拔编码器和解码器。 Spring Cloud添加了对Spring MVC注释的支持，并支持使用Spring Web中默认使用的相同HttpMessageConverters。 Spring Cloud集成了Ribbon和Eureka以及Spring Cloud LoadBalancer，以在使用Feign时提供负载平衡的http客户端。 https://github.com/OpenFeign/feign https://cloud.spring.io/spring-cloud-openfeign/2.2.x/reference/html/ Ribbon和Feign的区别# Ribbon# 是一个基于 HTTP 和 TCP 客户端 的负载均衡的工具。主启动类上使用@RibbonClient开启 它可以 在客户端 配置 RibbonServerList（服务端列表），使用 HttpClient 或 RestTemplate 模拟http请求，步骤相当繁琐。 Ribbon 可以用来做客户端负载均衡，调用注册中心的服务 Ribbon的使用需要代码里手动调用目标服务，请参考官方示例：https://github.com/Netflix/ribbon Feign# Feign 是在 Ribbon的基础上进行了一次改进，是一个使用起来更加方便的 HTTP 客户端。 采用接口的方式， 只需要创建一个接口，然后在上面添加注解即可 ，就能完成对服务方的接口绑定。只需要将需要调用的其他服务的方法定义成抽象方法即可， 不需要自己构建http请求。 然后就像是调用自身工程的方法调用，而感觉不到是调用远程方法，使得编写 客户端变得非常容易。Feign自动封装底层Http请求。 Feign是Spring Cloud组件中的一个轻量级RESTful的HTTP服务客户端 Feign内置了Ribbon，用来做客户端负载均衡，去调用服务注册中心的服务。 Feign支持的注解和用法请参考官方文档：https://github.com/OpenFeign/feign Feign本身不支持Spring MVC的注解，它有一套自己的注解 OpenFeign# OpenFeign是Spring Cloud 在Feign的基础上支持了Spring MVC的注解，如@RequesMapping等等。 OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口， 并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务。 实践案例# 主启动类开启@EnableFeignClients 写服务接口，对应提供方的Controller，接口上@FeignClient(服务名)和@Component实例化。 把这个service接口注入到业务中即可使用。（这个Service会有springcloud动态代理生成实现并实例化） Server端：# pom新增open-feign支持： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;dependencies&gt; &lt;!--open feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--上面的eureka-client会自动引入ribbon--&gt; &lt;!-- &lt;dependency&gt;--&gt; &lt;!-- &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;--&gt; &lt;!-- &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;--&gt; &lt;!-- &lt;/dependency&gt;--&gt; &lt;!--业务common类，引用当前项目的版本号--&gt; &lt;dependency&gt; &lt;groupId&gt;com.sam.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--MVC--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--TEST--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--DEV-TOOLS--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类 123456789101112@SpringBootApplication@EnableFeignClients // 开启feign功能public class CustomerOpenFeign8084 &#123; /** * 依赖Eureka7001\\7002，Peyment服务方8001\\8002四个服务 * @param args */ public static void main(String[] args) &#123; SpringApplication.run(CustomerOpenFeign8084.class,args); &#125;&#125; Service接口 1234567891011121314/** * 使用OpenFeign调用Server只用一个接口，Feign会使用代理模式给我们生成一个实现。 */@Component@FeignClient(\"CLOUD-PAYMENT-SERVICE\") // server端的服务名称public interface PaymengFeignService &#123; @PostMapping(value=\"/payment/add\") // server端的服务地址 public CommonResult&lt;Payment&gt; addPayment(@RequestBody Payment payment); @GetMapping(value = \"/payment/get/&#123;id&#125;\") // server端的服务地址 public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") long id);&#125; 提供方# controller： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Controller@Slf4j@RequestMapping(\"/payment\")public class PaymentController &#123; @Resource private PaymentService paymentService; @Value(\"$&#123;server.port&#125;\") private String serverPort; @Resource private DiscoveryClient discoveryClient; /** * 因为是接受调用的server，这里使用@RequestBody接受json，否则字段会丢失 * http://localhost:8002/payment/add * &#123;\"serial\":\"lalala\"&#125; content-type: application/json才行 * @param payment * @return */ @PostMapping(value=\"/add\") @ResponseBody public CommonResult&lt;Payment&gt; addPayment(@RequestBody Payment payment)&#123; int result = paymentService.add(payment); log.info(\"---------插入:\"+result); if(result &gt; 0)&#123; return CommonResult.success(\"插入payment成功！serverPort=\"+serverPort); &#125;else&#123; return CommonResult.businessFail(\"插入payment失败\"); &#125; &#125; @GetMapping(value = \"/get/&#123;id&#125;\") @ResponseBody public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") long id)&#123; Payment payment = paymentService.getById(id); if(payment != null)&#123; return CommonResult.success(\"ok,serverPort=\"+serverPort, payment); &#125;else&#123; return CommonResult.businessFail(\"查询失败！\"); &#125; &#125;&#125; feign常见配置# 12345678910111213141516feign: client: config: feignName: # 这里是可变的，如default connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false encoder: com.example.SimpleEncoder decoder: com.example.SimpleDecoder contract: com.example.SimpleContract 超时控制# 因为feign底层是使用的ribbon，调用方的application.yml中配置ribbon的超时时间： 12345678910111213# 超时配置，以下二选一#ribbon:# ReadTimeout: 5000 # 连接建立后请求数据的时间# ConnectTimeout: 5000 # 建立连接的时间# 或者使用feign原生配置，https://cloud.spring.io/spring-cloud-openfeign/2.2.x/reference/html/feign: client: config: default: # 可变的name connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic Feign日志控制# yml对应包打开日志 123logging: level: com.sam.springcloud.service.PaymengFeignService: debug feign配置日志级别，使用上面的yml配置文件控制，或者下面人肉注入： 12345678910111213import feign.Logger;@Configurationpublic class FeignConfig &#123; /** * 可选，设置Feign的日志级别 * @return */ @Bean public Logger.Level feignLoggerLevel()&#123; return Logger.Level.FULL; &#125;&#125; Feign更多# Encoder、Decoder、和Hystyix结合，消息压缩，见 https://cloud.spring.io/spring-cloud-openfeign/2.2.x/reference/html/#spring-cloud-feign-hystrix","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/tags/SpringCloud/"}]},{"title":"互联网金融资产质量评估指标---fpd、vintage、rollrate和迁移率等等","slug":"风控指标vintage和rollrate","date":"2020-03-21T17:25:33.000Z","updated":"2020-05-25T06:57:03.990Z","comments":true,"path":"article/vintage_rollrate_fpd.html","link":"","permalink":"https://blog.sofunnyai.com/article/vintage_rollrate_fpd.html","excerpt":"","text":"目录# 概述 基础概念 风险分析有常见的5要素： 其他的相关概念 延滞率 即期指标（coincidental）： 递延指标（lagged）： 账龄(Month of Book，MOB) FPD 首逾率（反欺诈相关） 入催率 逾期时间 vintage 成熟期 观察点与表现期： vintage举例 roll rate滚动率 滚动率定义—状态变化 如何确定bad和good标签的账龄 vintage和roll rate的区别： roll rate已经确定了bad为什么还需要通过Vintage分析来确定表现期？ Vintage里所有的账户，我们的目的是抓住尽可能多的坏客户。 Flow Rate迁移率 坏账准备金 坏账准备金的概念----各期逾期余额乘以各自准备金率 准备金比例 资产组合管理相关 参考文章链接： 概述# 想写一个vintage和roll rate的文章，查到求是汪大佬写的非常详细，图文并茂。直接偷懒摘录了一个脱水版，想看原文的在这里。下面开始干货。 本文主要讲述账龄vantage、滚动率roll rate、迁移率flow rate三个指标的关系。 账龄分析（Vintage Analysis）：用以分析账户成熟期、变化规律等。 滚动率分析（Roll Rate Analysis）：用以定义账户好坏程度。 迁移率分析（Flow Rate Analysis）：用以分析不同逾期状态之间的转化率。 基础概念# 风险分析有常见的5要素：# 下单月： 观察月： 放款额（GMV）：就是零售业说的“流水”，成交总额包括销售额、取消订单金额、拒收订单 金额和退货订单金额。 在贷余额（Balance）/ ENR：至某时点借款人尚未偿还的本金 逾期天数（DPD） 其他的相关概念# C,M1,M2,M3…的贷款余额：根据逾期期数(C,M1,M2,M3…)，计算每条借款的当时的贷款余额。（贷款余额 = 放款时合同额 –已还本金） 核销金额: 贷款逾期M7+（坏账）后经审核进行销帐，核销金额即在核销日期当天的贷款余额。 回收金额 Recovery：来自历史所有已核销合同的全部实收金额。（核销后又回收的部分） 净坏账 NCL：当月新增核销金额 – 当月回收金额（坏账减去回收） 延滞率# 延滞率（delinquent%）的计算可分为coincidental以及lagged两种方式，除了各bucket延滞率之外，也会观察特定bucket以上的延滞率，如M2+lagged%以及M4+lagged%等指标，以M2+lagged%为例，分母为两个月前应收账款，分子为本月M2（含）以上尚未转呆账的逾期金额。 在消费金融风险管理上，M2以及M4为两个重要的观测点，原因是客户可能因为一时忙碌或疏忽造成账款逾期，但若经过M1催收仍旧落入M2以上，几乎可以确认为无力缴款或者蓄意拖欠。另外依据经验，客户一旦落入M4，事后转呆账几率非常高。 下面部分来自知乎京东白条的回复： 逾期率有两种方法：即期逾期率指标Coin(X)%和递延逾期率指标Lagged(X)% 这个指标分子 = 时点逾期余额，分母 = 时点透支余额。逾期率最直观，但也最容易被“操控”： 分子会受到统计粒度的影响（以客户/账户/贷款单/贷款分期单哪个粒度来计算差异很大，尤其是偏重分期的产品），也会受到核销等资产处置的影响（是否有核销处理、统计时是否包含）。 分母会受到当期时点规模的影响，季末/年末冲量或特殊的营销时点上，都会导致规模的激增，人为拉低时点的逾期率。 在产品高速发展时期，规模增长迅速，而风险滞后释放，导致对风险的低估和滞后判断；而在产品成熟和衰退期，导致对风险的高估，容易误导风险策略的制定。 由于上述原因的存在，一般逾期率只能说明累积的整体风险水平如何。如果根据时点的不良率判断近期风险水平，存在高估/低估的可能。-------------逾期率只能是整体一个粗略的观察，具体来说逾期的结构更重要。 如果一定要用时点余额来判断近期的风险，建议使用延滞率或逾期的净生成率： Mi延滞率=当期Mi/i月前的M0 Mi净生成率=(当期Mi-i月前的Mi)/i月前的透支余额 这两个指标至少能在一定程度上排除当期时点规模、历史存量的影响，能更真实反映近期的风险水平。 新增客户/资产的风险水平如何？# 整体的逾期率并不一定能回答或甄别近期客户/资产的风险水平。需要通过VINTAGE拆解客户和资产，观察相同的表现期后不同客群/资产的逾期占比，例如激活或放款后1~24个月各月月末时点的0+/30+/90+贷款户数和金额或余额的占比。 通过对比不同激活月或放款月在相同的表现窗口后的逾期水平，能观察不同激活月/放款月（对应了不同的策略或人群）的风险走势，更合理评价不同时点人群/资产的情况和策略的效果。 如果运营是针对的客户的，按照激活时间划分客群统计VINTAGE更通用一些；如果是针对资产进行运营，按照贷款的放款月划分资产统计VINTAGE更通用一些。 存量资产的迁移情况？# 除了需要时刻关注新增的风险外，也需要掌握已经逾期资产的迁移/退出情况，也就是滚动率(或者迁徙率、迁移率)。 滚动率一方面体现了客群和资产的质量，也能反映催收运营的状况。 常见的滚动率一般是当期账龄余额与上一期上一账龄余额的比值，用百分比表示。账龄越高，滚动率越高，表示资产回收的可能性越低，进入下一期高账龄的概率越高。 滚动率也可以进一步细分为向上/向下滚动，一般默认的滚动率都是向上滚动，即从低账龄滚到高账龄。向上/向下滚动需要锁定月末时点某一账龄的客户/资产，在下月底观察锁定的这部分客户或资产，统计向上/向下滚动的占比，能排除统计粒度和分期带来的降期影响。 另外，滚动率与产品、前中后的运营等诸多因素有关，短期容易波动，可以计算复合滚动率，例如M0-&gt;M4的滚动率，能从长周期来观察资产质量和运营的稳定水平。 即期指标（coincidental）：# 计算延滞率时常用的两种方法之一，以当期各bucket延滞金额÷应收账款（AR）。 如逾期率Coin©%、Coin(M1)%、Coin(M2)%、Coin(M3)%等等： 当月不同逾期期数的贷款余额/当月底总贷款余额 例： Coin©%=当月C贷款余额/当月底贷款余额(C-M6)-------------------正常用户余额占所有贷款余额 Coin(M1)%=当月M1贷款余额/当月底贷款余额(C-M6) Coin(M1+)%=当月M1−M6贷款余额/当月底贷款余额(C-M6)------------------逾期M1以上的用户余额占所有贷款余额 递延指标（lagged）：# 计算延滞率时常用的两种方法之一，延滞金额÷上月应收账款。若单纯想了解各月资产质量结构，可使用coindental，但若想精准溯及逾放源头的话，建议采用lagged。 与coincident相同也是计算延滞率的一个指标，区别是lagged的分母为产生逾期金额的那一期的应收账款。Lagged观察的是放贷当期所产生的逾期比率，所以不受本期应收账款的起伏所影响。 逾期率Lagged(M1)%、Lagged(M2)%、Lagged(M3)%、Lagged(M4)%、Lagged(M5)%、Lagged(M6)% Lagged DPD30+ = 当前逾期&gt;=30天的客户的本金余额 / 30天前的累计放款本金 当月不同逾期期数的贷款余额/往前推N个月的总贷款余额可以提出当前时点的影响。 例: Lagged(M1)%=当月M1的贷款余额/上个月底时点的贷款余额 -----------------其实就是平台当月M1/1月前的M0 Lagged(M4)%=当月M4的贷款余额/往前推四期的总贷款余额 Lagged(M4+)%=当月M4的贷款余额/往前推四期的总贷款余额 + 当月M5的贷款余额/往前推五期的总贷款余额 + 当月M6的贷款余额/往前推六期的总贷款余额 逾期结算# 实际风险有两种结算方式： Month end：月底结算 （常用方式，主要以自然月月底的逾期指标为主） Cycle end：期末结算（单个借款人还款日时间不同，在月底结算的数据不准确，所以一般设置20日还款，留出10天给催收部门） 早期逾期多数为借款人忘记还款，或短时间资金周转不周，这是与策略密切相关的。通过借款人债偿能力评估识别出借款人有足够资金，可以不做提醒，以获取滞纳金，对于借款人资产表现不好的，可以设置提前10天提醒还款。 逾期天数90-119天，为资产M4阶段。M4-M6的阶段都称之为不良。M4是一个重要的节点，因为消金公司，上报给银监会，或上市公司披露财务数据、风险数据时，都会选择披露不良率。如果有些公司要在审计认可这个方法论时，会对M4做一些调整。 通常180天以上都作为坏账处理，坏账也是被披露的数据之一，还包含一些特别的计提。 账龄(Month of Book，MOB)# 指资产放款月份。放款日截止观察点的月数。如： MOB0：放款日至当月月底 MOB1：放款后第二个完整的月份 MOB2：放款后第三个完整的月份 FPD 首逾率（反欺诈相关）# FPD是指首期逾期率，是说在某一个还款日，仅第一期到期的客户中有多少没有按时还款。与入催率的差别在于，入催率包含了第一期、第二期、第三期等等所有到期的M0。FPD一般用来做反欺诈，因为欺诈用户他第一期是根本不会还款的。 用户授信通过后，首笔需要还款的账单，在最后还款日后7天内未还款且未办理延期的客户比例即为FPD 7，分子为观察周期里下单且已发生7日以上逾期的用户数，分母为当期所有首笔下单且满足还款日后7天，在观察周期里的用户数。常用的FPD指标还有FPD 30。 举例： 假设用户在10.1日授信通过，在10.5日通过分期借款产生了首笔分3期的借款，且设置每月8日为还款日。则11.08是第一笔账单的还款日，出账日后，还款日结束前还款则不算逾期。如11.16仍未还款，则算入10.1-10.30周期的FPD7的分子内。通常逾期几天的用户可能是忘了还款或一时手头紧张，但FPD 7 指标可以用户来评价授信人群的信用风险，对未来资产的健康度进行预估。 与FPD 7 类似，FPD 30也是对用户首笔待还账单逾期情况进行观察的指标。对于逾期30天内的用户，可以通过加大催收力度挽回一些损失，对于逾期30天以上的用户，催收回款的几率就大幅下降了，可能进行委外催收。如果一段时间内的用户FPD 7较高，且较少催收回款大多落入了FPD 30 内，则证明这批用户群的non-starter比例高，借款时压根就没想还，反之则说明用户群的信用风险更严重。 入催率# 有了前面的铺垫，入催率就比较简单了。它指的是在某一个还款日，客户从M0变成M1的比例。比如说，今天，有N个M0客户到了还款日，里面有M个客户按时还款了，那么今天的入催率就是（N-M）/N。它与上面的FPD是有区别的。 逾期时间# DPD、M0（未逾期）、M1（逾期一个月类）、M2（逾期两个月内）。。。 一般M3+就要委外了，M6+(180天以上)就要记为坏账了。 vintage 成熟期# 其实就是逾期率随着账龄变化的趋势图。常见的作用有： 逾期率：vintage的纵轴随着横轴账龄的增大肯定是变大的，最终的平稳后的逾期率（最大值）就是逾期率。（有资产逾期率、账户逾期率两种口径） 欺诈：如果前两期逾期率陡增，短期风险没处理好，是欺诈（特别是第一期就违约的） 信用风险：如果一直上升、很久不拐，说明信用风险控制不太好。 成熟期： 因素判断：风险策略变化、客群变化、市场环境、政策法规变化时，资产质量的变化。（看vintage曲线的波动） 观察点与表现期：# 观察点、观察期、表现期：通常是在整个MOB中选取一个月份作为观察点，前面的期限是观察期，后面的期限是表现期。也就是在时间轴上选取一个点，这个点是观察点。前面的是观察期，后面的是表现期。 表现期越长，信用风险暴露将越彻底，但意味着观察期离当前越远，用以提取样本特征的历史数据将越陈旧，建模样本和未来样本的差异也越大。(模型PSI高) 反之，表现期越短，风险还未暴露完全，但好处是能用到更近的样本。（模型PSI低） vintage举例# 下面是求是汪大佬的一个例子： 对于一个12期分期还款的信贷产品，理论上当用户在12期结束，并还清所有的钱后，我们才能定义为绝对的好客户；反之，我们只能说到目前为止是一个好客户，但并不能知道未来几期用户会不会逾期不还钱。 汪大佬的这个图中可以看到： 账龄最长为12个月，代表产品期限为12期。 根据2018年5月放贷的订单完全走完账龄生命周期，而2018年6月却没走完，说明数据统计时间为2019年6月初。 账龄MOB1、MOB2、MOB3的逾期率都为0，说明逾期指标为M4+（逾期超过90天）风险。 由放贷月份从2018年1月～12月的账户的最终逾期率都在降低，说明资产质量在不断提升，可能是因为风控水平在不断提升。 2018年5月相对于2018年1～4月的逾期率大幅度下降，说明该阶段风控策略提升明显。 不同月份放款的M4+在经过9个MOB后开始趋于稳定（后面违约率不再大幅上升），说明账户成熟期是9个月。 roll rate滚动率# 滚动率定义—状态变化# 滚动率：就是从某个观察点之前的一段时间**（观察期）的最坏的状态，向观察点之后的一段时间（表现期）的最坏的**状态的发展变化情况。（就是说从上一状态向下一状态发展的一个度量，说最坏是因为可能用户逾期多笔） 滚动率分析的具体操作步骤为： step 1. 确定数据源。一般利用客户还款计划表（repayment schedule）。 step 2. 选择观察点，以观察点为截止时间，统计客户在观察期（如过去6个月）的最长逾期期数，按最坏逾期状态将用户分为几个层次，如C（未逾期）、M1、M2、M3、M4+。 step 3. 以观察点为起始时间，统计客户在表现期（如未来6个月）的最长逾期期数，按最坏逾期状态将用户分为几个层次，如C、M1、M2、M3、M4+。 step 4. 交叉统计每个格子里的客户数，如图6中表1所示。 step 5. 统计每个格子里的客户占比，如图6中表2所示。 step 6. 为了排除观察点选择时的随机影响，一般会选择多个观察点。重复step1 ～5。 上面的图说明： 逾期状态为M0的客户，在未来6个月里，有96%会继续保持正常状态，4%会恶化为M1和M2； 逾期状态为M1的客户，未来有81%会回到正常状态，即从良率为81%，有7%会恶化，13%会保持M1状态； 逾期状态为M2的客户，从良率为23%，有39%会恶化为M3和M4+； 逾期状态为M3的客户，从良率为14.7%，有60.7%会恶化为M4+； 逾期状态为M4+的客户，从良率仅为4%，有80%会继续保持此状态。 因此，我们认为历史逾期状态为M4+的客户已经坏透了，几乎不会从良。为了让风控模型有更好的区分能力，需要将客户好坏界限尽可能清晰(也就是从良率最剧烈减少的点开始)，可以定义： 坏用户（bad）= 逾期状态为M4+（即逾期超过90天） 如何确定bad和good标签的账龄# vintage和roll rate的区别：# 滚动率分析用于定义客户的好坏程度。(定义标签bad和good) Vintage分析用于确定合适的表现期。（找到一个合适的观测点，前面的该逾期的已经逾期了，充分暴露了） 定义目标客户到底是good还是bad的具体操作步骤为： step 1. 利用滚动率分析定义坏客户（找到不会再从良的那个账龄点），例如上文案例中定义：M4+为坏客户。（先找到bad和good） step 2. 以M4+作为资产质量指标（上一步找到定义了bad还是good），统计Vintage数据表，绘制Vintage曲线。目的是分析账户成熟期（逾期率不再明显增加），例如上文案例确定：账户成熟期是9个月。 也有根据迁徙率确定bad还是good的，下面是FAL提到的一个例子： 由下表可以看出，M2以上的迁徙率将近90%，所以确定当前逾期31天以上为区分好坏客户的标准，及后续分析的目标变量。 roll rate已经确定了bad为什么还需要通过Vintage分析来确定表现期？# 这是因为：虽然滚动率分析确定了M4+作为坏的程度（从良率最低），但是对于12期的产品，有些账户是在前4期MOB（也就是MOB1 ~ MOB4，经过4个表现期）就达到M4+，有些是在（观测点前）后几期才达到M4+。而这很重要。 Vintage里所有的账户，我们的目的是抓住尽可能多的坏客户。# 现在进一步补充Vintage曲线的绘制过程：如图8所示，对于这10,000个账户，以MOB1为起点，把前N个MOB作为一个窗口，滑窗统计坏客户率，得到图5-表1中的Vintage数据，并绘制Vintage曲线。我们可以发现：经过9期，我们几乎能够抓住所有的坏客户。（也就是前9期该逾期的都逾期了，充分暴露了） 下图是每个用户逾期的不同起止情况举例： 因此，我们将两者结合起来，定义： Bad = 账户经过9期表现期后，逾期状态为M4+（逾期超过90天）。此时 Y=1。 Good = 经过9期表现期，但未达到M4+逾期状态。此时Y=0。 Intermediate = 未进入9期表现期，账户还未成熟，无法定义好坏，也就是不定样本。 有时候也考虑到这么干的话，bad用户会太少，会往上移动到M3,同时因为前面的good用户要和bad做一个截断。比如M1以内的都是good，m3+的都是bad，m2的忽略截断。 Flow Rate迁移率# 展示客户贷款账户在整个生命周期中的变化轨迹，也是预测未来坏账损失的最常用的方法。 其核心假设为：处于某一逾期状态（如M2）的账户，一个月后，要么从良为M0账户，要么恶化为更坏的下一个逾期状态（如M3）。 迁移率 = 前一期逾期金额到下一期逾期金额的转化率 一般缩写为M0-M1、M4-M5等形式，例如： M0-M1 = 当月进入M1的贷款余额 / 上月末M0的贷款余额 M2-M3 = 当月进入M3的贷款余额 / 上月末M2的贷款余额 迁移率分析的具体操作步骤为： step 1. 定义逾期状态，如前文所述的M0、M1、M2等。 step 2. 计算各逾期状态之间的迁移率，如M0-M1、M2-M3等。 step 3. 计算不同月份（也可称为Vintage）的平均迁移率。目的是对本平台在不同时期的资产的迁移率有整体的认知。 step 4. 根据平均迁移率和不良资产回收率，计算净坏账损失率。 接下来，我们以数值案例（非真实业务数据）展示上述过程。 下面表1，每一列代表截止当月放款的总额M0一直到M6的情况，每一行代表1-7月的各个月对应周期的违约率,所以斜线是前后时间序列关系： 上图表2中，2月份的逾期M1资产只能从1月份的正常M0资产滚动而来（斜线迁移），因此从逾期M0资产向M1的转化率为: 2373381007844=23.55%\\frac{237338}{1007844}=23.55\\% ​1007844​​237338​​=23.55% 截止1月末，正常M0资产为 1007844 元，这是起点。 截止2月末，1月末的正常M0资产中有2373381007844=23.55%\\frac{237338}{1007844}=23.55\\%​1007844​​237338​​=23.55% 恶化为逾期M1资产。【较低，因为有不小心逾期的】 截止3月末，2月末的逾期M1资产中有 \\frac{55362}{237338}=23.33%恶化为逾期M2资产。【较低，因为有不小心逾期的】 截止4月末，3月末的逾期M2资产中有 \\frac{25144}{55362}=45.32% 恶化为逾期M3资产。【翻倍上升了】 截止5月末，4月末的逾期M4资产中有83.38%恶化为逾期M5资产。此时已过催收黄金期（90天以内）。【大幅上升！】 截止6月末，5月末的逾期M5资产中有49.37% 恶化为逾期M6资产。这可能采用了委外催收、司法手段等催收策略，效果显著。【从80+%下降到49%】 截止7月末，6月末的逾期M5资产中有82.7% 恶化为逾期M7资产。此时将视为不良资产，打包转卖给第三方公司，这样就能回收部分不良资产，减少损失【没救了】 我们从横向比较每个月的迁移率，发现不完全一样。这是因为随着时间推移、外在宏观经济环境、用户渠道、内部政策、资产质量等变化而产生一定的波动。我们可以利用这些数据： 观察迁移率的发展轨迹，监控坏账的发展倾向和催收效果。 通过对多个月份的迁移率计算平均值，从而使迁移率更加稳定。 坏账准备金# 坏账准备金的概念----各期逾期余额乘以各自准备金率# 呆帐风险是信贷机构必须面对的风险，主要来源于信用风险和欺诈风险等。为了应对未来呆帐的可能，信贷机构一般都会设定一个储备资金，这就是**坏账准备金（Bad Debt Reserve）。**那么我们该如何计算坏账准备金？ 一般做法是，把未清偿贷款余额乘以一定的**准备金比例（Reserve Ratio）**所得。可以理解，资产逾期等级越高（越差），准备金比例也应该越高，因为恶化为呆帐的可能性也更高。如图10所示，正常M0资产恶化为呆帐的可能性最低，因此我们预留的准备金比例也就最少。 我们总结下计算坏账准备金的步骤为： step 1. 统计未清偿贷款金额的分布，也就是M0~M6状态分别对应的资产余额。 step 2. 为每个逾期状态的资产分配一个准备金比例。 step 3. 每个子项目的准备金金额 = 未清偿贷款余额 x 准备金比例。 step 4. 每个子项目的准备金金额相加，得到最终的准备金。 准备金比例# 准备金比例是如何给出的？ 由于坏账准备金是用来覆盖预期的未来呆帐损失的，准备金比例必须等于处于各个逾期状态的资产未来演变为呆帐的比例。 回到上一节的迁移率分析中，我们发现从正常M0资产迁移至逾期M7资产（呆帐）需经过7次迁移，如图11所示。那么，我们只要把各个状态之间的转化率相乘，不就得到准备金比例了？ 因此，我们定义正常M0资产对应的毛坏账损失率，也就是迁移到呆帐的转化率为： 毛坏账损失率 = (M0-M1)×(M1-M2)×(M2-M3)...×(M6-M7) 也就是从M0一直到M7的平均迁移率的乘积。 在本案例中，正常M0资产对应的毛坏账损失率为上上图表2最左侧截止M6-M7的平均迁移率88.03%上面所有的乘起来：0.60% 在实际中，信贷机构会将不良资产打包转卖给第三方公司，这样就能回收部分不良资产，减少损失。因此，我们定义净坏账损失率为： 净坏账损失率 = 毛坏账损失率 - 不良资产外卖回收率 由于M7不良资产的平均回收率为 10.79%，则可计算净坏账损失率为： 0.60%×(1-10.79%)=0.54% 同理，我们可以计算正常资产到不同逾期状态资产的毛损失率和净损失率如下： 根据图12所示的损失率表，我们定义： 当月应计拨备额 = SUM(净坏账损失率 * 月末应收账款余额) 拨备率 = 当月应计拨备额 / 总资产金额 其中，拨备率是用来预防不良资产的发生而准备的金额的比例。拨备率应越低越好。拨备率越高说明风险越大，损失越大，利润越小。 在本案例中，当月应计拨备额为65421元，如图13所示。拨备率为： 654212625091=2.49%\\frac{65421}{2625091}=2.49\\% ​2625091​​65421​​=2.49% 资产组合管理相关# 根据风控成因分类：信用风险、欺诈风险。信用风险主要是用户因为各种原因导致逾期而存在的风险，欺诈风险就是黑产欺诈团队的攻击对公司造成的风险，通过设置规则来拦截高风险用户。 生命周期分为三类： 拓展客户期（学校刚成立时，既要招生，又要有教材支撑） 审批客户期（学习成绩、平时表现） 管理客户期（对学生进行管理） 拓展客户期需要三个方面的支持 目标用户： 适用于拨备segment的风险分级或用户画像支持（拨备与财务挂钩） 目标产品： 风险分级对应期数、利率支持 资产配置有效性分析 资金成本、获客成本、运营成本，在放贷还没开始的时候，就已经由资产管理部门估算确定下来了。后续需要技术来创造价值的，主要是风控的坏账成本，所以资产管理部会用拨备工具来给予支持。 在一个产品刚产生的时候，资产管理部门需要给出关于目标客户的年龄身份，期数，利率的建议；放款后，又需要从其他金融机构拉资金，债权转让等。每一个公司的要求都不一样，我们需要给出推荐，哪一些标的推荐给哪一些公司，如何进行资源组合配置。 审批客户期 主要由贷前策略实施，资产组合管理部门可提供盈利性测算支持，并做好监控、预测、预警系统，当准入用户风险状况超阈值，需提出干预。 资金成本、获客成本、运营成本，在放贷还没开始的时候，就已经由资产管理部门估算确定下来了。后续需要技术来创造价值的，主要是风控的坏账成本，所以资产管理部会用拨备工具来给予支持。 在一个产品刚产生的时候，**资产管理部门需要给出关于目标客户的年龄身份，期数，利率的建议；**放款后，又需要从其他金融机构拉资金，债权转让等。每一个公司的要求都不一样，我们需要给出推荐，哪一些标的推荐给哪一些公司，如何进行资源组合配置。 审批客户期 主要由贷前策略实施，资产组合管理部门可提供盈利性测算支持，并做好监控、预测、预警系统，当准入用户风险状况超阈值，需提出干预。 管理客户期 1.指标方面：新增/存量、风险/规模指标 风险 规模 新增 vintage、FPD GMV 存量 roll rate、coincident dpd、lagging dpd、badrate 在贷余额 2.策略方面：主要由贷中贷后策略实施，可提供盈利性测算支持，并做好监控、预测、预警系统，风险状况超阈值，需提出干预。 资产组合管理作为支撑部门，支撑什么？ 风险计量 策略规则上线 模型效力验证 向CRO提供各种专题类或临时性分析 … 风险计量主要是数据分析，报表，专题性报告，为了规避、减少风险，策略实施者和策略制定者需要分为2个部门。资产管理部门接到业务部门提交的需求，然后根据内容做一些空跑，监控。同时大的模型开发与模型验证也是两个部门，需要资产管理部对模型做持续的监控与评估。统筹贷前、贷中、贷后的数据给到CRO。 资产组合管理方法？ 1.拨备准备金 思考：实际风险与名义风险的区别？ 2.风险分级(用户画像) 思考：有了评分卡模型为什么还要做风险分级? 3.监控、预测、预警系统 思考：资产组合管理报表和业务部门（贷前、中、后）的不同点？ 本次分享总结 1.资产组合管理部门不同于传统的风控业务部门，而是直属于CRO的信息整合部门； 2.资产组合管理贯穿于客户及产品的全生命周期，需要从业者极强的沟通能力； 3.作为支撑部门，资产组合管理部需要运用数据分析把控公司全局资产质量，除此之外还需要以降低作业风险的目的为模型或策略设置二次防线。 4.资产组合管理部门是小白进入金融风控核心岗位的捷径，可以快速的积累风控经验，之后如果转岗策略或模型，都比较容易。 参考文章链接：# https://zhuanlan.zhihu.com/p/81027037/ https://blog.csdn.net/liulj_0803/article/details/52964473 https://www.zhihu.com/question/51583052 这里也有很多干货","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/tags/risk/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"}]},{"title":"SpringCloud组件01---CAP、注册中心、Ribbon实践","slug":"springcloud01-CAP、注册中心、Ribbon实践","date":"2020-03-02T14:30:40.000Z","updated":"2020-06-02T06:36:58.717Z","comments":true,"path":"article/springcloud-H-01-eureka-ribbon.html","link":"","permalink":"https://blog.sofunnyai.com/article/springcloud-H-01-eureka-ribbon.html","excerpt":"","text":"CAP理论快速简介 微服务的通用定义： 本次测试版本： 分布式服务包括的组件 环境搭建 支付子module建立： IDEA自动热部署配置（可选） 关于RestTemplate 注册中心 EUREKA服务注册 工作流程 Server配置 client配置 EUREKA高可用集群 服务集群 自我保护 Discovery Zookeeper服务注册 注入调用方 zk客户端和server jar包冲突 Consul服务注册 简介 服务端注册 客户端注册 Eureka、Zookeeper、Consul的对比 Ribbon Ribbon简介 Ribbon的负载均衡策略 其他负载均衡算法： 自定义规则 注意事项： 原始的轮询规则 定义手动实现一个负载均衡 动手实现一个自定义ribbon策略 CAP理论快速简介# CAP理论关注的是粒度是数据，而不是整体系统设计。 Consistency（强一致性） Availability（高可用性） Partition Tolerance（分区容错性） 以上三个最多只能较好满足两个，一个系统不可能同时满足这三个需求。 CA：单点集群，满足一致性和高可用，通常在可拓展性上不强大。 CP：满足一致性，分区容忍度。通常性能不太高。 当网络分区出现后，为了保证一致性，就必须拒接请求，否则无法保证一致性。（违背A高可用） Consul和Zk，更关注一致性，不在了很快就给干掉，但不是立刻。 AP：满足可用性和分区容忍度，通常对一致性要求较低。 当网络分区出现后，为了保证可用性，B系统可以返回旧的值，优先保证可用。（违背C一致性） Eureka，不会立刻踢掉服务 分布式架构的P永远都要保证 图例 AP：如微博热门微博点赞数，后续柔性理论和base数据补充来保证一致性 CP： 微服务的通用定义：# 是一种架构模式，提倡将单一应用划分成一组轻量级的微服务互相调用和配合，基于restful，并可以独立部署。 是一整套的较量，不是单个的组件。 本次测试版本：# springboot 2.2.x+版本 spring cloud H版。如果cloud是G，boot对应2.1具体： boot 2.2.2.RELEASE： CLOUD Hoxton.SR1 Cloud Alibaba 2.1.0.RELEASE 分布式服务包括的组件# 服务注册与发现：eureka，现在不维护了。zk、Consul(golang不推荐)、用alibaba的Nacos(推荐) 服务调用：Ribbon(维护状态)，后续LoadBalancer。Feign用OpenFeign。 服务熔断：hystrix(维护状态，但是大规模，思想需要学习)，resilience4j(海外，国内很少)，alibaba sentienl（推荐） 负载均衡：fegin 服务降级：hystrix 服务消息队列： 配置中心管理：config，推荐携程的阿波罗，或者alibaba的Nacos(推荐) 服务网关：zuul，现在用cloud gateway 服务监控 总线：bus—&gt;alibaba Nacos 全链路监控 自动化部署 服务定时操作 分布式配置：cloud config 环境搭建# idea里面new-project-maven_architect_site 设置项目encoding utf-8 设置项目 settings-annotation processor- 勾选 enable annotation prosessing 设置java-compile是1.8 设置pom：maven项目的的聚合、依赖、传递依赖 父工程，project根目录下的pom文件修改maven，添加packaging标签为pom。 1&lt;packaging&gt;pom&lt;/packaging&gt; dependencyManagement用在父工程，子模块继承后，提供作用：锁定版本、子module都引用一个依赖，而不用写version。 dependencyManagement用在父工程只是声明版本依赖，并不真的引用。真正的是要子项目自己引用group和artifactid即可，不用指定版本号自动用父类的。 支付子module建立：# 建module：在父工程右键新建module，新建完了之后父工程上会有&lt;module&gt;引入了 改pom 写yml 主动启动类 业务类 IDEA自动热部署配置（可选）# 在子项目工程pom中添加devtools依赖包： 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 添加插件到父聚合项目的pom中 12345678&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; 开启自动编译 更新值 ctrl+alt+shift+/-----registry，勾选允许自动编译： 勾选下面两个选项 重启idea 关于RestTemplate# getForObjec：返回Json对象，或者Json字符串可以格式化为对象。 getForEntity：返回ResponseEntity，除了数据，还包括网络层面的状态码、响应头等东西。 RestTemplate已经被Springcloud深度定制，底层可以支持各种客户端负载均衡策略支持，也支持自定义负载均衡策略。 注册中心# EUREKA服务注册# 传统一对第一调用，太多的时候就是网状的，需要每个客户端都去维护对端服务信息。无法统一管理，非常乱。 EUREKA作为一个注册中心的server，系统中其他services都向他链接注册并维持心跳。 这样EUREKA就能知晓所有的services的信息，就像一个电话号码本。其他service想互相调用可以来这里用service别名来询问当前可用的对端地址。 下面左边是SpringCloud，右边是Dubbo。 EUREKA分为Server和Client两个组件： Server提供一个监听，供给其他cloud所有service进来连接。 Client是一个Java客户端，简化与Server的交互，是一个内置、轮循的负载均衡器。默认30s向Server发送一次心跳。如果Server多伦没有收到心跳就把这个节点移除。(默认90s) EUREKA已经停止更新，后续需要迁移到别的技术栈，比如zk、consl、nacos。 工作流程# Server配置# pom.xml 2.2版本后，eureka分为server和client了，此处是server。 不用指定版本，因为父module中指定了版本。 12345&lt;!--eureka server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; application.yml 12345678910server: port: 7001eureka: instance: hostname: localhost # erureka client: register-with-eureka: false # 不向注册中心注册自己 fetch-registry: false # 自己仅仅作为注册中心，不去检索服务 service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka Server的main类 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaMain7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaMain7001.class, args); &#125;&#125; client配置# pom.xml 同上 123456&lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!--上面的eureka-client会自动引入ribbon--&gt; application.yml 123456eureka: client: register-with-eureka: true # 是否注册到eureka server 默认true fetch-registry: true # 是否从eureka抓取已注册的信息，true才能配合ribbon使用负载均衡 service-url: defaultZone: http://localhost:7001/eureka Client的main类 1234567@SpringBootApplication@EnableEurekaClientpublic class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; EUREKA高可用集群# 高可用原理：相互注册，相互守望。 比如7001和7002有两个EUREKA，会互相注册到对方那边去。互相心跳监控。 两台EUREKA的yml配置 12345678910server: port: 7001eureka: instance: hostname: eureka7001.com # erureka另一个节点的ip，互相注册 如192.168.1.2:7001 &lt;---&gt; 192.168.1.3:7002,此处就应该写192.168.1.2 client: register-with-eureka: false # 不向注册中心注册自己 fetch-registry: false # 自己仅仅作为注册中心，不去检索服务 service-url: # 下面应该注册到另外一台eureka，也就是http://192.168.1.3:7002/eureka defaultZone: http://eureka7002.com:7002/eureka 12345678910server: port: 7002eureka: instance: hostname: eureka7002.com # erureka另一个节点的ip，互相注册 如192.168.1.2:7001 &lt;---&gt; 192.168.1.3:7002,此处就应该写192.168.1.3 client: register-with-eureka: false # 不向注册中心注册自己 fetch-registry: false # 自己仅仅作为注册中心，不去检索服务 service-url: # 集群模式下，下面应该注册到另外一台eureka，也就是http://192.168.1.2:7001/eureka defaultZone: http://eureka7001.com:7001/eureka 客户端的yml配置 1234567eureka: client: register-with-eureka: true # 是否注册到eureka server 默认true fetch-registry: true # 是否从eureka抓取已注册的信息，true才能配合ribbon使用负载均衡 service-url: # defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,eureka7002.com:7002/eureka # EUREKA是集群 服务集群# 当一个服务在多台机器上运行，注册到一个EUREKA中后，在EUREKA上可以看到服务的多个ip列表用逗号隔开的。 这时候假设客户端还是使用restTemplate请求的，不能写死对端服务的ip和端口，可以写EUREKA中的服务名。 这样消费端不再关注提供方的地址，而且有负载均衡功能 12345678910111213// private String url = \"http://localhost:8001\"; // 单机private String url = \"http://CLOUD-PAYMENT-SERVICE\"; // cloud服务名，会UNKWNON HOST，需要给restTemplate开启LoadBalanced /** * 添加用户 * post http://localhost:8080/customer/payment/add?serial=cus_lalala * @param payment * @return */ @PostMapping(\"/customer/payment/add\") public CommonResult&lt;Payment&gt; create(Payment payment)&#123; return restTemplate.postForObject(url+\"/payment/add\", payment, CommonResult.class); // &#125; 但是因为服务方是多个节点，所以需要restTemplate开启负载均衡功能去调用: 12345678910111213@Configurationpublic class ApplicationContextConfig &#123; /** * 类似&lt;bean id=\"xxx\", class=\"xxxx\"&gt;&lt;/bean&gt; * @return */ @Bean @LoadBalanced //这个注解可以负载均衡，也可以把host地址由一个cloud的application-name去zookeeper转换为ip和端口 public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125; 自我保护# 一句话描述：某时刻某个微服务不能用了，Eureka不会立刻清理，依旧会对该服务的信息进行保存。 为什么？防止Eureka Server网络不通，但是Eureka Client正常运行的时候，EurekaServer不会立刻把EurekaClient剔除。 详细：默认30s一次，当90s没收到心跳就该干掉，但是如果短时间内大量丢失客户端时，这个节点就会进入自我保护机制。（此时可能大量客户端都是正常的，很可能是网络分区故障） 属于CAP里面的AP分支。（高可用、分区容错性） server端关闭自我保护，修改 123server: enable-self-preservation: false # 关闭自我保护，客户端90s没心跳立马干掉 eviction-interval-timer-in-ms: 60000 Discovery# 主启动类，开启Discovery的能力 12345678@SpringBootApplication@EnableEurekaClient@EnableDiscoveryClient //主启动类，开启Discovery的能力public class PaymentMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentMain8001.class, args); &#125;&#125; controller，注入，获取服务和实例信息 1234567891011121314151617@Resourceprivate DiscoveryClient discoveryClient;@GetMapping(value = \"/discovery\") @ResponseBody public CommonResult&lt;Object&gt; discovery()&#123; System.out.println(\"-------------Services--------------\"); discoveryClient.getServices().forEach(System.out::println); System.out.println(\"-------------Instances--------------\"); List&lt;String&gt; instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\").stream().map(each-&gt;each.getInstanceId()+\"/\"+each.getHost()+\":\"+each.getPort()+\"/\"+each.getUri()).collect(Collectors.toList()); instances.forEach(System.out::println); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"services\", discoveryClient.getServices()); map.put(\"instances\", instances); return CommonResult.success(\"discovery\",map); &#125; Zookeeper服务注册# zookeeper使用临时节点存储服务的信息，一会儿心跳不出现就会干掉这个节点（不是立马干掉）。是CAP的CP，和EUREKA不太一样。 服务引入jar包 12345&lt;!--zookeeper client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;/dependency&gt; application.yml只有几行不一样，指定zookeeper的连接字符串即可： 123456789server: port: 8004spring: application: name: cloud-provider-service cloud: # 启动基于zookeeper的服务注册 zookeeper: connect-string: 127.0.0.1:2181 主启动类，使用DescoveryClient即可 12345678910111213@SpringBootApplication@EnableDiscoveryClientpublic class PaymentZkMain8004 &#123; /** * 基于zk的服务提供方，访问/payment/zk即可看到测试效果 * @param args */ public static void main(String[] args) &#123; SpringApplication.run(PaymentZkMain8004.class, args); &#125;&#125; 启动后： 123456789101112[zk: localhost:2181(CONNECTED) 7] ls /[services, zookeeper][zk: localhost:2181(CONNECTED) 8] ls /services[cloud-provider-service][zk: localhost:2181(CONNECTED) 10] ls /services/cloud-provider-service[ba35208f-59ea-4d70-b75f-857c5a5b0a64][zk: localhost:2181(CONNECTED) 11] get /services/cloud-provider-service/ba35208f-59ea-4d70-b75f-857c5a5b0a64&#123;\"name\":\"cloud-provider-service\",\"id\":\"ba35208f-59ea-4d70-b75f-857c5a5b0a64\",\"address\":\"192.168.1.10\",\"port\":8004,\"sslPort\":null,\"payload\":&#123;\"@class\":\"org.springframework.cloud.zookeeper.discovery.ZookeeperInstance\",\"id\":\"application-1\",\"name\":\"cloud-provider-service\",\"metadata\":&#123;&#125;&#125;,\"registrationTimeUTC\":1590931922948,\"serviceType\":\"DYNAMIC\",\"uriSpec\":&#123;\"parts\":[&#123;\"value\":\"scheme\",\"variable\":true&#125;,&#123;\"value\":\"://\",\"variable\":false&#125;,&#123;\"value\":\"address\",\"variable\":true&#125;,&#123;\"value\":\":\",\"variable\":false&#125;,&#123;\"value\":\"port\",\"variable\":true&#125;]&#125;&#125;[zk: localhost:2181(CONNECTED) 12] 注入调用方# pom和application.yml和启动类一模一样，暂时用restTemplate调用，需要config一下 12345678910@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced //这个注解可以负载均衡，也可以把host地址由一个cloud的application-name去zookeeper转换为ip和端口 public RestTemplate getRestTemplate()&#123; RestTemplate template = new RestTemplate(); return template; &#125;&#125; customer的controller 123456789101112131415161718@RestControllerpublic class ZkCustomerController &#123; @Resource private DiscoveryClient discoveryClient; @Resource private RestTemplate restTemplate; public static final String URL = \"http://cloud-provider-service\"; @GetMapping(\"/customer/payment/zk\") public CommonResult&lt;Payment&gt; testZkCloud()&#123; return restTemplate.getForObject(URL+\"/payment/zk\", CommonResult.class); &#125;&#125; 启动后可以在zk看到双方： 12[zk: localhost:2181(CONNECTED) 26] ls /services[cloud-customer-order, cloud-provider-service] zk客户端和server jar包冲突# 有可能client和server的zk jar包不一致会报错，比如客户端太新，服务端太老。 需要在cloud的zk的starter里面exclude掉zk的包，然后重新引入一个和zkServer版本一致的包即可。 Consul服务注册# 简介# 分布式的服务注册和配置管理中心(KV存储)，同时提供控制总线由golang开发。 基于Raft协议，比较简洁。支持健康检查、Http和DNS协议，支持跨数据中心的WAN集群，支持图形界面、跨平台。 功能： 服务发现：Http和DNS两种方式 健康检查：多种方式，Http、TCP、Docker、Shell定制 KV存储：K-V存储，可以做配置管理 可视化界面 官网下载解压，只有一个consul文件 https://www.consul.io/ 启动参考video： https://learn.hashicorp.com/consul/getting-started/agent 比如consul agent -dev启动 访问http://localhost:8500查看信息，或者： 1234567891011121314151617181920 curl localhost:8500/v1/catalog/nodes # 获取消息[ &#123; \"ID\": \"890e9cd0-322b-fafc-fe58-33728d41f305\", \"Node\": \"treeMate\", \"Address\": \"127.0.0.1\", \"Datacenter\": \"dc1\", \"TaggedAddresses\": &#123; \"lan\": \"127.0.0.1\", \"lan_ipv4\": \"127.0.0.1\", \"wan\": \"127.0.0.1\", \"wan_ipv4\": \"127.0.0.1\" &#125;, \"Meta\": &#123; \"consul-network-segment\": \"\" &#125;, \"CreateIndex\": 10, \"ModifyIndex\": 11 &#125;] 服务端注册# pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;dependencies&gt; &lt;!--Consul client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--MVC--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--业务common类，引用当前项目的版本号--&gt; &lt;dependency&gt; &lt;groupId&gt;com.sam.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--DEV-TOOLS--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类 12345678@SpringBootApplication@EnableDiscoveryClientpublic class PaymentConsulMain8004 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentConsulMain8004.class, args); &#125;&#125; application.yml 123456789101112server: port: 8004spring: application: name: cloud-provider-service cloud: # 启动基于consul的服务注册 consul: discovery: service-name: $&#123;spring.application.name&#125; hostname: localhost host: localhost controller只是一个简单的数据模拟 123456789101112131415161718@RestControllerpublic class PaymentConsulController &#123; @Value(\"$&#123;server.port&#125;\") private String port; /** * 返回一个随机payment即可 * @return */ @GetMapping(\"/payment/consul\") public CommonResult&lt;Payment&gt; testConsulPayment()&#123; Payment payment = new Payment(); payment.setId(RandomUtils.nextLong()); payment.setSerial(\"这是一个模拟的随机payment，\"+ RandomStringUtils.randomAlphabetic(16)); return CommonResult.success(\"I'm Consul Client on:\"+port,payment); &#125;&#125; 启动后就可以在上面的ui中看到。 客户端注册# pom application 都一毛一样，config、主启动类、controller和上面zk的一毛一样（因为暂时没用openFeign和ribbon），没啥可写的。 Eureka、Zookeeper、Consul的对比# 组件 CAP 对外接口 Eureka AP Http Consul CP Http/DNS Zookeeper CP 客户端 C主要是数据一致，Eureka主要保证高可用。 Ribbon# Ribbon简介# 是一套客户端的负载均衡工具，如链接超时、重试等，配置文件只用列出所有的节点，Ribbon自动基于规则（轮询、随机、响应时间加权等）去链接，也很容易自定义实现负载均衡。 官网在github，目前也是维护模式了。未来的趋势是Spring的LoadBalancer，但是还很不成熟。 Ribbon： 本地负载均衡，进程内。调用前从注册中心获取服务信息，缓存到JVM，本地负载均衡。 负载均衡+RestTemplate进行RPC，可以和多种客户端结合。Eureka只是其中之一。 工作时分两步： 先选择注册中心，比如先从注册中心选择一个负担小的Eureka 根据用户指定的策略，从注册地址取到一个进行。 Nginx：是服务端的LB。 新版2.2.x的springcloud的eureka会自动引入ribbon： 12345678910 &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--上面的eureka-client会自动引入ribbon--&gt;&lt;!-- &lt;dependency&gt;--&gt;&lt;!-- &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;--&gt;&lt;!-- &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;--&gt;&lt;!-- &lt;/dependency&gt; Ribbon的负载均衡策略# 都是IRule的实现，策略模式。 RoundRobinRule： 默认轮询的方式 RandomRule： 随机方式 WeightedResponseTimeRule： 根据响应时间来分配权重的方式，响应的越快，分配的值越大。 BestAvailableRule： 选择并发量最小的方式 RetryRule： 在一个配置时间段内当选择server不成功，则一直尝试使用subRule的方式选择一个可用的server。 ZoneAvoidanceRule： 根据性能和可用性来选择。 AvailabilityFilteringRule： 过滤掉那些因为一直连接失败的被标记为circuit tripped的后端server，并过滤掉那些高并发的的后端server（active connections 超过配置的阈值） 其他负载均衡算法：# http://dubbo.apache.org/zh-cn/docs/source_code_guide/loadbalance.html LeastActiveLoadBalance：最小活跃数负载均衡算法 活跃调用越少，说明server性能越高。优先给他。具体实现：每个服务者对应一个活跃数，init的时候大家都为0，收到一个请求+1，处理完毕-1。一段时间后性能最好的机器下降速度最快，优先给他新的请求。 ConsistentHashLoadBalance：一致性hash算法 如nginx的IP hash，把client的ip或者url等进行hash，对同一个client，相同的请求永远在一台机器。 自定义规则# 注意事项：# 自定义ribbon规则类，不能放在@ComponentsScan所能扫描的包和子包内(主启动类和以下所有包)。否则这个配置类会被所有的Ribbon客户端共享，达不到特殊定制化目的。 注意@ComponentScan 和@SpringBootApplication注解都不要扫描到。 原始的轮询规则# 默认的那个轮询规则： discoveryClient拿到所有的Server实例，然后搞一个int计数，每次取模决定返回哪个Server。 里面有自旋锁、AQS，避免重量级锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960private AtomicInteger nextServerCyclicCounter; // 注意这里是一个原子型的Integerpublic Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; log.warn(\"no load balancer\"); return null; &#125; Server server = null; int count = 0; while (server == null &amp;&amp; count++ &lt; 10) &#123; List&lt;Server&gt; reachableServers = lb.getReachableServers(); // 获取可用的server List&lt;Server&gt; allServers = lb.getAllServers(); //所有的server int upCount = reachableServers.size(); int serverCount = allServers.size(); if ((upCount == 0) || (serverCount == 0)) &#123; log.warn(\"No up servers available from load balancer: \" + lb); return null; &#125; int nextServerIndex = incrementAndGetModulo(serverCount); // 注意，这里调用了下面，使用了一个自旋锁。传入服务器总数量。 server = allServers.get(nextServerIndex); if (server == null) &#123; /* Transient. */ Thread.yield(); continue; &#125; if (server.isAlive() &amp;&amp; (server.isReadyToServe())) &#123; return (server); &#125; // Next. server = null; &#125; if (count &gt;= 10) &#123; log.warn(\"No available alive servers after 10 tries from load balancer: \" + lb); &#125; return server; &#125; /** * Inspired by the implementation of &#123;@link AtomicInteger#incrementAndGet()&#125;. * * @param modulo The modulo to bound the value of the counter. * @return The next value. */ private int incrementAndGetModulo(int modulo) &#123; for (;;) &#123; int current = nextServerCyclicCounter.get(); int next = (current + 1) % modulo; if (nextServerCyclicCounter.compareAndSet(current, next)) return next; &#125; &#125; 定义手动实现一个负载均衡# 步骤： ApplicationContextConfig对象上面去掉@LoadBalanced注解（restTemplate上面），否则就会使用ribbon自带的策略 写一个LoadBalanced接口 实现接口来一个choose方法，使用discoverClient去根据策略选择一个instance 在controller的请求时候注入这个负载均衡，choose一个insrance，拿到uri，拼装请求地址。 123456789101112131415161718192021222324252627282930313233@Componentpublic class MyLoadBalancer implements ICustomerLoadBalancer &#123; // 计数器 private AtomicInteger integer = new AtomicInteger(0); @Override public ServiceInstance chooseInstance(List&lt;ServiceInstance&gt; instances) &#123; if(instances == null || instances.isEmpty())&#123; System.out.println(\"没有可用的服务！！！！！\"); return null; &#125; // 计数器线程安全得+1，对server数量取模 int i = incrementAndGet() % instances.size(); return instances.get(i); &#125; /** * 自选增加，获取下一个值 * @return */ private final int incrementAndGet()&#123; int curr,next; do&#123; curr = integer.get(); next = curr &gt; Integer.MAX_VALUE ? 0 : curr+1; // int不能超限 // 只要没获取到真正的curr，就一直自旋 &#125;while (!integer.compareAndSet(curr, next)); // true之后就中断 System.out.println(\"------------------next:\"+next); return next; &#125;&#125; controller，使用上面的loadbalancer手动获取instance地址url地址 12345678910111213/** * 测试使用自定义手动负载均衡的方式获取 * @param id * @return */@GetMapping(\"/customer/payment/lb/get/&#123;id&#125;\")public CommonResult&lt;Payment&gt; getByIdByHanLoadBalancer(@PathVariable(\"id\") long id)&#123; List&lt;ServiceInstance&gt;instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); // 使用我们的自定义轮循负载均衡器 ServiceInstance instance = myLoadBalancer.chooseInstance(instances); // getForObject 返回Json数据，可以转化为对象 return restTemplate.getForObject(instance.getUri()+\"/payment/get/\"+id, CommonResult.class);&#125; 动手实现一个自定义ribbon策略# 自定义策略，实现IRule接口，或者继承自AbstractLoadBalancerRule 在@SpringBootApplication扫描位置外定义一个Config，里面配置我们的自定义策略 在主启动类加上我们的自定义策略配置 RestTemplate类加上@LoadBalanced注解 controller正常请求类似 自定义Rule实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class MyRibbonRule extends AbstractLoadBalancerRule&#123; @Resource private DiscoveryClient discoveryClient; // 获取服务实例用 /** * 人工实现一个轮询策略，在主启动类使用了下面的注解引用过来 * @RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\", configuration = MyRibbonRule.class) //为每个服务定制规则 */ AtomicInteger integer = new AtomicInteger(0); // 自定义核心方法，挑选主机 private Server choose(ILoadBalancer lb, Object key)&#123; if (lb == null) &#123; return null; &#125; Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers(); //List&lt;Server&gt; allList = lb.getAllServers(); int i = integer.getAndIncrement(); System.out.println(\"MyRibbonRule----integer-cnt=\"+i); if(i &gt; Integer.MAX_VALUE)&#123; integer.set(0); &#125; server = upList.get(i%upList.size()); if (server == null) &#123; /* * The only time this should happen is if the server list were * somehow trimmed. This is a transient condition. Retry after * yielding. */ Thread.yield(); continue; &#125; // 选了个挂的，重来 if (server.isAlive()) &#123; return (server); &#125; // Shouldn't actually happen.. but must be transient or a bug. server = null; Thread.yield(); &#125; return server; &#125; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) &#123; // 初始化 System.out.println(\"--------------init rule-------------\"); System.out.println(iClientConfig.getClientName()); System.out.println(iClientConfig.getProperties()); &#125; @Override public Server choose(Object key) &#123; // 根据一个key返回一个Server return choose(getLoadBalancer(), key); &#125;&#125; 配置实例化： 1234567891011121314151617181920@Configurationpublic class ApplicationContextConfig &#123; /** * 类似&lt;bean id=\"xxx\", class=\"xxxx\"&gt;&lt;/bean&gt; * @return */ @Bean @LoadBalanced //当调用服务方集群的时候，需要加上这个，然后restTemplate请求地址写cloud注册的服务名即可。 // 自定义负载均衡策略的时候不用这个注解 public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125; @Bean public IRule getRule()&#123; return new MyRibbonRule(); &#125; &#125; 主启动类 12345@SpringBootApplication@EnableEurekaClient@RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\", configuration = MyRibbonRule.class) //为每个服务定制规则@EnableDiscoveryClient // 给自定义规则用，这里可以获取实例列表public class CustomerMyRibbonMain8083 &#123; controller： 12345678910/** * 测试使用自定义负载均衡策略的方式获取 * @param id * @return */ @GetMapping(\"/customer/payment/rule/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getByIdByIRuleBalancer(@PathVariable(\"id\") long id)&#123; // getForObject 返回Json数据，可以转化为对象 return restTemplate.getForObject(url+\"/payment/get/\"+id, CommonResult.class); &#125; 参考链接： https://blog.csdn.net/qq_41211642/article/details/104772140#comments","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/tags/SpringCloud/"}]},{"title":"let's-encrypt配置网站免费SSL证书及自动更新","slug":"基于lets-encrypt的https证书","date":"2019-07-13T18:44:23.000Z","updated":"2020-07-19T15:25:55.925Z","comments":true,"path":"article/lets-encrypt.html","link":"","permalink":"https://blog.sofunnyai.com/article/lets-encrypt.html","excerpt":"","text":"前言 厂商选择 下载安装cert-bot 安装cert-bot 获取证书 直接安装到nginx 只生成证书 测试自动更新证书 纯手动的certonly 参考链接 前言# 相信看到这里的对SSL/TSL都有一定了解，链式信任、防劫持、防隐私泄露、安全可信，这些关键字大家脑海里都很熟悉。具体SSL细节就不啰嗦了，感兴趣可以去看看阮一峰的博客或者网上资料，本文主要是实操。 厂商选择# 除了域名统配的高端证书之外，一般我们的博客或者小型网站可以考虑使用免费厂商提供的证书。和大厂商的主要区别就是公信力了，不过理论上都是同等安全的。比如： https://letsencrypt.org/ 在chrome等浏览器厂商的努力支持下，这些之前看起来小点的证书厂商现在兼容性也非常好了。 本文就以let's encrypt和nginx为例。 下载安装cert-bot# 废话少说，现在let's encrypt是推荐在server上使用cert-bot来安装、更新我们的证书，https://certbot.eff.org/ 所以： 安装cert-bot# 1yum install certbot python2-certbot-nginx 获取证书# 首先把我们的域名解析到当前机器的nginx上，80可以正常访问。 然后获取证书有两种方式：1.直接自动安装到nginx，并由cert-bot管理nginx配置文件。 2.获取证书，但手动修改nginx配置文件 直接安装到nginx# 配置环境变量： 123 ln -s /main/server/nginx/sbin/nginx /usr/bin/nginxln -s /main/server/nginx/conf/ /etc/nginxcertbot --nginx 会自动识别nginx配置文件，生成nginx的证书，并修改nginx文件。这是最简单的方式。 只生成证书# 只生成证书： 1certbot certonly --nginx 会让你输入邮箱、域名等信息 然后去域名DNS插入一条TXT，之后会生成证书。 测试自动更新证书# 配置自动更新 1echo \"0 0,12 * * * root python -c 'import random; import time; time.sleep(random.random() * 3600)' &amp;&amp; certbot renew -q\" | sudo tee -a /etc/crontab &gt; /dev/null 测试一下： 1certbot renew -q --dry-run 如果报错一个ASCII错误问题，是因为nginx的配置文件有中文。。。所以还是建议只生成证书，手动去配置nginx比较好。 纯手动的certonly# 适用于上面的certonly报错的时候 certbot certonly --manual --email xxx@xxx.com -d *.domain.com 12345678910111213# 自动更新DNS并更新通配符证书- 如果还是想自动，nginx配置文件的中文也解决了的话，&#96; certbot renew -q --dry-run&#96;测试如果还报错： &#96;&#96;&#96;bash certbot renew -q --dry-run Attempting to renew cert (sofunnyai.com) from &#x2F;etc&#x2F;letsencrypt&#x2F;renewal&#x2F;sofunnyai.com.conf produced an unexpected error: The manual plugin is not working; there may be problems with your existing configuration. The error was: PluginError(&#39;An authentication script must be provided with --manual-auth-hook when using the manual plugin non-interactively.&#39;,). Skipping. All renewal attempts failed. The following certs could not be renewed: &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;sofunnyai.com&#x2F;fullchain.pem (failure) 大意是说缺少一个`--manual-auth-hook`，因为我们比较狠使用的通配符证书`*.sofunnyai.com`,所以此处每次更新证书需要给DNS插入一条TXT的记录。我们需要脚本自动插入这个DNS记录，我们使用的`cloudflare`作为DNS厂商，所以这里需要一个插件`certbot-dns-cloudflare`。 先去CloudFlare后台申请一个局部的API令牌，只允许编辑DNS。 然后去github找到了这个https://github.com/7sDream/certbot-dns-challenge-cloudflare-hooks 一个DNS更新脚本。 下载配置dns的APIKEY 依赖jq yum install jq 是一个json字符串处理的库，很小。 上面的脚本一共有三个文件，因为CloudFlare的官方API修改为标准Authorization授权，但是原作者还没改。需要修改三个文件里面的http认证头： cat config.sh文件的http认证头： 这个文件的主要功能是获取zones 123456789101112CLOUDFLARE_KEY=&lt;这里修改为你的key&gt;CLOUDFLARE_EMAIL=&lt;这里修改为你的邮箱，新版已经不用了&gt;CHALLENGE_PREFIX=\"_acme-challenge\"CHALLENGE_DOMAIN=\"$&#123;CHALLENGE_PREFIX&#125;.$&#123;CERTBOT_DOMAIN&#125;\"CLOUDFLARE_ZONE=$(curl -X GET \"https://api.cloudflare.com/client/v4/zones?name=$&#123;CERTBOT_DOMAIN&#125;\" \\ -H \"X-Auth-Email: $&#123;CLOUDFLARE_EMAIL&#125;\" \\ -H \"Authorization: Bearer $&#123;CLOUDFLARE_KEY&#125;\" \\ -H \"Content-Type: application/json\" -s | jq -r '.result[0].id')echo \"获取zone结果=$&#123;CLOUDFLARE_ZONE&#125;\" cloudflare-update-dns.sh文件，这个文件的主要功能是添加dns记录。但是这里也需要修改里面的http认证头： 1234567891011121314151617181920212223242526272829303132333435#!/bin/bashDIR=\"$(dirname \"$0\")\"source \"$DIR/config.sh\"DNS_SERVER=8.8.8.8echo \"CHALLENGE_DOMAIN: $&#123;CHALLENGE_DOMAIN&#125;\"echo \"CHALLENGE_VALUE: $&#123;CERTBOT_VALIDATION&#125;\"echo \"DNS_SERVER: $&#123;DNS_SERVER&#125;\"echo \"ZONE: $&#123;CLOUDFLARE_ZONE&#125;\"ADD_RECORD_RESULT=$(curl -X POST \"https://api.cloudflare.com/client/v4/zones/$&#123;CLOUDFLARE_ZONE&#125;/dns_records\" \\ -H \"X-Auth-Email: $&#123;CLOUDFLARE_EMAIL&#125;\" \\ -H \"Authorization: Bearer $&#123;CLOUDFLARE_KEY&#125;\" \\ -H \"Content-Type: application/json\" \\ --data \"&#123;\\\"type\\\":\\\"TXT\\\",\\\"name\\\":\\\"$&#123;CHALLENGE_DOMAIN&#125;\\\",\\\"content\\\":\\\"$&#123;CERTBOT_VALIDATION&#125;\\\", \\\"ttl\\\": 120&#125;\" -s | jq -r \"[.success, .errors[].message] | @csv\")echo \"添加记录结果Add record result: $&#123;ADD_RECORD_RESULT&#125;\"if [[ ! $(echo \"$&#123;ADD_RECORD_RESULT&#125;\" | grep \"true\") ]]; then echo \"添加记录失败....Add record failed, exit\" exit 1fiwhile true; do records=$(dig -t TXT $&#123;CHALLENGE_DOMAIN&#125; @$&#123;DNS_SERVER&#125; +noall +answer +short | grep \"$&#123;CERTBOT_VALIDATION&#125;\") if [[ $&#123;records&#125; ]]; then break fi echo \"等待DNS生效.....DNS records have not been propagate, sleep 10s...\" sleep 10doneecho \"DNS已经生效，DNS record have been propagated, finish\" cloudflare-clean-dns.sh，这个文件是当证书处理完毕结束后清理掉记录，修改认证头： 12345678910111213141516171819202122#!/bin/bashDIR=\"$(dirname \"$0\")\"source \"$DIR/config.sh\"echo \"DOMAIN: $&#123;CHALLENGE_DOMAIN&#125;\"echo \"ZONE: $&#123;CLOUDFLARE_ZONE&#125;\"records=($(curl -X GET \"https://api.cloudflare.com/client/v4/zones/$&#123;CLOUDFLARE_ZONE&#125;/dns_records?type=TXT&amp;name=$&#123;CHALLENGE_DOMAIN&#125;&amp;page=1&amp;per_page=100\" \\ -H \"X-Auth-Email: $&#123;CLOUDFLARE_EMAIL&#125;\" \\ -H \"Authorization: Bearer $&#123;CLOUDFLARE_KEY&#125;\" \\ -H \"Content-Type: application/json\" -s | jq -r \".result[].id\"))echo \"即将删除这些DNS记录：$&#123;records&#125;\"for record in \"$&#123;records[@]&#125;\"; do echo \"clean: $record\" curl -X DELETE \"https://api.cloudflare.com/client/v4/zones/$&#123;CLOUDFLARE_ZONE&#125;/dns_records/$&#123;record&#125;\" \\ -H \"X-Auth-Email: $&#123;CLOUDFLARE_EMAIL&#125;\" \\ -H \"Authorization: Bearer $&#123;CLOUDFLARE_KEY&#125;\" \\ -H \"Content-Type: application/json\" -s | jq -r \"[.success, .errors[].message] | @csv\"done 测试我们的脚本 certbot renew --manual-auth-hook=&quot;/path/to/cloudflare-update-dns.sh&quot; --manual-cleanup-hook=&quot;/path/to/cloudflare-clean-dns.sh&quot; --post-hook=&quot;/path/to/nginx/sbin/nginx -s reload&quot; --dry-run 如果测试通过，就可以配置定时任务了 参考链接# https://certbot.eff.org/lets-encrypt/centosrhel7-nginx https://www.jianshu.com/p/6ea81a7b768f https://www.jianshu.com/p/a1cc68c7d916 https://github.com/7sDream/certbot-dns-challenge-cloudflare-hooks","categories":[{"name":"network","slug":"network","permalink":"https://blog.sofunnyai.com/categories/network/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"},{"name":"运维","slug":"运维","permalink":"https://blog.sofunnyai.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"代理模式的一切","slug":"动态代理的一切proxy-jdk-cglib","date":"2019-03-15T04:43:38.000Z","updated":"2020-07-28T16:20:58.818Z","comments":true,"path":"article/proxy.html","link":"","permalink":"https://blog.sofunnyai.com/article/proxy.html","excerpt":"","text":"代理模式的背景 静态代理： 动态代理 人肉朴素思想的手动代理 JDK 动态代理 JDK动态代理为什是接口不是继承？ CGlib Javassist 代理模式的背景# 假如我们有一个用户实现接口，如UserService，和实现类UserServiceImpl。现在想在UserServiceImpl的某些方法前后打印参数日志，可以选择的方式有： 静态代理：# 继承：写一个子类继承这个UserServiceImpl，然后方法前后加上日志功能。但是如果要再实现另外一个增强需求，就需要再次继承。或者对多个接口的方法同时进行增强，就要链式继承。长此以往产生类爆炸。 聚合：装饰模式。实现同一个接口UserService，装饰器的构造方法传入一个同样的类，进行包装。在包装方法里面进行前后的增强，再去调用父类。[Java的IO流使用了大量的装饰模式]。和上面的代理很像，但是装饰模式只能装饰一个特定的对象，在构造方法里面传进来，实现同样的接口进行增强。 12345678910111213141516171819/** * 装饰模式增强，实现相同接口 */public class UserServiceDeractor implements UserService &#123; UserService userService; /** * 构造方法传入同样的对象进行包装 */ public UserServiceDeractor(UserService userService)&#123; this.userService = userService; &#125; @Override public User getUser(String name) &#123; System.out.println(\"--------------装饰模式增强，传入参数\"+name); return userService.getUser(name); &#125;&#125; 缺点：实现起来简单，但是代理类会比较多，比较复杂。 动态代理# 基于以上的静态代理，会产生大量的class，如何改进？最浅显的想法就是 程序拼装这一段动态代理的java文件代码—&gt;然后生成class字节码—&gt;然后加载到项目中—&gt;创建对象并使用。 人肉朴素思想的手动代理# 基于以上思想我们试着实现一个山寨版 先来一个函数接口，用于动态封装我们的代理增强功能： 123456789101112131415161718/** * 动态代理接口 */@FunctionalInterfacepublic interface MyInvocationHandler &#123; /** * 代理增强 * @param proxy 代理类 * @param method 代理方法 * @param target 目标包装对象 * @param args 参数 * @return * @throws Exception */ public Object invoke(Object proxy, Method method,Object target, Object... args) throws Exception;&#125; 如果需要对某个对象进行增强，就写一个Handler接口的实现，然后在invoke方法中增强。 将这个invoke传入到我们下面的ProxyUtil中去创建一个代理对象： public static &lt;T&gt; T getProxy(Object target, MyInvocationHandler handler, Class&lt;T&gt; ... interfaces) throws Exception有三个参数，目标对象、增强实现（或者Lambda）、要实现的接口列表。 这个方法会把所有target的public方法进行重新生成java，每个方法里面调用handler.invoke进行增强 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152/** * 人工模拟动态代理， 不用任何第三方jar，也不用JDK */public class ProxyUtil &#123; static JavaCompiler javaCompiler = ToolProvider.getSystemJavaCompiler(); /** * 需要生成一个代理对象，必然要： * 1.先得到java代码 * 2.然后把java代码变成class * 3.然后把class变成对象 * * 我们动态实现那个装饰模式的静态代理 * @param &lt;T&gt; */ public static &lt;T&gt; T getProxy(Object target, MyInvocationHandler handler, Class&lt;T&gt; ... interfaces) throws Exception &#123; //Class clazz = target.getClass(); if(interfaces == null || interfaces.length==0)&#123; System.out.println(\"该对象没有实现接口，无法代理！\"); return null; &#125; //Class interfaceClazz = clazz.getInterfaces()[0]; System.out.println(\"即将针对接口\"+interfaces+\"进行动态代理...\"); // 拼装java类 StringBuffer java = new StringBuffer(); String proxyPackage = \"com.sam.proxy\"; java.append(\"package \"+proxyPackage+\";\\n\\n\"); // 引入接口 java.append(Arrays.stream(interfaces).map(c-&gt;\"import \"+c.getName()).collect(Collectors.joining(\";\\n\"))+\";\\n\"); java.append( \"import \"+target.getClass().getName()+\";\\n\" + \"import java.util.Arrays;\\n\" + \"import \"+MyInvocationHandler.class.getName()+\";\\n\\n\" + // import MyInvocationHandler \"// TODO 这个类是由ProxyUtil自动生成的\\n\"+ // 接口$Myproxy 此处也可以使用 \"public class MyProxyOf\"+target.getClass().getSimpleName()+\" implements \"+ Arrays.stream(interfaces).map(Class::getSimpleName).collect(Collectors.joining(\",\"))+\" &#123;\\n\" + // private 接口 target \" private \"+target.getClass().getSimpleName()+\" target;\\n\" + \" private \"+MyInvocationHandler.class.getSimpleName()+\" handler;\\n\\n\" + // 构造方法包装 \" public MyProxyOf\"+target.getClass().getSimpleName()+\"(\"+target.getClass().getSimpleName()+\" target, \"+MyInvocationHandler.class.getSimpleName()+\" h)&#123;\\n\" + \" this.target = target;\\n\" + \" this.handler = h;\\n\" + \" &#125;\\n\"); // 不用在每个方法处理，使用动态处理 for(Method method : target.getClass().getDeclaredMethods())&#123; // public com.xx.xx.User getUser(java.lang.String java.append(\"\\n\\t@Override\\n\\tpublic \"+method.getReturnType().getName()+\" \"+method.getName()+\"(\"); // String name)&#123; List&lt;String&gt; params = IntStream.range(0,method.getParameterTypes().length).mapToObj(i-&gt;method.getParameterTypes()[i].getName() +\" var\"+i).collect(Collectors.toList()); java.append(String.join(\", \",params));// java.lang.String var1, java.lang.Integer var2 java.append(\")\"); if(method.getExceptionTypes().length &gt; 0)&#123; java.append(\"thorws \"+ Arrays.stream(method.getExceptionTypes()).map(Class::getName).collect(Collectors.joining(\", \"))); &#125; java.append(\"&#123;\\n\"); // 开始调用invoke或者lambda进行代理增强！ java.append(\"\\t\\tSystem.out.println(\\\"代理对象中即将调用invoke.....\\\");\\n\"); // 调用包装类target的方法，进行增强 java.append(\"\\t\\ttry&#123;\\n\"); if(method.getParameterTypes().length == 0)&#123; java.append(\"\\t\\t\\t\"+(method.getReturnType()==void.class?\"\":(\"return (\"+method.getReturnType().getName()+\")\"))+\"handler.invoke(this, target.getClass().getMethod(\\\"\"+method.getName()+\"\\\"), target);\\n\"); &#125;else&#123; List&lt;String&gt;vars = IntStream.range(0,method.getParameterTypes().length).mapToObj(i-&gt;\"var\"+i).collect(Collectors.toList()); List&lt;String&gt;paramClazz = Arrays.stream(method.getParameterTypes()).map(c-&gt;c.getName()+\".class\").collect(Collectors.toList()); java.append(\"\\t\\t\\tClass[] paramClazz = new Class[]&#123;\"+String.join(\",\",paramClazz)+\"&#125;;\\n\"); java.append(\"\\t\\t\\t\"+(method.getReturnType()==void.class?\"\":(\"return (\"+method.getReturnType().getName()+\")\"))+\"handler.invoke(this, target.getClass().getMethod(\\\"\"+method.getName()+\"\\\", paramClazz), target, \"+String.join(\",\",vars)+\");\\n\"); &#125; java.append(\"\\t\\t&#125;catch(Exception ex)&#123;\\n\"); //method.getExceptionTypes() if(method.getExceptionTypes().length &gt; 0)&#123; java.append(\"\\t\\tList&lt;Class&gt; methodExs = Arrays.asList(\"+ String.join(\",\",Arrays.stream(method.getExceptionTypes()).map(c-&gt;c.getName()+\".class\").collect(Collectors.toList()))+\");\\n\"); java.append(\"\\t\\t\\tif(methodExs.contains(ex.getClass()))&#123;throw ex;&#125;\\n\"); &#125; java.append(\"\\t\\t\\tex.printStackTrace();\\n\"); if(method.getReturnType() != void.class)&#123; // 异常时候返回null java.append(\"\\t\\t\\treturn null;\\n\"); &#125; java.append(\"\\t\\t&#125;\\n\"); // 结束catch java.append(\"\\t&#125;\\n\");// 结束方法 &#125; java.append(\"&#125;\\n\"); //System.out.println(java); // 落盘 String filePath = System.getProperty(\"user.dir\")+\"/src/main/java/\"+proxyPackage.replaceAll(\"\\\\.\",\"/\"); String fileprefix = \"MyProxyOf\"+target.getClass().getSimpleName(); File dir = new File(filePath); if(!dir.exists())&#123; dir.mkdirs(); &#125; File javaFile = new File(filePath + \"/\" +fileprefix +\".java\"); if(javaFile.exists())&#123; javaFile.delete(); &#125; FileWriter fw = new FileWriter(javaFile); fw.write(java.toString()); fw.flush(); fw.close(); boolean result = compilerJavaFile(filePath + \"/\" + fileprefix +\".java\",System.getProperty(\"user.dir\")+\"/target/classes/\"); if(result)&#123; // 因为上一步编译到了当前工程的target中，在classpath里面，所以可以Class.forName // TODO 如果是线上编译到一个类似/tmp目录，这里需要使用URLClassloader去LoadClass加载进来才行 Class tClass = Class.forName(proxyPackage+\".MyProxyOf\"+target.getClass().getSimpleName()); // 找到装饰模式的那个构造方法，传入装饰器包装的原始对象 return (T) tClass.getConstructor(target.getClass(),MyInvocationHandler.class).newInstance(target,handler); &#125; return null; &#125; /** * 动态编译java文件到class字节码，需要把JDK/lib/tools.jar加入到环境变量中 * @param sourceFileInputPath * @param classFileOutputPath * @return */ public static boolean compilerJavaFile(String sourceFileInputPath, String classFileOutputPath) &#123; System.out.println(\"sourceFileInputPath=\"+sourceFileInputPath); System.out.println(\"classFileOutputPath=\"+classFileOutputPath); try&#123; // 设置编译选项，配置class文件输出路径 System.out.println(\"输出到:\"+classFileOutputPath); Iterable&lt;String&gt; options = Arrays.asList(\"-d\", classFileOutputPath); StandardJavaFileManager fileManager = javaCompiler.getStandardFileManager(null, null, null); Iterable&lt;? extends JavaFileObject&gt; compilationUnits = fileManager.getJavaFileObjectsFromFiles(Arrays.asList(new File(sourceFileInputPath))); boolean flag = javaCompiler.getTask(null, fileManager, null, options, null, compilationUnits).call(); if(flag)&#123; System.out.println(\"动态编译成功！\"); &#125; return flag; &#125;catch (Exception ex)&#123; ex.printStackTrace(); if(ex instanceof ClassNotFoundException)&#123; System.out.println(\"动态编译失败！\"); System.out.println(\"把JDK/lib/tools.jar加入到环境变量中\"); &#125; return false; &#125; &#125; public static void main(String[] args) throws Exception&#123; UserService instance = getProxy(new UserServiceImpl(), (proxy,method,target,params)-&gt;&#123; System.out.println(\"在lambda中的增强代理.....\");return method.invoke(target,params); &#125;, UserService.class); System.out.println(\"-----------------开始运行\"); instance.addUser(new User(\"wangwu\",20)); &#125;&#125; 生成效果： 12345678910111213141516171819202122232425262728293031323334353637383940414243// TODO 这个类是由ProxyUtil自动生成的public class MyProxyOfUserServiceImpl implements UserService &#123; private UserServiceImpl target; private MyInvocationHandler handler; public MyProxyOfUserServiceImpl(UserServiceImpl target, MyInvocationHandler h)&#123; this.target = target; this.handler = h; &#125; @Override public com.sam.bootdemo.model.User getUser(java.lang.String var0)&#123; System.out.println(\"代理对象中即将调用invoke.....\"); try&#123; Class[] paramClazz = new Class[]&#123;java.lang.String.class&#125;; return (com.sam.bootdemo.model.User)handler.invoke(this, target.getClass().getMethod(\"getUser\", paramClazz), target, var0); &#125;catch(Exception ex)&#123; ex.printStackTrace(); return null; &#125; &#125; @Override public void addUser(com.sam.bootdemo.model.User var0)&#123; System.out.println(\"代理对象中即将调用invoke.....\"); try&#123; Class[] paramClazz = new Class[]&#123;com.sam.bootdemo.model.User.class&#125;; handler.invoke(this, target.getClass().getMethod(\"addUser\", paramClazz), target, var0); &#125;catch(Exception ex)&#123; ex.printStackTrace(); &#125; &#125; @Override public void initService()&#123; System.out.println(\"代理对象中即将调用invoke.....\"); try&#123; handler.invoke(this, target.getClass().getMethod(\"initService\"), target); &#125;catch(Exception ex)&#123; ex.printStackTrace(); &#125; &#125;&#125; 可以正常运行并输出： 1234567动态编译成功！-----------------开始运行代理对象中即将调用invoke.....在lambda中的增强代理.....UserServiceImpl假装addUser：User(userName&#x3D;wangwu, age&#x3D;20)Process finished with exit code 0 JDK 动态代理# JDK动态代理使用InvocationHandler实现，和我们上面的思想很像： 123456789101112131415161718192021222324// 实现一个增强器，来拦截我们包装target的方法，进行业务增强public class UserServiceInvocationHandler implements InvocationHandler &#123; private Object target; public UserServiceInvocationHandler(Object target)&#123; this.target = target; &#125; /** * 代理方法的增强器 * 调用代理对象的业务对象的时候会来执行这个方法 * @param proxy * @param method * @param args * @return * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"-------UserServiceInvocationHandler.invoke代理增强\"); // 此处进行拦截增强 return method.invoke(target, args); // 执行target的真正业务逻辑 &#125;&#125; 测试JDK的动态代理： 123456789System.out.println(\"===================JDKProxy InvocationHandler=========================\");// jdk动态代理// 为啥要classloader？因为JVM启动的时候已经加载了project的所有class。// 但是项目运行过程中动态生成了calss，所以要传入classloader去加载这个class。// 为啥不是URLClassLoader去远程加载？因为JDK动态代理产生的项目是在classpath下的// 传入classloader、接口、和要增强的InvocationHandlerUserService service3 = (UserService) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;UserService.class&#125;, new UserServiceInvocationHandler(new UserServiceImpl()));service3.getUser(\"小马\"); 原理： Class使用来描述一个类的，看起来是废话。但是很重要，仔细体会。 Class对象如 Class userClazz = Clazz.forname(&quot;com.xxx.User&quot;)就可以拿到User类的详细信息，包括属性、方法、构造方法等等。 一个java文件---&gt;编译成class文件---&gt;解析成byte[]到JVM中---&gt;构建为类对象Class-----&gt;newInstance变成实例 判断两个对象是否相等，首先判断类加载器是否同一个，不是的话就不相等。这块动态代理判断了。传进去的接口列表使用用户的ClassLoader先加载一遍forName的结果，看看和传进来的是否相同。 默认生成的代理类在com.sun.proxy这个包名下如com.sun.proxy.$Proxy0，除非有interface不是public的，会生成到这个interface同包名下（否则无法外部implements访问到）。 12//java.lang.reflect.Proxy中获取到包名后生成class字节流的方法，使用了native方法生成byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); 结果： JDK上面那一步动态生成的类，我们反编译后看一眼： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import com.sam.bootdemo.model.User;import com.sam.bootdemo.service.UserService;import java.io.FileNotFoundException;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;import java.sql.SQLException;// 继承了JDK的Proxy，所以不能继承我们的目标对象，只能是实现接口public class UserServiceProxy extends Proxy implements UserService &#123; private static Method m1; private static Method m3; private static Method m5; private static Method m2; private static Method m4; private static Method m0; // 反射获取了我们UserService接口中需要覆盖的方法，同时反射拿到要覆盖的hashCode、equals、toString方法 static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"com.sam.bootdemo.service.UserService\").getMethod(\"initService\"); m5 = Class.forName(\"com.sam.bootdemo.service.UserService\").getMethod(\"addUser\", Class.forName(\"com.sam.bootdemo.model.User\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m4 = Class.forName(\"com.sam.bootdemo.service.UserService\").getMethod(\"getUser\", Class.forName(\"java.lang.String\")); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125; // 构造方法传入了我们写的增强类InvocationHandler，塞到父类Proxy中了 // 这个handler里面有包装我们的原始userServiceImpl对象 public UserServiceProxy(InvocationHandler var1) throws &#123; super(var1); &#125; // 因为实现了同样的UserService接口，这里代理实现 public final User getUser(String var1) throws &#123; try &#123; // 调用了invocationHandler的invoke方法，传入 代理对象、method、参数。（但是缺少真正的target，target在invocationhandler中，也就是我们要增强的userServiceImpl对象） return (User)super.h.invoke(this, m4, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; // 同上 public final void initService() throws &#123; try &#123; super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; // 同上 public final void addUser(User var1) throws FileNotFoundException, SQLException &#123; try &#123; super.h.invoke(this, m5, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | FileNotFoundException | SQLException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; // toString、equals、hashCode也调用了invocationHandler的invoke方法。 public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125;&#125; 可以发现JDK生成代理类的逻辑和我们之前手动山寨版的很像。只是JDK是调用native方法直接生成字节流数组。我们是拼装java，再动态编译为class的。 虽然是native方法，但JDK也是通过反射生成的，他反射读取了我们接口中的方法列表，逐个实现，然后生成到class流里的。 缺点： 必须要有接口，才能生成动态代理。如果对象没有接口就无法进行代理。 JDK动态代理为什是接口不是继承？# 因为Java是单继承的，JDK底层源码已经继承了proxy对象， 里面存放了invocationHandler（invocationHandler里面包装了我们的目标对象）。所以不能再继承我们的目标对象。 只能去和目标对象实现相同的接口，包装一下，具有相同行为。 CGlib# 使用基于继承的方式，使用ASM进行字节码操作完成代理增强。都是直接操作字节码和JDK比起来性能差异不大。 Javassist# 也可以实现字节码增强的代理，使用不太多。","categories":[{"name":"spring","slug":"spring","permalink":"https://blog.sofunnyai.com/categories/spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.sofunnyai.com/tags/spring/"}]},{"title":"IO基础-select、poll、epoll和TCP","slug":"IO模型之selector和Epoll","date":"2018-09-12T12:12:26.000Z","updated":"2020-06-14T10:58:15.967Z","comments":true,"path":"article/io-basic-socket-tcp.html","link":"","permalink":"https://blog.sofunnyai.com/article/io-basic-socket-tcp.html","excerpt":"","text":"计算机组成原理# 内核态与用户态：计算机刚开机的时候，硬盘的kernel内核程序先加载，然后才启动上层的各种app应用文件。 kernel启动的时候会先在内存中开启内核空间，或者内核态。剩余的部分给用户态、用户空间 用户态的应用程序无法直接访问内核态的内存，必须调用内核的“系统调用”才可以。(system call ，在man里面是2类) 应用程序去调用的“系统调用”需要通过【中断】的方式找到内核的方法实现，CPU切换到内核态，内核中断去访问硬件 中断# 背景：CPU内部有晶振元件，通电后在一定时间内振动固定的次数。当晶振一定次数后，产生“时间中断”，就产生了所谓CPU时间片。 1.内核启动的时候会产生一个进程调度的回调地址Callback 2.CPU产生中断的时候会把缓存刷回程序内存，保护现场。 3.然后调用内核的callback，根据不同优先级调用的不同进程回调地址。（从主存里面把曾经刷过去的缓存再加载到CPU缓存） 4.下次晶振再重复上面的过程，就完成了进程切换的过程。 **缺点：**如果进程很多，切换成本很高，比如切换过去后发现在阻塞，其实是一种浪费。 软中断：因为应用程序需要进行系统调用，调用内核态。会发生用户态到内核态的切换。CPU需要刷缓存，调用callback，传递参数，再回来。 系统调用是一个软中断，中断号是0x80，它是上层应用程序与Linux系统内核进行交互通信的唯一接口。 我们有多个应用，应用IO的变化是由内核的变化来实现的。 硬件中断# 我们有多个硬件设备，比如键盘、鼠标、网卡，当他们发生动作的时候如何让OS响应？也是通过调用中断。 比如鼠标点击的时候调用CPU中断，传递参数生成一个事件event。CPU去调用kernel（kernel启动的时候通过设备的驱动程序获取了中断号和callback。包括中断信号，和执行的方法） 然后kernel根据对应的callback程序做出正确的响应即可。 网卡为了避免频繁发送中断，使得降低CPU的浪费，会在内存中被分配极小一块缓存区域（DMA区域 直接内存），攒够了发一次中断。是一个buffer思想。 IO 升级发展之路# 经典CS架构的BIO# 任何服务想要启动监听接受请求，需要进行以下步骤 1.调用kernel启动一个socket的文件描述符，假设叫fd3，监听 2.死循环去调用kernel的accept(fd3)方法，去不断获取最新的客户端文件描述符，假设获得一个客户端fd4 3.去调用kernel的read(fd4)方法读取客户端的消息，这是一个阻塞方法！！！ 4.为了不阻塞，只能accept拿到每一个客户端之后，read去启动一个线程，线程里面去阻塞读取用户消息。 弊端：有多少客户端连接，就要启动多少线程，资源浪费极大。而且多线程的数据共享、调度都很麻烦。 12345// 伪代码while(true)&#123; client_fd = accept(server监听的fd) // 获取客户端的监听，调用内核态 new Thread(read(client_fd)).start() // 单独启动线程去阻塞读取用户响应，阻塞调用内核态&#125; 【痛点】：kernel的read(fd)操作是阻塞的(在等待对端发消息)，会需要很多线程，但是多线程开销太大，kernel的调度也很费劲。 C10K问题# 最初的服务器是基于进程/线程模型。新到来一个TCP连接，就需要分配一个进程/线程。假如有C10K也即是1W个客户端，就需要创建1W个进程/线程，可想而知单机是无法承受的。那么如何突破单机性能是高性能网络编程必须要面对的问题，进而这些局限和问题就统称为C10K问题，最早是由Dan Kegel进行归纳和总结的，并且他也系统的分析和提出解决方案。 【问题本质】：是操作系统的问题，创建的进程或线程多了，数据拷贝频繁（缓存I/O、内核将数据拷贝到用户进程空间、阻塞，进程/线程上下文切换消耗大， 导致操作系统崩溃，这就是C10K问题的本质。 【解决方案】： 同一个线程/进程同时处理多个连接---------------------多路复用。 ​ kernel的非阻塞的read与多路复用器（NIO时代）# kernel进化了，支持了一个应用层面非阻塞的read接口，所以我们应用就可以同上类似： 任何服务想要启动监听接受请求，需要进行以下步骤 1.调用kernel启动一个socket的文件描述符，假设叫fd3，监听 2.死循环去调用kernel的accept(fd3)方法，去不断获取最新的客户端文件描述符，假设获得一个客户端fd4 3.去调用kernel的非阻塞read(fd4)方法读取客户端的消息，这是一个非阻塞方法。有内容就给你，没有就给一个没有个的返回或者异常。调用后就该干嘛干嘛去，待会儿再来。 4.不用去开启线程，直接循环回到第2步骤，再去获取客户端。（截止这一轮2个客户端的话保存一个fd的数组） 5.上面的第3步循环这个客户端fd的数组，逐个去调用kernel的非阻塞read(each_fd)方法，拿到返回继续会到2… 12345678while(true)&#123; client_fd = accept(server监听的fd) // 获取客户端的监听，调用内核态 clients.add(client_df) // 存储一个新的客户端 for(each_fd in clients)&#123; msg = read(each_fd) // 非阻塞读取到消息，非阻塞调用内核态 // 业务处理 &#125;&#125; 或者可以启动2个线程，一个Boss线程去死循环专门获取客户端的连接，一个Worker线程去专门死循环所有的客户端非阻塞读取消息。----------是不是有Netty的感觉了？ 【弊端】：工作线程的worker虽然都不是阻塞的，不用启动多线程。但是还是要进行系统调用，也就是调用内核。调用内核是通过软中断实现的。用户态到内核态的切换太频繁。 比如10w的fd客户端，work线程每次循环需要调用10w次kernel的read方法，发生10w次用户态和内核态的切换。但是可能只有10个人发消息了，绝大部分的内核切换都浪费了。read的调用是O(n)的。 现在的JDK的NIO包中已经使用了多路复用器解决，见下节。 多路复用器实现—select/poll和epoll# kernel发生变化，我们才能突破。如果无法解决上面例子中10w个fd需要10w次调用才能传给kernel的问题，就无法改进。 第一类多路复用器—select和poll# man 2 select可以看到内核的select多路复用情况。 【多路 复用】：假设10w个客户端fd，把原先需要调用10w次read(each_fd)读取消息，复用成select(fds)，返回有消息的fd集合。 select多路复用器带来的改变： 任何服务想要启动监听接受请求，需要进行以下步骤 1.调用kernel启动一个socket的文件描述符，假设叫fd3，监听 2.死循环去调用kernel的accept(fd3)方法，去不断获取最新的客户端文件描述符，假设获得一个客户端fd4，多个积攒的客户端得到一个fd的集合fds 3.去调用一次kernel的select(fds)方法，kernel去把所有的fd进行检查，把发生消息变化的fd集合返回！【循环发生在kernel里面，没有用户态和内核态的切换】 4.程序只用去调用上面有消息的一小部分fd的read(each_fd)方法，就能读取到消息 5.回到2循环… 【优势】：大大减少内核态和用户态的切换。例子中一次调用复用了10w次read，后续统一处理返回的个别有消息的fd。 【弊端】： 1.每次循环调用select的时候，都要copy 10w个fd的数据从用户态到内核态。（内核能记住之前的客户端多好？） 2.内核态还需要把这10w个fd每次都循环检查一遍。 select支持的fd是有上限的，需要重新编译内核才行很费劲，默认只支持1024个fd的多路复用。 poll改进：使用一个链表结构突破限制，支持无上限的fd集合一起传输。只依赖于操作系统的ulimites设置 第二类多路复用器----epoll-IO/Event Notifycation facility# epoll是一个多路复用的进阶版，改进了客户端fd频繁copy到内核态的问题。是同步非阻塞的。是C10K问题的进阶版。 系统级同步：程序还是需要去主动调用kernel的read方法获取数据 系统级异步：程序给一个内核级别的callback，发生事件的时候直接到callback，接收到数据。------epoll做不到。 epoll工作原理：# epoll不用去轮询监听所有文件句柄是否已经就绪。epoll只对发生变化的文件句柄感兴趣。 有epoll_create(2)、epoll_ctl(2)、epoll_wait(2)组成（2是系统调用）。 其中epoll_create创建一个epoll实例，返回一个文件描述符，代表内核空间。 epoll_ctl，将我们的client订阅关注的事件去丢到内核空间（每个client只用丢一次） epoll_wait去阻塞，或者超时查看发生状态变化的client的fd，拿到后去处理。 使用&quot;事件&quot;的就绪通知方式，通过epoll_ctl注册文件描述符fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd, epoll_wait便可以收到通知, 并通知应用程序。 man epoll 看一眼帮助： 首先EPOLL(7)是一个杂项，由三个2类的系统调用组成：epoll_create(2)、epoll_ctl(2)、epoll_wait(2) 1234567891011121314151617181920212223242526272829303132333435EPOLL(7) Linux Programmer's Manual EPOLL(7)NAME epoll - I/O event notification facilitySYNOPSIS #include &lt;sys/epoll.h&gt;DESCRIPTION The epoll API performs a similar task to poll(2): monitoring multiple file descriptors to see if I/O is possible on any of them. The epoll API can be used either as an edge-triggered or a level-triggered inter‐ face and scales well to large numbers of watched file descriptors. The following system calls are provided to create and manage an epoll instance: * epoll_create(2) creates a new epoll instance and returns a file descriptor referring to that instance. (The more recent epoll_cre‐ ate1(2) extends the functionality of epoll_create(2).) * Interest in particular file descriptors is then registered via epoll_ctl(2). The set of file descriptors currently registered on an epoll instance is sometimes called an epoll set. * epoll_wait(2) waits for I/O events, blocking the calling thread if no events are currently available. Level-triggered and edge-triggered The epoll event distribution interface is able to behave both as edge- triggered (ET) and as level-triggered (LT). The difference between the two mechanisms can be described as follows. Suppose that this scenario happens: 1. The file descriptor that represents the read side of a pipe (rfd) is registered on the epoll instance. epoll_create 系统调用# 可以去man 2 epoll_create看一眼这个系统调用（2类）的epoll的帮助，看他的返回： 12345678910111213141516171819202122232425262728EPOLL_CREATE(2) Linux Programmer's Manual EPOLL_CREATE(2)NAME epoll_create, epoll_create1 - open an epoll file descriptorSYNOPSIS #include &lt;sys/epoll.h&gt; int epoll_create(int size); int epoll_create1(int flags);DESCRIPTION epoll_create() creates a new epoll(7) instance. Since Linux 2.6.8, the size argument is ignored, but must be greater than zero; see NOTES below. epoll_create() returns a file descriptor referring to the new epoll instance. This file descriptor is used for all the subsequent calls to the epoll interface. When no longer required, the file descriptor returned by epoll_create() should be closed by using close(2). When all file descriptors referring to an epoll instance have been closed, the kernel destroys the instance and releases the associated resources for reuse............................RETURN VALUE On success, these system calls return a nonnegative file descriptor. On error, -1 is returned, and errno is set to indicate the error. 他的返回是：On success, these system calls return a nonnegative file descriptor. On error, -1 is returned, and errno is set to indicate the error. 这个返回是一个fd，它代表的是一个内核空间------------保存我们的客户端fd。这些客户端怎么放进去的呢？epoll_ctl可以往里面添加fd epoll_ctl-增删改fd给到内核空间# 一样我们看一下帮助man 2 epoll_ctl可以看到int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);这是一个系统调用，epfd可以传递客户端的fd，op可以传递EPOLL_CTL_ADD、EPOLL_CTL_MOD、EPOLL_CTL_DEL去增删改。一个客户端只用放一次，以后再也不用放了。 123456789101112131415161718192021222324252627282930EPOLL_CTL(2) Linux Programmer's Manual EPOLL_CTL(2)NAME epoll_ctl - control interface for an epoll file descriptorSYNOPSIS #include &lt;sys/epoll.h&gt; int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);DESCRIPTION This system call performs control operations on the epoll(7) instance referred to by the file descriptor epfd. It requests that the opera‐ tion op be performed for the target file descriptor, fd. Valid values for the op argument are: EPOLL_CTL_ADD Register the target file descriptor fd on the epoll instance referred to by the file descriptor epfd and associate the event event with the internal file linked to fd. EPOLL_CTL_MOD Change the event event associated with the target file descrip‐ tor fd. EPOLL_CTL_DEL Remove (deregister) the target file descriptor fd from the epoll instance referred to by epfd. The event is ignored and can be NULL (but see BUGS below). epoll_wait-让fd等待事件# 同上类似man 2 epoll_wait 1234567891011121314151617181920212223242526272829303132333435363738EPOLL_WAIT(2) Linux Programmer's Manual EPOLL_WAIT(2)NAME epoll_wait, epoll_pwait - wait for an I/O event on an epoll file descriptorSYNOPSIS #include &lt;sys/epoll.h&gt; int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); int epoll_pwait(int epfd, struct epoll_event *events, int maxevents, int timeout, const sigset_t *sigmask);DESCRIPTION The epoll_wait() system call waits for events on the epoll(7) instance referred to by the file descriptor epfd. The memory area pointed to by events will contain the events that will be available for the call‐ er. Up to maxevents are returned by epoll_wait(). The maxevents argument must be greater than zero. The timeout argument specifies the number of milliseconds that epoll_wait() will block. Time is measured against the CLOCK_MONOTONIC clock. The call will block until either: * a file descriptor delivers an event; * the call is interrupted by a signal handler; or * the timeout expires. Note that the timeout interval will be rounded up to the system clock granularity, and kernel scheduling delays mean that the blocking interval may overrun by a small amount. Specifying a timeout of -1 causes epoll_wait() to block indefinitely, while specifying a timeout equal to zero cause epoll_wait() to return immediately, even if no events are available. epoll工作流程# 【Epoll】：假设10w个客户端fd 任何服务想要启动监听接受请求，需要进行以下步骤 1.调用kernel启动一个socket的文件描述符，假设叫fd3，监听 2.调用epoll_create,创建epoll实例，会在内核中开辟空间假设fd6。 3.调用epoll_ctl(fd6, ADD , fd3, event_accept),把socket fd3加入内核空间fd6中，同时监听accept事件。 4.调用epoll_wait(fd6,res),等待fd6中的所有fd返回，阻塞，也可以可以超时。传递一个res是接受返回的内存空间。 假设上面epoll_wait的时候，一个C1来了三次握手，制造事件中断。CPU回调，知道来了一个客户端，就把这个fd放到fd3上。fd3就放到上面给的res。（accept） 5.epoll_wait从res看到有fd3的accept了，把这个fd3给到程序去执行accept(fd3)，得到一个fd8.这时候fd8就代表下面的C1客户端了。 6.调用epoll_ctl(fd6, ADD , fd8, event_read),把客户端fd8加入内核空间fd6中，同时监听read事件。（以后就不用监听了） 7.程序循环调用epoll_wait(fd6,res),等待fd6中的所有fd返回，阻塞，也可以可以超时。传递一个res是接受返回的内存空间。拿出res里面的fd和事件去处理。 这时候C2如果来了，fd6里面监听了accept和read，都会触发中断。CPU会把fd3和fd8都放到res，注明有一个连接来了俩event。 这时候epoll_wait会返回两个fd，fd3里面的event拿出来会得到一个新的client，命名fd9，来代表C2. 然后把fd9也调用epoll_ctl(fd6, ADD , fd9, event_read)加进去，内核就多监听一个中断事件。 多而两个系统调用 epoll空间开辟早期的时候用mmap（程序和内核都可以访问），后来系统调用不用这个实现了，因为多线程的时候mmap有点问题。 上层开辟线程，传递数据的时候还是用的mmap。内存直接访问。 【优势】：压榨硬件资源到极致，规避了客户端fd的频繁拷贝。事件驱动。 【缺点】：epoll只完成了event的通知，需要拿到数据的时候还是需要去同步调用read。（可以非阻塞调用read，但是还是程序需要主动调用read，不会直接给到） epoll不一定是最快的，根据client的特点？ 也就是网卡把数据放到DMA区域，内核通过中断只知道DMA有数据，有事件。kernel知道是什么时间类型，会通过epoll_wait的res告诉程序，但是不会直接把消息读取出来。还是需要应用app去调用kernel的read（阻塞或者非阻塞）去拿回数据。 思想：事件到达了，会有event告诉内核。 ​ select/poll和epoll的对比# select和poll是一类 epoll是另一类 支持一个进程所能打开的最大连接数 FD剧增后带来的IO效率问题 消息传递方式 select 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。 因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。 内核需要将消息传递到用户空间，都需要内核拷贝动作 poll poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的 同上 同上 epoll 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接 epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。 epoll通过内核和用户空间共享一块内存来实现的。 AIO# aio on linux比较费劲，因为linux希望更多的CPU运行在用户空间，内核空间保证安全。 如果AIO如何搞定系统级别异步？linux kernel去执行应用定义的callback？在哪里启动callback的线程？这个callback在哪里执行？kernel执行的话安全性？ TCP基础# OSI基础模型# 提到IO，首先是OSI参考模型，计算机网络基础，一共七层 这7层是一个虚的东西，是一个规范。TCP/IP协议给精简到4层，把上面的应用层-表示层-会话层统一归结到新的应用层是用户称，把下面的传输控制层-网络层-链路层-物理层视为内核层。 OSI七层网络模型 TCP/IP四层概念模型 对应网络协议 应用层（Application） 应 HTTP、TFTP, FTP, NFS, WAIS、SMTP 表示层（Presentation） 用 Telnet, Rlogin, SNMP, Gopher 会话层（Session） 层 SMTP, DNS 传输层（Transport） 传输层 TCP, UDP 网络层（Network） 网络层 IP, ICMP, ARP, RARP, AKP, UUCP 数据链路层（Data Link） 数据 FDDI, Ethernet, Arpanet, PDN, SLIP, PPP 物理层（Physical） 链路层 IEEE 802.1A, IEEE 802.2到IEEE 802.11 linux命令测试讲解TCP# 创建一个到baidu的文件描述符（内核层）# linux一切皆文件，每一个程序都有自己的IO流。程序里面的IO流也会被描述成文件（数字）。没一个程序都有3个自带的文件描述符： 0：system.in 1: system.out 2: system.err 用户创建的IO就从3开始 **【举例】**执行一个bash命令创建一个到baidu的socket，IO流重定向到当前进程的8号文件描述符中： exec 8&lt;&gt; /dev/tcp/www.baidu.com/80 上面面创建了一个文件描述符“8”，是一个socket指向了百度， 8是文件描述符fd(就像代码的变量)，&lt;&gt;是一个双向输入输出流，可以看到 echo $$ # 打印当前命令行的进程号 16199 # 也可以ps -ef 然后grep出来 tree 16199 9368 0 4月15 pts/1 00:00:01 /bin/bash 123456789101112 - 可以去当前进程的目录看一眼- &#96;&#96;&#96;bash cd &#x2F;proc&#x2F;16199&#x2F;fd # 进入当前进程的fd目录 ls # 看一眼 lrwx------ 1 tree tree 64 5月 21 18:31 0 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 1 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 2 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 255 -&gt; &#x2F;dev&#x2F;pts&#x2F;1 lrwx------ 1 tree tree 64 5月 21 18:31 8 -&gt; &#39;socket:[1037956]&#39; # 每个进程都有0,1,2三个fd文件描述符。分别是stdin、stdout、stderr 向文件描述符中写东西通信（用户层态）# 123456echo -e \"GET / HTTP/1.0\\n\" 1&gt;&amp; 8 # 打印一个字符串到标准输出（所以是1）重定向&gt;到文件描述符(所以是&amp;，重定向到文件不用&amp;)8中cat 0&lt;&amp; 8# 从文件描述符(所以是&amp;，文件的话不用&amp;)8中标准输入&lt;# 。。。。。下面打印一大堆百度的html 传输控制层TCP协议# TCP和UDP是传输控制层协议。 什么是socket套接字？# ip+port &lt;---------&gt; ip+port 是一【套】，客户端和服务端的ip+port 4个要素决定唯一的一个socket 客户端的ip是B，可以和baidu建立多少个链接？65535个 此时客户端B还能继续和163建立链接吗？也可以继续再次建立65535个，因为socket是【一套】4个要素，server换了就是另外一个socket了。 对于类似如下netstat -anp出来的socket链接，每一个established都有一个文件描述符(fd目录下)数字和他对应并交给一个进程。程序只用和这个文件描述符进行读写就可以进行socket通信了。【如果多个socket对应一个进程：就是多路复用器selector或者epoll】 下面的192.168.150.12:22建立了两个到192.168.150.1的socket： 什么是TCP协议？# 是一个面向连接的可靠的传输协议。因为三次握手保证了可靠传输。 连接：不是物理连接，是三次握手实现的逻辑连接，完成双向确认。 为啥可靠：通信前三次握手双方分配资源，为未来的通讯做好了准备。所有数据包发送的时候有个确认机制保证了可靠。 DDOS：发握手包，但是不回。造成服务器有一大堆接受TCP的等待队列。使得真正想进来的连接进不来。 三次握手的细节？# C-----------syn-----------&gt;S # “我要跟你连接了，标识是syn” C&lt;----------syn+ack-------S # “好的，我知道了” 让客户端知道Server已经响应了 C------------ack-----------&gt;S # 好的，我知道你知道了。让Server知道发出的消息客户端收到了 然后双方开始开辟资源（内存，结构体，线程），建立连接。 谁触发三次握手？目的？# 应用层的程序先告诉内核，我要和一个地址建立连接。内核去尝试三次握手。 三次握手成功后会在双方服务器开辟资源（线程、内存结构体等等）来为对方提供响应服务。 三次握手完毕后，双方才有资源开辟，才能开始传输。 tcpdump 查看三次握手# tcpdump -nn 显示ip断开 -i 显示哪个网卡接口 port 显示哪个端口 四次分手的细节，为啥要四次？# 因为握手是三次，开辟了资源。分手是双方一起释放资源，对对方有义务的，所以是四次（双方都要同时释放，不能轻易单方面释放了） 分手的C只是先说断开的人 C-----------fin-----------&gt;S # “我要跟你分手了，标识是fin”给Server一个结束标识 C&lt;----------fin+ack-------S # “好的，我知道了” 让客户端知道Server已经响应了（但是我要确认一下真的没事儿了） C&lt;-----------fin------------S # “好吧，分吧，标识是fin”确认真的没事儿了，给客户端一个结束标识 C------------ack-----------&gt;S # “好的，”让Server知道发出的消息客户端收到了 然后双方把给对方准备的资源都释放了。 三次握手和四次分手是不可分割的最小粒度# LVS作为一个工作在四层的负载均衡，是无法知晓数据包的具体内容的！ LVS是否可以随意把数据给后端进行负载？-可以负载，但是受制于协议约束！ C ----- lvs ----- S1/S2 的时候，LVS必须要把握手的三次给到一对C—S，不能给到另外一个S，否则无法建立连接。 网络和路由# 上面的TCP协议只管传输和控制，也就是发什么内容，怎么发。但是发送的路径不管，是下层寻址ARP协议管理的。 网络设置要ip、gateway、mask、dns4个东西 如果几个设备ip：192.168.1.10、192.168.1.11，他们只要成功联网，肯定知道他们的下一跳路由器地址（静态或者DHCP），如192.168.1.1 客户端向发送一个ARP广播包，带着路由器的ip和全FFFFFFFFFF的mac地址，路由器收到后看到是自己的ip，就把自己的mac地址返回给客户机。 然后客户端才知道路由器的mac，包装后就能往百度发了三次握手的包了。 通过路由表往下一跳发 【测试】`` 下面会先去请求ARP，收到路由器返回mac后，包装三次握手的包发出去。最后四次分手。 每次发送的包和接受的包都有一个seq和seq+1的关系，保证了不会错乱。 其他：# 关于DirectBuffer# 每个进程都有堆内存，JVM是C写的，启动的时候有堆空间。我们可以堆外分配空间直接给JVM访问。这个堆外空间除了内核共享，还可以接到磁盘文件上。 RandomAccessFile里面有direct分配空间和map(4096)：可以使用RandomAccessFile打开文件，对着这个文件对象调用map。JVM就有堆外空间接到磁盘上了。map返回一个buffer，JVM直接把文件存到磁盘上了。不用调用kernel的write，减少一次系统调用。 mmap# 内核和应用共同访问的共享内存。mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。这样直接对内存的读写就完成了之前的系统调用read、write，速度更快，而且内核空间也可以对这个文件直接修改，可以完成进程间文件共享。 mongoDB （3.0以前版本） 、rocketMQ 都用到了 mmap https://www.cnblogs.com/huxiao-tee/p/4660352.html Kafka的IO优化？# kafka是基于JVM的消息队列，读取消息的时候Client到Kernel调用系统调用read，再到kafka去解析。kafka优化对这个文件开启mmap映射，写文件的时候就像写buffer一样，越过系统调用直接落到磁盘。少了一次write系统调用。 kafka启动的时候有一个segment01段文件，就是mmap开辟的内存映射的大小，默认1G。对这1G的内存哪个位置放了，就会出现在文件的哪个位置。 segment把1G文件填满之后移动，再创建一个segment，再mmap一下得到第二个文件。 读：正常是程序调动kernel，kernel去读取文件到文件偏移量，拷贝到用户空间。用户空间把数据再发出去的时候又要调用kernel，多copy了一次。 如果数据是不需要kafka再加工的，就可以触发零拷贝： 程序调用sendfile，把输入输出的fd传进去，sendfile是在内核里实现的，所以直接零拷贝了。 man 2 sendfile 1234567891011121314151617181920212223242526272829303132333435363738394041424344SENDFILE(2) Linux Programmer's Manual SENDFILE(2)NAME sendfile - transfer data between file descriptorsSYNOPSIS #include &lt;sys/sendfile.h&gt; ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);DESCRIPTION sendfile() copies data between one file descriptor and another. Because this copying is done within the kernel, sendfile() is more efficient than the combination of read(2) and write(2), which would require transferring data to and from user space. in_fd should be a file descriptor opened for reading and out_fd should be a descriptor opened for writing. If offset is not NULL, then it points to a variable holding the file offset from which sendfile() will start reading data from in_fd. When sendfile() returns, this variable will be set to the offset of the byte following the last byte that was read. If offset is not NULL, then sendfile() does not modify the file offset of in_fd; otherwise the file offset is adjusted to reflect the number of bytes read from in_fd. If offset is NULL, then data will be read from in_fd starting at the file offset, and the file offset will be updated by the call. count is the number of bytes to copy between the file descriptors. The in_fd argument must correspond to a file which supports mmap(2)-like operations (i.e., it cannot be a socket). In Linux kernels before 2.6.33, out_fd must refer to a socket. Since Linux 2.6.33 it can be any file. If it is a regular file, then send‐ file() changes the file offset appropriately.RETURN VALUE If the transfer was successful, the number of bytes written to out_fd is returned. Note that a successful call to sendfile() may write fewer bytes than requested; the caller should be prepared to retry the call if there were unsent bytes. See also NOTES. 所以kafka用到mmap、零拷贝、epoll，性能高。redis底层也是epoll. nginx也是epoll，还有sendfile的零拷贝，配置文件里面就有sendfile。 参考资料 https://www.cnblogs.com/jjzd/p/6540148.html https://www.cnblogs.com/huxiao-tee/p/4660352.html","categories":[{"name":"IO","slug":"IO","permalink":"https://blog.sofunnyai.com/categories/IO/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"基础","slug":"基础","permalink":"https://blog.sofunnyai.com/tags/%E5%9F%BA%E7%A1%80/"}]},{"title":"一文讲透springboot的入门、原理","slug":"springboot","date":"2018-09-11T08:17:53.000Z","updated":"2020-07-28T16:20:10.546Z","comments":true,"path":"article/springboot.html","link":"","permalink":"https://blog.sofunnyai.com/article/springboot.html","excerpt":"","text":"Springboot入门 背景 演进过程： 快速开始 SpringbootStarter SpringBoot启动流程 SpringApplication类 背景： Import注解的使用 直接在Import中列举需要导入的类 导入ImportSelector类 导入ImportBeanDefinitionRegistrar 启动流程 工具方法 工具方法getSpringFactoriesInstances 多拨器发布事件 prepareContext： 附录 spring-boot-2.3.1.RELEASE.jar # META-INF/spring.factories spring-boot-autoconfigure-2.3.1.RELEASE.jar#spring.factories spring-beans-5.2.7.RELEASE.jar#spring.factories SpringBoot自动装配原理 启动过程： 核心配置主启动类 @SpringBootApplication @SpringBootConfiguration @EnableAutoConfiguration @AutoConfigurationPackage @Configuration SpringBoot经典问题 Springboot入门# 背景# 演进过程：# 传统web开发（servlet2.5以下），web项目必须要一个web.xml，里面配置 &lt;listener&gt;：配置一个在web容器启动时可以执行的类（如ContextLoadListener去初始化spring，需要制定参数去加载类似applicatoinContext.xml文件，扫描业务service、dao，或者&lt;bean&gt;单个定义） 在ContextLoadListener参数中要去指定加载的配置文件，如applicationContext.xml，里面通过&lt;bean&gt;去指定对象装配注入，或通过去批量扫描业务类 &lt;servlet&gt;、&lt;servlet-mapping&gt;：配置web容器从接管的请求处理类和对应请求映射规则（DispatherServlet去接管请求到springMVC），参数扫描springMvc.xml去批量扫描Controller，配置产生HttpMessageConverter、ViewResovler。 &lt;filter&gt;、&lt;filter-mapping&gt;：配置对请求的过滤类和映射规则 以上配置繁琐，第二种方式： @WebServlet(urlmapping)、 第三种，JavaConfig方式： spring使用servlet3.1的SPI机制，在META-INF/services/javax.servlet.ServletContainerInitializer下面的文件里面配置了Spring的initial类，是ServletApi的一个实现。web容器启动会去执行他，这个Spring的初始化器又会找到所有WebApplicationInitializer接口实现，挨着执行OnStartup（委托代理） springboot是建立在spring framework上的。传统我们的spring framework最开始是xml-based，然后annotation-based，最后javaconfig-based。 快速开始# 新建一个maven项目，然后去spring.io的https://spring.io/quickstart官方会指引到https://start.spring.io选择springboot版本，即可生成pom文件甚至Java基础启动文件。 点击下方EXPLORECTRL + SPACE会给你展示生成的项目结构和pom文件预览。点击GENERATECTRL + ⏎则会下载一个生成的zip包。 一般我们选用前者，我们在右边添加了web（springboot-web）、lombok后，copy一段生成的pom.xml即可： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 这里是依赖了一个springboot的父项目 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.sam&lt;/groupId&gt; &lt;artifactId&gt;bootdemo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;bootdemo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 看起来只有很简单的web-starter、lombok甚至连版本号都没有指定，但其实有很核心的一个父项目： 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; 上面的项目点进去可以发现他又依赖于 12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;/parent&gt;&lt;!-- t同时约定了配置文件的名称和目录--&gt; &lt;resource&gt; &lt;directory&gt;$&#123;basedir&#125;/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/application*.yml&lt;/include&gt; &lt;include&gt;**/application*.yaml&lt;/include&gt; &lt;include&gt;**/application*.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; 这个再点进spring-boot-dependencies去可以看到一大堆默认的约定配置： 12345678910111213141516171819202122&lt;properties&gt; &lt;activemq.version&gt;5.15.12&lt;/activemq.version&gt; &lt;antlr2.version&gt;2.7.7&lt;/antlr2.version&gt; &lt;appengine-sdk.version&gt;1.9.80&lt;/appengine-sdk.version&gt; &lt;artemis.version&gt;2.12.0&lt;/artemis.version&gt; &lt;aspectj.version&gt;1.9.5&lt;/aspectj.version&gt; &lt;assertj.version&gt;3.16.1&lt;/assertj.version&gt; &lt;atomikos.version&gt;4.0.6&lt;/atomikos.version&gt; &lt;awaitility.version&gt;4.0.3&lt;/awaitility.version&gt; &lt;bitronix.version&gt;2.1.4&lt;/bitronix.version&gt; &lt;build-helper-maven-plugin.version&gt;3.1.0&lt;/build-helper-maven-plugin.version&gt; &lt;byte-buddy.version&gt;1.10.11&lt;/byte-buddy.version&gt; &lt;caffeine.version&gt;2.8.4&lt;/caffeine.version&gt; &lt;cassandra-driver.version&gt;4.6.1&lt;/cassandra-driver.version&gt; &lt;classmate.version&gt;1.5.1&lt;/classmate.version&gt; &lt;commons-codec.version&gt;1.14&lt;/commons-codec.version&gt; &lt;commons-dbcp2.version&gt;2.7.0&lt;/commons-dbcp2.version&gt; &lt;commons-lang3.version&gt;3.10&lt;/commons-lang3.version&gt; &lt;commons-pool.version&gt;1.6&lt;/commons-pool.version&gt; &lt;!-- ....... --&gt;&lt;properties&gt; 所以，我们的springboot为何能自动选择合适的版本去启动原因就在这里，父项目默认为我们选择好了合适的集成版本。之后导入项目依赖，默认是不用写版本的，除非在spring-boot-dependencies中不包含的项目。 也就是SpringBoot将常用的场景抽取出来作为starter启动器，使用组件的时候直接引用这些starter即可。 SpringbootStarter# sprinbboot的场景启动器，如springboot-starter-web点击进去： 可以看到他依赖了一些默认的web项目所需的包： 123456789101112131415161718192021222324252627282930313233343536373839&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;!--tomcat--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;!--web,以来了beans和core--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- springMVC，里面依赖了beans、context、core、aop、expression --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; SpringBoot启动流程# SpringApplication类# 123456@SpringBootApplicationpublic class BootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(BootApplication.class); &#125;&#125; 日常我们使用上面几行看起来巨简单的代码，就一个注解 + 一行SpringApplication.run(当前类.class)，通过这个run方法入口。 我们调用的SpringApplication.run先看看这个类是个啥，注释告诉我们： 这是用来启动SpringApplication的一个类，默认以下步骤： 根据环境不同，创建合适的ApplicationContext（） 注册一个CommandLinePropertySource命令行的参数解析器，来解析我们的命令行参数暴露到spring中 刷新我们第一步的ApplicationContext，并创建加载所有的单例对象 触发所有的CommandLineRunner 这个类可以从各种来源读取bean，建议使用@Configuration类来启动我们的应用，也就是AnnotatedBeanDefinitionReader。（其他的还有XmlBeanDefinitionReader、GroovyBeanDefinitionReader） ClassPathBeanDefinitionScanner会去扫描我们制定的包 我们看看这个启动流程。 背景：# springboot有很多Listener，会发布一系列事件： ApplicationStartingEvent ApplicationEnvironmentPreparedEvent ApplicationStartedEvent ApplicationReadyEvent Import注解的使用# 直接在Import中列举需要导入的类# 12345@Configuration@Import(&#123;A.class, B.class&#125;)public class XXXConfig&#123;&#125; 导入ImportSelector类# @Configuration + @Import(ImportSelectorXXXImpl.class 即可实现动态导入、动态插拔： 123456789101112// 先看一个接口ImportSelector，我们一般要导入的是这个接口的实现public interface ImportSelector &#123; // 返回需要导入的类名。参数importingClassMetadata给传入了注解的信息，可以根据注解信息在逻辑里面动态导入 String[] selectImports(AnnotationMetadata importingClassMetadata); // 排除的exclude逻辑 @Nullable default Predicate&lt;String&gt; getExclusionFilter() &#123; return null; &#125;&#125; 实现动态插拔例子 1234567891011121314// 继承的SessionConfigurationImportSelector其实就是一个 ImportSelector，里面根据WebApplicationType返回不同的类名数组而已class MyXXXConfigurationImportSelector extends ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; // 根据 importingClassMetadata里面的信息：被修饰的类名、方法名、其他注解的信息，来动态返回一个字符串数组 // 也可以去拿到BF中的bean定义、env等信息来决定返回哪些 if(xxxxx)&#123; return new String[]&#123;com.xxx.XXXXService, com.xxx.YYYYService&#125;; &#125;else&#123; return new String[]&#123;com.xxx.XXXXService&#125;; &#125; &#125; &#125; 使用 123456@Configuration@YYYConfig(yyyyy)@Import(MyXXXConfigurationImportSelector.class) // MyXXXConfigurationImportSelector中就可以根据YYYConfig的信息、当前类的信息、BF、env信息决定导入哪些public class XXXConfig&#123; &#125; 导入ImportBeanDefinitionRegistrar# 自己手动包装一个BeanDefinition，注册到registry里面，同时给一BeanName 相当与给BF开后门，直接生成bd并注入进去，还可以修改bd信息。（用来做代理、 FactoryBean的实现等等，如mapper实现） 12345678910111213141516171819202122232425262728293031323334353637383940public interface ImportBeanDefinitionRegistrar &#123; /** * Register bean definitions as necessary based on the given annotation metadata of * the importing &#123;@code @Configuration&#125; class. * &lt;p&gt;Note that &#123;@link BeanDefinitionRegistryPostProcessor&#125; types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to &#123;@code @Configuration&#125; * class processing. * &lt;p&gt;The default implementation delegates to * &#123;@link #registerBeanDefinitions(AnnotationMetadata, BeanDefinitionRegistry)&#125;. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry * @param importBeanNameGenerator the bean name generator strategy for imported beans: * &#123;@link ConfigurationClassPostProcessor#IMPORT_BEAN_NAME_GENERATOR&#125; by default, or a * user-provided one if &#123;@link ConfigurationClassPostProcessor#setBeanNameGenerator&#125; * has been set. In the latter case, the passed-in strategy will be the same used for * component scanning in the containing application context (otherwise, the default * component-scan naming strategy is &#123;@link AnnotationBeanNameGenerator#INSTANCE&#125;). */ // 重载注册Bean定义，有默认实现 default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry, BeanNameGenerator importBeanNameGenerator) &#123; registerBeanDefinitions(importingClassMetadata, registry); &#125; /** * Register bean definitions as necessary based on the given annotation metadata of * the importing &#123;@code @Configuration&#125; class. * &lt;p&gt;Note that &#123;@link BeanDefinitionRegistryPostProcessor&#125; types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to &#123;@code @Configuration&#125; * class processing. * &lt;p&gt;The default implementation is empty. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry */ // 注册类定义,默认为空，啥都没干，子类要实现 default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; &#125;&#125; 典型应用AOP：# (或者Mybatis的Mapper代理生成并注入到BF也是ImportBeanDefinitionRegistrar实现的) 12345678910111213141516171819202122232425class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; /** * Register, escalate, and configure the AspectJ auto proxy creator based on the value * of the @&#123;@link EnableAspectJAutoProxy#proxyTargetClass()&#125; attribute on the importing * &#123;@code @Configuration&#125; class. */ // 重写了2个参数的注册方法，拿到register，自己创建RootBeanDefinition，往里面添加注册。 @Override public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // registry.registerBeanDefinition(\"internalAutoProxyCreator\", new RootBeanDefinition(cls)); AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean(\"proxyTargetClass\")) &#123; // 强制CGLib代理，去注册一个CGLib的 AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean(\"exposeProxy\")) &#123; // 暴露ThreadLocal的AOPContext AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; 使用方式，再定义一个AOP注解@EnableAspectJAutoProxy来导入刚才的ImportBeanDefinitionRegistrar实现 123456789101112131415161718192021// 导入上面的AspectJAutoProxyRegistrar@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123; /** * Indicate whether subclass-based (CGLIB) proxies are to be created as opposed * to standard Java interface-based proxies. The default is &#123;@code false&#125;. */ // 是否强制代理，默认false boolean proxyTargetClass() default false; /** * Indicate that the proxy should be exposed by the AOP framework as a &#123;@code ThreadLocal&#125; * for retrieval via the &#123;@link org.springframework.aop.framework.AopContext&#125; class. * Off by default, i.e. no guarantees that &#123;@code AopContext&#125; access will work. * @since 4.3.1 */ // proxy是否通过ThreadLocal暴露到AopContext中 boolean exposeProxy() default false;&#125; 使用，在AopAutoConfiguration这个配置类中有以下内部类： 12345678910111213141516171819 @Configuration(proxyBeanMethods = false)@ConditionalOnClass(Advice.class)static class AspectJAutoProxyingConfiguration &#123; @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = false) // 这里的false传递给了里面的BDRRegistry，会动态生成不同的Bean定义 @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"false\", matchIfMissing = false) static class JdkDynamicAutoProxyConfiguration &#123; // JDK动态代理spring.aop.proxy-target-class=false的时候才会触发 &#125; @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = true) static class CglibAutoProxyConfiguration &#123; &#125;&#125; 启动流程# 我们main方法中的run最终调用了：new SpringApplication(primarySources).run(args) new了一个我们上面的SpringApplication类。这个new里面的操作： 1234567891011121314public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; // null Assert.notNull(primarySources, \"PrimarySources must not be null\"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); // 就是我们当前启动main方法的类 this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 去确认WebApplication的类型，是Servlet还是Reactive还是None // getSpringFactoriesInstances是核心工具方法，去加载META-INF/spring.factories所有org.springframework.context.ApplicationContextInitializer // 加载回来list放到当前SpringApplication中，默认7个 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 同上，加载所有jar包META-INF/spring.factories内配置的org.springframework.context.ApplicationListener （详情可以见附录）， // 默认11个，加载回来list放到当前SpringApplication中 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // new了一个RuntimeException，然后去遍历堆栈，找到main方法的类，真是骚操作。。。 this.mainApplicationClass = deduceMainApplicationClass(); &#125; 然后继续执行run方法： public ConfigurableApplicationContext run(String... args) { //---------------------准备工作开始 StopWatch stopWatch = new StopWatch(); // 计时器 stopWatch.start(); ConfigurableApplicationContext context = null; // AnnotationConfigServletWebServerApplicationContext和XmlWebApplicationContext都是实现 Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); // headless解决awt // 使用`getSpringFactoriesInstances`工具方法从factories配置文件里面加载并创建的所有`SpringApplicationRunListener`实现。默认只有一个EventPublishingRunListener-------这个类使用来发布所有Spring应用程序事件的，里面有一系列时机去调用多拨器的发布功能。构造方法里面new了一个多拨器Multicaster，并加入配置文件里面的11个默认监听器。 SpringApplicationRunListeners listeners = getRunListeners(args); // 迭代所有的启动listener，调用starting方法（其实就一个默认只有一个EventPublishingRunListener）它里面其实是发布了一个启动事件initialMulticaster.multicastEvent(new ApplicationStartingEvent(this.application, this.args)); 然后又会去拿着这个事件信息获取所有support这个源的监听类，执行他们的listener.onApplicationEvent(event);方法。 listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 解析运行参数 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); // 准备环境----见下面 configureIgnoreBeanInfo(environment); // 获取env中spring.beaninfo.ignore设置到System.setProperty中 Banner printedBanner = printBanner(environment); // 打印banner（spring.banner.location） // 根据类型创建不同的Context，这里创建了一个AnnotationConfigServletWebServerApplicationContext，塞进去AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner context = createApplicationContext(); // 调用工具类读取jar包内/META-INF/spring.factories，获取所有异常报告器 exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class,new Class[] { ConfigurableApplicationContext.class }, context); // 给上下文设置env、给Context注册参数、执行初始化器的方法、-------发布ApplicationContextInitializedEvent事件、给BeanFactory注册应用的启动参数、load方法new了一个AnnotatedBeanDefinitionReader，把启动类注册进去。--------发布ApplicationPreparedEvent事件。 prepareContext(context, environment, listeners, applicationArguments, printedBanner); //---------------------准备工作结束，开始进入spring // 刷新context，调用applicationContext.refresh()进入AbstractApplicationContext的resresh方法，也就是常规spring流程------------ refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); } listeners.started(context); callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } return context; } &lt;!--￼15--&gt; - 先根据运行模式创建一个环境，这里是`StandardServletEnvironment`，也有相应式的`StandardReactiveWebEnvironment` - 解析启动参数到env中，启动参数解析`spring.profiles.active`选择生效的配置文件 解析env中的忽略bean设置到System.property中 打印banner 根据类型创建不同的Context，反射创建一个AnnotationConfigServletWebServerApplicationContext prepareContext准备上下文： 给上下文设置env、给Context注册参数、执行初始化器的方法、发布ApplicationContextInitializedEvent事件、给BeanFactory注册应用的启动参数、load方法new了一个AnnotatedBeanDefinitionReader，把启动类注册进去。发布ApplicationPreparedEvent事件。 private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) { // 上下文设置env context.setEnvironment(environment); // 给context设置一些属性，类型转换器ConversionService postProcessApplicationContext(context); // 拿到所有的初始化器，执行初始化方法initializer.initialize(context);可以给context进行拓展，如给context添加BeanFactoryPostPocessor applyInitializers(context); listeners.contextPrepared(context); // 发布ApplicationContextInitializedEvent事件----------------------------------第三个事件，进行一堆初始化 if (this.logStartupInfo) { logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); // 打印生效的配置文件 } // Add boot specific singleton beans 给beanFactory注册springBoot特殊的对象 ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); // 注册应用参数 beanFactory.registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) { beanFactory.registerSingleton(\"springBootBanner\", printedBanner); } // 设置是否允许BeanDefinition覆盖 if (beanFactory instanceof DefaultListableBeanFactory) { ((DefaultListableBeanFactory) beanFactory).setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); } // 添加一个懒加载的BFPP if (this.lazyInitialization) { context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); } // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); // 重要-------------把当前启动类注册到AnnotatedBeanDefinitionReader里面。new了一个AnnotatedBeanDefinitionReader实现，调用其load方法，里面判断了isComponent。是的话就annotatedReader.register(source);source就是启动类。注册到BeanDefinitionReader中。使得我们的主启动类可以被发现。 // 我们的@SpringBootApplication也是继承自@Component的，所以上面isComponent才可以。 // 后续在spring的resresh的invokeBFPP(beanFactory)中调用postProcessBeanDefinitionRegistry--&gt;processConfigBeanDefinitions,判断对象是否是@Configuration的，是否是@Order，解析每一个用@Configuration标识的类，parse方法内--&gt;doProcessConfigurationClass进行自动装配。 load(context, sources.toArray(new Object[0])); // 发布事件-------------------------------ApplicationPreparedEvent-----------------------------------第四个事件 listeners.contextLoaded(context); } &lt;!--￼16--&gt; springboot的核心功能还是在spring里面： 自动装配在invokeBeanFactoryPostProcessor完成 后续spring中的refresh里面，finishrefresh完成tomcat启动 临时参考，自己画后干掉 工具方法# 工具方法getSpringFactoriesInstances# private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) 传入想获取的类型，如上面的getSpringFactoriesInstances(ApplicationContextInitializer.class)就可以获取所有META-INF/spring.factories文件中配置key为ApplicationContextInitializer的实现。 ClassLoader从每个jar包的META-INF/spring.factories中读取个个properties，默认的三个见附录。都是一个key，一大串value，然后放到Map缓存中。 然后反射拿到各个value中的bean名称，使用构造方法创建对象list（一个key对应多个对象）。 使用@Order对上面的bean进行排序，返回list。 多拨器发布事件# SimpleApplicationEventMulticaster#multicastEvent方法用于发布启动、EnvPrepared、： 如刚开始启动的时候：initialMulticaster.multicastEvent(new ApplicationStartingEvent(this.application, this.args)) 发布了一个启动方法 12345678910111213public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); Executor executor = getTaskExecutor(); // getApplicationListeners拿到event和一个resolvableType去拿所有支持这个事件的listener，底层是用event的时间源source类名去各个listener中判断当前listener是否supportEvents支持这个event源，支持的话才能拿到。 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; invokeListener(listener, event); // 执行所有的listener.onApplicationEvent(event); &#125; &#125; &#125; public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;… primarySources) ，resourceLoader是null，primarySources是当前启动main类 webApplicationType = WebApplicationType.deduceFromClasspath(); 去决定我们的 new 的时候完成了prepare 环境准备好之后，发布environmentPreparedEvent，然后发布事件，listener挨个执行。 创建上下文对象AnnotationConfigServletWebServerApplicationContext prepareContext：# 附录# org.springframework.context.ApplicationContextInitializer和org.springframework.context.ApplicationListener 在启动并new SpringApplication的时候加载 spring-boot-2.3.1.RELEASE.jar # META-INF/spring.factories# spring-boot-2.3.1.RELEASE.jar中的spring.factories文件参考： 里面有个8个key，功能如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# PropertySource Loaders-----------加载properties或者yaml配置文件的org.springframework.boot.env.PropertySourceLoader=\\org.springframework.boot.env.PropertiesPropertySourceLoader,\\org.springframework.boot.env.YamlPropertySourceLoader# Run Listeners------------启动的监听器，用于事件发布org.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener# Error Reporters----------------异常报告器org.springframework.boot.SpringBootExceptionReporter=\\org.springframework.boot.diagnostics.FailureAnalyzers# Application Context Initializers----------------初始化器org.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\org.springframework.boot.context.ContextIdApplicationContextInitializer,\\org.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\org.springframework.boot.rsocket.context.RSocketPortInfoApplicationContextInitializer,\\org.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer# Application Listeners-----------------监听器列表，文件编码、配置文件、日志org.springframework.context.ApplicationListener=\\org.springframework.boot.ClearCachesApplicationListener,\\org.springframework.boot.builder.ParentContextCloserApplicationListener,\\org.springframework.boot.cloud.CloudFoundryVcapEnvironmentPostProcessor,\\org.springframework.boot.context.FileEncodingApplicationListener,\\org.springframework.boot.context.config.AnsiOutputApplicationListener,\\org.springframework.boot.context.config.ConfigFileApplicationListener,\\org.springframework.boot.context.config.DelegatingApplicationListener,\\org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\org.springframework.boot.context.logging.LoggingApplicationListener,\\org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener# Environment Post Processors---------------环境处理processor，json环境、等等org.springframework.boot.env.EnvironmentPostProcessor=\\org.springframework.boot.cloud.CloudFoundryVcapEnvironmentPostProcessor,\\org.springframework.boot.env.SpringApplicationJsonEnvironmentPostProcessor,\\org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor,\\org.springframework.boot.reactor.DebugAgentEnvironmentPostProcessor# Failure Analyzers----------------各种异常的失败解析器org.springframework.boot.diagnostics.FailureAnalyzer=\\org.springframework.boot.diagnostics.analyzer.BeanCurrentlyInCreationFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.BeanDefinitionOverrideFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.BeanNotOfRequiredTypeFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.BindFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.BindValidationFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.UnboundConfigurationPropertyFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.ConnectorStartFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.NoSuchMethodFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.NoUniqueBeanDefinitionFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.PortInUseFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.ValidationExceptionFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyNameFailureAnalyzer,\\org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyValueFailureAnalyzer# FailureAnalysisReporters-----------------异常失败分析报告器org.springframework.boot.diagnostics.FailureAnalysisReporter=\\org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter spring-boot-autoconfigure-2.3.1.RELEASE.jar#spring.factories# 内容和功能如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165# Initializers----------初始化器org.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener# Application Listeners----------------后台预初始化器org.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listeners-----------------------自动配置的ImportListenerorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filters------------------------自动配置的ImportFilter条件org.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnBeanCondition,\\org.springframework.boot.autoconfigure.condition.OnClassCondition,\\org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition# Auto Configure-----------------自动配置的核心类EnableAutoConfiguration，可以看到里面集成了ES、JPA、Mongo、Neo4j、Redis、MQ等等org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRestClientAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jdbc.JdbcRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.r2dbc.R2dbcDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.r2dbc.R2dbcRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.r2dbc.R2dbcTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.ElasticsearchRestClientAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\\org.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\\org.springframework.boot.autoconfigure.r2dbc.R2dbcAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketRequesterAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketServerAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketStrategiesAutoConfiguration,\\org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,\\org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration,\\org.springframework.boot.autoconfigure.security.rsocket.RSocketSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.client.reactive.ReactiveOAuth2ClientAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.resource.reactive.ReactiveOAuth2ResourceServerAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration,\\org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.client.WebServiceTemplateAutoConfiguration# Failure analyzers----------------异常失败解析器org.springframework.boot.diagnostics.FailureAnalyzer=\\org.springframework.boot.autoconfigure.diagnostics.analyzer.NoSuchBeanDefinitionFailureAnalyzer,\\org.springframework.boot.autoconfigure.flyway.FlywayMigrationScriptMissingFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.DataSourceBeanCreationFailureAnalyzer,\\org.springframework.boot.autoconfigure.jdbc.HikariDriverConfigurationFailureAnalyzer,\\org.springframework.boot.autoconfigure.r2dbc.ConnectionFactoryBeanCreationFailureAnalyzer,\\org.springframework.boot.autoconfigure.session.NonUniqueSessionRepositoryFailureAnalyzer# Template availability providers-------------------模板引擎支持org.springframework.boot.autoconfigure.template.TemplateAvailabilityProvider=\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.mustache.MustacheTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafTemplateAvailabilityProvider,\\org.springframework.boot.autoconfigure.web.servlet.JspTemplateAvailabilityProvider spring-beans-5.2.7.RELEASE.jar#spring.factories# 1org.springframework.beans.BeanInfoFactory=org.springframework.beans.ExtendedBeanInfoFactory SpringBoot自动装配原理# 首先，一句话描述“在BeanFactoryPostProcessor中完成的。”具体来说： 启动过程：# 住启动类里面的run方法，底层new了一个SpringApplicatin,执行他的run方法。 new这个SpringApplicatin这个过程会推断我们的运行环境，是Sevlet、还是Groovy、还是Reactive 解析/META-INF/spring.factories，从这个文件里面加载初始化器、加载ApplicationListener，放到当前的对象里。 推断主启动类，new了一个RuntimeException，找到堆栈中main的那个类 继续执行run方法： 启动一个计时器stopWatch，配置headless 从/META-INF/spring.factories找到一个SpringRunListener的实现，默认是EventPublishListenr，创建他，并在他里面塞了一个多拨器。多拨器里面是上面的一堆listener。 发布第一个事件：ApplicationStartingEvent： 有一个BackgrougPreInitListener判断多核就启动一个后台线程去执行初始化（jackson、conversion、messegeConvert）。 DelegatingApplicatoinListener转发事件到用户的listener中去，此时为空。 准备系统环境参数prepareEnvironment：将请求参数封装，拿出来系统参数、serlvet-init param封装、获取active-profiles，发布EnvironmentPreparedEvent： ConfigFileApplicationListener从env拿到active-profiles，读取配置文件 LoggingApplicationListenerenv拿到参数，设置日志文件、等级 DelegatingApplicationListener—解析配置文件**context.listener.classes**参数的类名，把用户实现了ApplicationListener的类都拿出来。 打印banner **创建上下文createApplicationContext：**既然是创建，先要知道类型。根据构造方法里面的运行环境是servlet，new了一个AnnocationConfigSevletWebServerApplicationContext对象，反射创建，作为我们的核心context对象。构造方法里： 创建了DefaultListableBeanFactory，new了两个核心对象塞进去： AnnotatedBeanDefinitionReader(this)传入当前context作为BeanDefinitionRegistry注册中心。里面创建并注册了核心的Annocation PostProcessor的BeanDefinition： ConfigurationClassPostProcessor：后续自动装配的核心类 AutowiredAnnotationBeanPostProcessor：后续IOC注入的一个核心类 ClassPathBeanDefinitionScanner(this)同样传入context、env、resourceLoader 准备上下文prepareContext(context, environment, listeners, applicationArguments, printedBanner)： postProcessingContext(ctx)：给BF塞进去一堆conversionService（数字、字符、日期转换服务） applyInitializers：应用所有的初始化器： DelegatingApplicationContextInitializer:又是一个委托代理，把配置文件的context.initializer.classes解析出来实例化，执行，默认空的。 发布ApplicationContextInitializedEvent事件,同样由EventPublishingRunListener使用多拨器发布事件: DelegatingApplicationListener：转发请求到用户自定义的listener中去 load方法：加载资源、识别注解，使得当前启动类是可以被识别到： 创建BeanDefinitionLoader，里面塞了AnnotatedBeanDefinitionReader(registry) 进入重载的load(启动类)方法，判断isComponent(启动类)，当前启动类的继承接口中是否@Component修饰（必然是，因为@Configuration是）： 去给启动类创建一个Definitio（解析了@Lazy、@Primary、@DependsOn），然后把启动类的definition注册到context中去 把启动类注册到annocationReader中去------把我们的主启动类让Spring注解能扫描到 发布ApplicationPreparedEvent事件： DelegatingApplicacationListener转发给用户自定义listener 其他的没啥了，PrepareContext的事件业务，实现类大多都在上一步的ApplicationContextInitializedEvent做了 刷新上下文application.refreshContext(context)： super.refresh()中调用了**ConfigurableApplicationContext#refresh()**进入AbstractApplicationContext.refresh()方法，也就是经典springframework流程。 下面就开始真正的refresh()过程，分割一下更清晰： prepareRefresh()：没啥用，设置启动时间、启动停止标志位 obtainFreshBeanFactory()：直接拿到DefaultListableBeanFactory，经典springframework此处是new的 prepareBeanFactory(BF)： 给BF设置参数,BF里面注册env， 添加一个BPP：ApplicationContextAwareProcessor，处理各种Aware，后续创建Bean的时候可以根据Bean实现的Aware的类型塞进去context、env、ApplicationEventPublisher等。 BF添加一个BPP：ApplicationListenerDetector，用来识别所有的ApplicationListener **postProcessBeanFactory(BF)**给BF设置参数、初始化SCOPE、初始化Ruquest、Response、Session各自的ObjectFactory **invokeBeanFactoryPostProcessors(BF)**实例化并执行所有已经注册的BFPP，有顺序的话按照顺序执行，自动装配在此实现： **PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(BF, getBeanFactoryPostProcessors());**里面的逻辑几块都是重复的： 从BF中拿出所有的BFPP，然后将子类BDRPP放到一个list中，BPP放到一个list中： 依次先找@PriorityOrdered、再@Ordered、再others去寻找BeanDefinitionRegistryPostProcessor和BeanFactoryPostProcessor,创建、排序后执行。 其中：**``ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry(BF)`**实现了自动装配： **processConfigBeanDefinitions()**方法做了： 拿出BF所有的类定义，找到@Configuration修饰的（此时默认只有启动类） new ConfigurationClassParser().parse(ConfigurationBeanNames)：参数也只有启动类。 parse方法进入一个核心干活的**ClassPathBeanDefinitionScanner#doScan**会去扫描子包，解析所有子包的@Component的类，判断Scope、生成BeanName、设置AutoWire类型、initMethodName、destroyMethodName、解析@Lazy、@Primary、@DependsOn然后生成一个Set&lt;BeanDefinitionHolder&gt;类定义。 同时记录下了所有的@Configuration类 上面parse的doScan扫描完毕后，会拿到2个默认的@Import类就是我们启动类配置文件上面的。使用processImports方法处理@Import，完成自动装配。准备工作： 循环Set&lt;BeanDefinitionHolder&gt;（扫描来的每个类定义），检查是否配置类，检查逻辑： 是@Configuration，且类定义元数据中的proxyBeanMethods不存在，设置类定义的configurationClass=full。 是 @Configuration且有proxyBeanMethods、或者非@Configuration的@Import、@Component、@ImportResource、@ComponentScan，设置类定义的configurationClass=lite。塞进去order，返回true 其他返回false **对上面每个确认通过的(可能的)配置类调用parse(className,beanName),又递归调用processConfigurationClass递归分类处理。 ConfigurationClassParser#processImports方法，核心中的核心： importStack(配置类)入栈 判断导入的类： 是启动类的 @EnableAutoConfiguration里面的@Import(AutoConfigurationImportSelector.class) 判断是ImportSelector的子类： 加载AutoConfigurationImportSelector类并实例化selector deferredImportSelectorHandler.handle(启动类Class、selector)完成自动装配，下面是细节-----递归，也会出入栈 - 是启动类的 @Import(AutoConfigurationPackages.Registrar.class)判断是ImportBeanDefinitionRegistrar的子类： - Defer - 实例化一个AutoConfigurationPackages.Registrar对象，塞进去BF、env、resourceLoader - impoimportBeanDefinitionRegistrars.put(registrar, 启动类MetaData)放进去这个对象 如果导入的类不是上面两种，processConfigurationClass把导入的类当作普通@Configuration类处理。 上面三种情况处理的结果都放到configClass这个list中 importStack(配置类)出栈 最后调用deferredImportSelectorHandler.process()去处理所有的import ConfigurationClassParser$DeferredImportSelectorHandler#handle(configClass,selector)处理DeferredImportSelector：----------递归逻辑 - 大体是解析`META-INF/spring.factories`中的自动配置类，筛选满足Condition的对象`deferredImportSelectorHandler.process()`： - `handler`的`deferredImportSelectors`对象里面有上面启动类`@EnableAutoConfiguration`上面的 `@AutoConfigurationImportSelector`对象(env,BF)，多个的话是list，排序。 - **`handler.processGroupImports()`**,执行分组导入，先执行grouping.getImports()方法去真正获取配置类： - **grouping.getImports()**会调用到`group.select()`会进入到**`AutoConfigurationImportSelector#process(annoMetaData, selector)`**方法。 - 最后落地调用了**`AutoConfigurationImportSelector#getAutoConfigurationEntry(annocationMetaData)`**方法去加载配置文件：**`SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class)`**去拿到`META-INF/spring.factories`里面所有的`EnableAutoConfiguration`自动配置类。(springboot2默认拿出来124个所有的自动装配类) - 处理`@ConditionOnBean、@ConditionOnMissingBean、@OnWebApplicationCondition`，删掉不符合的，剩下的就是有效的自动装配类（默认29个） 最后**Selector.selectImports()**，筛选我们配置文件上配置的exclude排除的配置类。（默认没有） 然后grouping.getImports().forEach(eachAotuConfiduration-&gt;{processImports(启动类,当前配置AnnotationMetaData)})-----开始递归一次解析当前自动装配类： importStack入栈---&gt;processConfigurationClass---&gt;doProcessConfigurationClass(解析@Component和递归内嵌方法@Configuration)---&gt;importStack出栈 后面依次再来上面的流程。 核心配置主启动类 @SpringBootApplication# 标明这是一个主启动类，是一个聚合注解，会同时触发@Configuration ，@EnableAutoConfiguration和@ComponentScan，参数有 exclude/excludeName要排除的自动装配的类/类名数组，从@EnableAutoConfiguration继承而来 scanBasePackages/scanBasePackageClasses要扫描@Components的包和类集合 nameGenerator:beanName生成器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111package org.springframework.boot.autoconfigure;/** * Indicates a &#123;@link Configuration configuration&#125; class that declares one or more * &#123;@link Bean @Bean&#125; methods and also triggers &#123;@link EnableAutoConfiguration * auto-configuration&#125; and &#123;@link ComponentScan component scanning&#125;. This is a convenience * annotation that is equivalent to declaring &#123;@code @Configuration&#125;, * &#123;@code @EnableAutoConfiguration&#125; and &#123;@code @ComponentScan&#125;. * * @author Phillip Webb * @author Stephane Nicoll * @author Andy Wilkinson * @since 1.2.0 */@SpringBootConfiguration // @EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ @AliasFor(annotation = EnableAutoConfiguration.class) Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ @AliasFor(annotation = EnableAutoConfiguration.class) String[] excludeName() default &#123;&#125;; /** * Base packages to scan for annotated components. Use &#123;@link #scanBasePackageClasses&#125; * for a type-safe alternative to String-based package names. * &lt;p&gt; * &lt;strong&gt;Note:&lt;/strong&gt; this setting is an alias for * &#123;@link ComponentScan @ComponentScan&#125; only. It has no effect on &#123;@code @Entity&#125; * scanning or Spring Data &#123;@link Repository&#125; scanning. For those you should add * &#123;@link org.springframework.boot.autoconfigure.domain.EntityScan @EntityScan&#125; and * &#123;@code @Enable...Repositories&#125; annotations. * @return base packages to scan * @since 1.3.0 */ @AliasFor(annotation = ComponentScan.class, attribute = \"basePackages\") String[] scanBasePackages() default &#123;&#125;; /** * Type-safe alternative to &#123;@link #scanBasePackages&#125; for specifying the packages to * scan for annotated components. The package of each class specified will be scanned. * &lt;p&gt; * Consider creating a special no-op marker class or interface in each package that * serves no purpose other than being referenced by this attribute. * &lt;p&gt; * &lt;strong&gt;Note:&lt;/strong&gt; this setting is an alias for * &#123;@link ComponentScan @ComponentScan&#125; only. It has no effect on &#123;@code @Entity&#125; * scanning or Spring Data &#123;@link Repository&#125; scanning. For those you should add * &#123;@link org.springframework.boot.autoconfigure.domain.EntityScan @EntityScan&#125; and * &#123;@code @Enable...Repositories&#125; annotations. * @return base packages to scan * @since 1.3.0 */ @AliasFor(annotation = ComponentScan.class, attribute = \"basePackageClasses\") Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;; /** * The &#123;@link BeanNameGenerator&#125; class to be used for naming detected components * within the Spring container. * &lt;p&gt; * The default value of the &#123;@link BeanNameGenerator&#125; interface itself indicates that * the scanner used to process this &#123;@code @SpringBootApplication&#125; annotation should * use its inherited bean name generator, e.g. the default * &#123;@link AnnotationBeanNameGenerator&#125; or any custom instance supplied to the * application context at bootstrap time. * @return &#123;@link BeanNameGenerator&#125; to use * @see SpringApplication#setBeanNameGenerator(BeanNameGenerator) * @since 2.3.0 */ @AliasFor(annotation = ComponentScan.class, attribute = \"nameGenerator\") Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; /** * Specify whether &#123;@link Bean @Bean&#125; methods should get proxied in order to enforce * bean lifecycle behavior, e.g. to return shared singleton bean instances even in * case of direct &#123;@code @Bean&#125; method calls in user code. This feature requires * method interception, implemented through a runtime-generated CGLIB subclass which * comes with limitations such as the configuration class and its methods not being * allowed to declare &#123;@code final&#125;. * &lt;p&gt; * The default is &#123;@code true&#125;, allowing for 'inter-bean references' within the * configuration class as well as for external calls to this configuration's * &#123;@code @Bean&#125; methods, e.g. from another configuration class. If this is not needed * since each of this particular configuration's &#123;@code @Bean&#125; methods is * self-contained and designed as a plain factory method for container use, switch * this flag to &#123;@code false&#125; in order to avoid CGLIB subclass processing. * &lt;p&gt; * Turning off bean method interception effectively processes &#123;@code @Bean&#125; methods * individually like when declared on non-&#123;@code @Configuration&#125; classes, a.k.a. * \"@Bean Lite Mode\" (see &#123;@link Bean @Bean's javadoc&#125;). It is therefore behaviorally * equivalent to removing the &#123;@code @Configuration&#125; stereotype. * @since 2.2 * @return whether to proxy &#123;@code @Bean&#125; methods */ @AliasFor(annotation = Configuration.class) boolean proxyBeanMethods() default true;&#125; @SpringBootConfiguration# 是上面SpringBootApplication引用的一个注解，就是表明我是一个@Configuration，可以被扫描加载。起一个别名，是因为是启动类的，需要特殊一点，所需的时候可以找到。 proxyBeanMethods是@Configuration里面的一个注解。决定我们是否@Bean标注的方法应该使用CGlib进行代理，用来保证bean的生命周期行为。 例如，即使在直接的情况下返回共享单例bean实例获得代理@Bean用户代码的方法调用。 该功能要求的方法的拦截，通过它配有限制的运行时生成的CGLIB子类实现如配置类及其方法不被允许声明final 。 默认为true ，允许配置类内部以及外部调用该配置的“bean间引用” @Bean 方法之间没有调用关系的话可以把 proxyBeanMethods 设置为 false以免CGLIB子类的处理。 关闭bean方法拦截有效地处理@Bean方法来单独像非申报时@Configuration班，又名“@Bean精简版模式”（见@Bean’s javadoc ）。 因此，它是行为上等同于除去@Configuration版本。 1234567891011121314151617181920212223242526272829303132@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Configurationpublic @interface SpringBootConfiguration &#123; /** * Specify whether &#123;@link Bean @Bean&#125; methods should get proxied in order to enforce * bean lifecycle behavior, e.g. to return shared singleton bean instances even in * case of direct &#123;@code @Bean&#125; method calls in user code. This feature requires * method interception, implemented through a runtime-generated CGLIB subclass which * comes with limitations such as the configuration class and its methods not being * allowed to declare &#123;@code final&#125;. * &lt;p&gt; * The default is &#123;@code true&#125;, allowing for 'inter-bean references' within the * configuration class as well as for external calls to this configuration's * &#123;@code @Bean&#125; methods, e.g. from another configuration class. If this is not needed * since each of this particular configuration's &#123;@code @Bean&#125; methods is * self-contained and designed as a plain factory method for container use, switch * this flag to &#123;@code false&#125; in order to avoid CGLIB subclass processing. * &lt;p&gt; * Turning off bean method interception effectively processes &#123;@code @Bean&#125; methods * individually like when declared on non-&#123;@code @Configuration&#125; classes, a.k.a. * \"@Bean Lite Mode\" (see &#123;@link Bean @Bean's javadoc&#125;). It is therefore behaviorally * equivalent to removing the &#123;@code @Configuration&#125; stereotype. * @return whether to proxy &#123;@code @Bean&#125; methods * @since 2.2 */ @AliasFor(annotation = Configuration.class) boolean proxyBeanMethods() default true;&#125; @EnableAutoConfiguration# 这个注解用来启用Spring应用程序上下文自动配置，尝试推断和自动配置bean。 自动配置类通常采用基于你的classpath中已有的bean定义。 举例来说，如果你有tomcat-embedded.jar在classpath中，你可能会想TomcatServletWebServerFactory （除非您已经定义了自己ServletWebServerFactorybean）。 当使用@SpringBootApplication ，自动配置上下文的，因此添加这个注解没有额外的效果。 自动配置尝试将智能地实现我们自己的配置， 您可以随时手动exclude()的任何配置，（使用excludeName()如果您没有访问它们）。或者通过spring.autoconfigure.exclude配置来排除无需引入的配置类。 通常通过@SpringBootApplication来使用 此注解。 如果你不使用@SpringBootApplication， 通常建议您将@EnableAutoConfiguration放在根目录，它会去搜索所有子包和类。 被自动配置类是普通的Spring @Configurationbean。 他们使用的是位于SpringFactoriesLoader机制（键控对这个类）。 一般的自动配置bean类@Conditionalbean（最常使用@ConditionalOnClass和@ConditionalOnMissingBean注释） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Enable auto-configuration of the Spring Application Context, attempting to guess and * configure beans that you are likely to need. Auto-configuration classes are usually * applied based on your classpath and what beans you have defined. For example, if you * have &#123;@code tomcat-embedded.jar&#125; on your classpath you are likely to want a * &#123;@link TomcatServletWebServerFactory&#125; (unless you have defined your own * &#123;@link ServletWebServerFactory&#125; bean). * &lt;p&gt; * When using &#123;@link SpringBootApplication @SpringBootApplication&#125;, the auto-configuration * of the context is automatically enabled and adding this annotation has therefore no * additional effect. * &lt;p&gt; * Auto-configuration tries to be as intelligent as possible and will back-away as you * define more of your own configuration. You can always manually &#123;@link #exclude()&#125; any * configuration that you never want to apply (use &#123;@link #excludeName()&#125; if you don't * have access to them). You can also exclude them via the * &#123;@code spring.autoconfigure.exclude&#125; property. Auto-configuration is always applied * after user-defined beans have been registered. * &lt;p&gt; * The package of the class that is annotated with &#123;@code @EnableAutoConfiguration&#125;, * usually via &#123;@code @SpringBootApplication&#125;, has specific significance and is often used * as a 'default'. For example, it will be used when scanning for &#123;@code @Entity&#125; classes. * It is generally recommended that you place &#123;@code @EnableAutoConfiguration&#125; (if you're * not using &#123;@code @SpringBootApplication&#125;) in a root package so that all sub-packages * and classes can be searched. * &lt;p&gt; * Auto-configuration classes are regular Spring &#123;@link Configuration @Configuration&#125; * beans. They are located using the &#123;@link SpringFactoriesLoader&#125; mechanism (keyed * against this class). Generally auto-configuration beans are * &#123;@link Conditional @Conditional&#125; beans (most often using * &#123;@link ConditionalOnClass @ConditionalOnClass&#125; and * &#123;@link ConditionalOnMissingBean @ConditionalOnMissingBean&#125; annotations). */@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125; @AutoConfigurationPackage# 注册配置的basePackageClasses或basePackageClasses数组。如果没有指定这两个参数，那就注册当前配置的这个类（主启动类） 1234567891011121314151617181920212223242526272829303132333435/** * Registers packages with &#123;@link AutoConfigurationPackages&#125;. When no &#123;@link #basePackages * base packages&#125; or &#123;@link #basePackageClasses base package classes&#125; are specified, the * package of the annotated class is registered. * @see AutoConfigurationPackages */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(AutoConfigurationPackages.Registrar.class)public @interface AutoConfigurationPackage &#123; /** * Base packages that should be registered with &#123;@link AutoConfigurationPackages&#125;. * &lt;p&gt; * Use &#123;@link #basePackageClasses&#125; for a type-safe alternative to String-based package * names. * @return the back package names * @since 2.3.0 */ String[] basePackages() default &#123;&#125;; /** * Type-safe alternative to &#123;@link #basePackages&#125; for specifying the packages to be * registered with &#123;@link AutoConfigurationPackages&#125;. * &lt;p&gt; * Consider creating a special no-op marker class or interface in each package that * serves no purpose other than being referenced by this attribute. * @return the base package classes * @since 2.3.0 */ Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;&#125; @Configuration# 是Spring定义的一个注解，而不是Springboot才有的。@Configuration 又依赖于 @Component，是一个Spring中就有的配置类，用来标记我们的一个Class是一个类似传统xml配置文件，里面有很多Bean。在Springboot中，它是被自动装配的对象。 Spring容器启动中@Configuration的过程： `AbstractApplicationContext::refresh–&gt;AbstractApplicationContext::invokeBeanFactoryPostProcessors –&gt;ConfigurationClassPostProcessor::postProcessBeanFactory–&gt;ConfigurationClassPostProcessor::enhanceConfigurationClasses` ConfigurationClassPostProcessor::enhanceConfigurationClasses这个方法是Configuration注解工作的核心方法， spring应用启动时所有的被@Configuration注解的类都会被spring cglib库生成cglib动态代理， 然后其他地方通过@Autowired注解引入业务Bean类对象就会被生成的configuration配置类生成的动态代理拦截， 处理完后再调用原configuration注解类的业务Bean方法获取到业务实例。 原文链接：https://blog.csdn.net/john1337/java/article/details/86544214 SpringBoot经典问题# 都搞定了，才能说熟练掌握SpringBoot BeanDefinition的定义，在spring体系当中beanDefinition的和bean的产生过程有什么关系， sping当中的各种BeanDefinition的作用 BeanDefinition有什么作用？如果来改变一个bean的行为， spring当中有哪些扩展点开源来修改beanDefinition 标记一个类的属性，包括class、singleton、lazy、constructor、depenedson BeanDefinitionRegistry的作用，源码分析，哪些开源框架利用了这个类 mybatis动态创建mapper的实现，注入到里面去。 BeanNameGenerator如何改变beanName的生成策略、如何自己写一个beanName的生成策略 BeanPostProcessor如何插手bean的实例化过程 经典的应用场景有哪些？ spring内部哪里用到了这个接口 程序员使用BPP接口实现类，可以在创建Bean之前改变bd的行为和属性，进行修改、增强。 会形成一个列表，依次执行，返回null就截至不再执行了 如AOP就在此时 BeanFactoryPostProcessor和BeanPostProcessor的区别、经典应用场景spring内部如何把他应用起来的 BeanDefinitionRegistryPostProcessor和BeanFactoryPostProcessor的关系已经区别, spring底层如何调用他们 BDRPP是BFPP的子类 ConfigurationClassPostProcessor这个类如何完成bean的扫描，如何完成@Bean的扫描，如何完成对@Import的解析 @lmoprt的三种类型，普通类，配置类ImportSelector， sprinq在底层源码当中如何来解析这三种importe @import普通类，只是加载 @import一个ImportSelector实现，这个实现会返回一个string[]，里面是选中的类名。反射得到对象 @import一个ImportBeanDefinitionRegistrar实现，在这个类中，可以拿到resigtry自己生成bd往里面注入。 上面的@Import注解最终都是在ConfigurationClassParser#processImports中进行解析。使用了一个ImportStarck的栈数据结构进行递归的链式import。细节如： 如何利用ImportSelector来完成寸spring的扩展？你所用的其他框架或者技术递明地方体现了这个类的使用 aop、mybatis @Confiauration这注解为什么可以不加？加了和不加的区别，底层为什么使用calib full，lite，后续增强 @Bean的方法是如何保证单例的？如果不需要单例需要这么配置？为什么需要这么配置 springFacoryBean和BeanFacory的区别，有哪些经典应用场景？ sprina的factoryMethod的经典应用场景？ ImportBeanDefinitionRegistrar这个接口的作用，其他主流框架如何利用这个类来完成和spring的结合的？ spring是什么时候来执行后置处理器的？有哪些重要的后置处理器，比如CommonAnnotationBeanPostProcessor CommonAnnotationBeanPostProcessor如何来完成spring初始化方法的回调。sprinq内部的各种Procesor的作用分别是什么 spring和springBoot当中的各种@Enablexx的原理是什么？如何自己实现一个？比如动态开启某某些自定义功能 spring如何来完成bean的循环依赖并且实例化的，什么是sprina的1OC容器，怎么通过源码来理解？ 其他，比如Bean的实例化过程，源码中的两次gegetSingleton的不同和相比如SpringMvc的源码分t等等… springboot里面有大量的listener，在meta-inf里面可以看到 springcloud的fegin实现使用的是FactoryBean","categories":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/tags/java/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.sofunnyai.com/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.sofunnyai.com/tags/SpringBoot/"}]},{"title":"AQS原理、Condition、ReentrantLock和ReentrantReadWriteLock","slug":"aqs源码和原理","date":"2018-09-02T05:24:15.000Z","updated":"2020-07-28T16:21:16.502Z","comments":true,"path":"article/aqs.html","link":"","permalink":"https://blog.sofunnyai.com/article/aqs.html","excerpt":"","text":"锁的前世今生 乐观锁与悲观锁 AQS AQS是啥 同步的抽象与各种实现： 从ReentrantLock说起 ReentrantLock的源码 AQS的内部 双向链表实现的同步队列 AQS加锁的源码 acquire入口—核心方法 tryAcquire子类实现的模板 addWaiter-线程如何排队— 自旋添加到尾部，直到成功为止 所以ReentrantLock排队的过程是： acquireQueued—尾入队获取锁 shouldParkAfterFailedAcquire 判断获取锁失败后是否应该park阻断 公平锁和非公平锁的体现 AQS锁释放的源码 ReentrantReadWriteLock读写锁（共享锁） 读写锁的status设计 写锁的代码 接着是读锁的代码： AQS的ConditionObject、await/signal API示例 Condition的等待队列 await等待 signal唤醒 参考 锁的前世今生# 先来一个镇楼图，来自美团技术： 锁的升级过程可以参见《多线程之volatile和synchronized》 乐观锁与悲观锁# 悲观锁：对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。（不能并发修改，只能排队顺序）-------适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁：而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 （可能并发修改，如果真并发修改了，再议）--------------适合读操作多(写少)的场景，不加锁的特点能够使其读操作的性能大幅提升。(没有加锁开销) 乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。 AQS# AQS是啥# 如果从来没有听说过AQS的同学要知道这个，可以先看下ReentrantLock，ReentrantLock实现了一个Lock接口，并持有一个私有抽象静态Sync对象，这个抽象Sync又有两个实现，分别是公平锁FairLock和非公平锁NonFiarLock。缺省是非公平锁。 公平锁：多个线程按照申请锁的顺序去获得锁，后申请锁的线程需要排队，等它之前的线程获得锁并释放后，它才能获得锁； 非公平锁：线程获得锁的顺序于申请锁的顺序无关，申请锁的线程可以直接尝试获得锁，谁抢到就是谁的； 具体的结构代码如下： 123456789101112131415161718public class ReentrantLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = 7373984872572414699L; /** Synchronizer providing all implementation mechanics */ private final Sync sync; // 实际ReentrantLock到底是公平还是非公平是new的时候指定的实现类。 /** * Base of synchronization control for this lock. Subclassed * into fair and nonfair versions below. Uses AQS state to * represent the number of holds on the lock. */ abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); 而抽象类Sync继承的AbstractQueuedSynchronizer类（简称AQS，抽象队列同步器）是是一个可以用来实现线程同步的基础工具。也就是说我们常用的ReentrantLock底层是由AQS实现的。 也就是说：AQS是一个提供了同步功能的基础设施，可以用它来完成锁同步等功能。在Java的并发包中大量使用。 同步的抽象与各种实现：# 器AQS是公共逻辑，各种Lock的实现算是自定义的业务逻辑： AQS和Sync、FairSync、NonfairSync都是公共的抽象逻辑，而Lock、ReadLock、ReentrantLock都算是业务逻辑。这些业务逻辑是有各个场景的特点，给予我们的公共抽象逻辑基础设施来实现的。 比如CountdownLatch里面也是有AQS和实现的。 此外ReentrantLock底层的Lock接口还保证了ReentrantLock的行为具有以下方法实现： 从ReentrantLock说起# ReentrantLock作为JUC包提供的可重入锁，和Synchronized关键字的区别如下： 1234567891011121314151617181920212223242526272829// **************************Synchronized的使用方式**************************// 1.用于代码块synchronized (this) &#123;&#125;// 2.用于对象synchronized (object) &#123;&#125;// 3.用于方法public synchronized void test () &#123;&#125;// 4.可重入for (int i = 0; i &lt; 100; i++) &#123; synchronized (this) &#123;&#125;&#125;// **************************ReentrantLock的使用方式**************************public void test () throw Exception &#123; // 1.初始化选择公平锁、非公平锁 ReentrantLock lock = new ReentrantLock(true); // 2.可用于代码块 lock.lock(); try &#123; try &#123; // 3.支持多种加锁方式，比较灵活; 具有可重入特性 if(lock.tryLock(100, TimeUnit.MILLISECONDS))&#123; &#125; &#125; finally &#123; // 4.手动释放锁 lock.unlock() &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html ReentrantLock的源码# 1234567891011121314151617181920212223public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; // 继承AQS，有一些默认实现 abstract static class Sync extends AbstractQueuedSynchronizer &#123; //...... 一些AQS的抽象方法实现 &#125; // 一些Sync抽象方法的实现（主要是非公平加锁和公平加锁，这里以非公平为例） static final class NonfairSync extends Sync &#123; final void lock() &#123; if (compareAndSetState(0, 1)) // CAS修改爷爷类AQS的state，去加锁--------------保证原子性 setExclusiveOwnerThread(Thread.currentThread()); // 修改成功的话去设置AQS当前锁的独占线程是我 else acquire(1); // 修改失败的就去AQS执行aquire尝试获得锁，看下面AQS &#125; // 实现AQS报错的源码获取一次锁，公平和非公平是两个实现，此处是非公平 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); // nonfairTryAcquire的实现：判断状态为0，独占是当前线程就重入+1返回true。不是重入的话就CAS抢占锁并设置AQS独占线程是我返回true，state=1或者没抢到返回false。 &#125; &#125; &#125; ReentrantLock内部使用了一个AQS的模板实现Sync，这个Sync又针对公平锁和非公平锁有两种实现。 非公平锁一上来就先CAS去修改AQS的锁状态state（unsafe用内存偏移量去修改，保证原子性），再去acquire(1) 公平的是上来就去acquire(1) acquire(1)可以看下面AQS的部分 AQS的内部# 开门见山： AQS内部有一个双向链表实现一个FIFO的同步队列来维护当前获取锁失败的线程。 使用一个volatile的int类型的同步状态state和一系列方法实现同步。（state的各个值什么含义是给子类去实现的） AQS内部还有一个当前独占线程，来标识谁在占用同步状态 AbstractQueuedSynchronizer使用了模板方法的设计模式，把大部分的流程都实现了，但关键步骤使用抽象方法、抛异常的方式，交给子类去强制实现个性化定制。如： 12345678910// 独占地获取锁和释放锁(非共享读写锁)protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;// 还有更多，见下图 AQS提供的模板方法主要分为三类： 独占式地获取和释放锁； 共享式地获取和释放锁； 查询AQS的同步队列中正在等待的线程情况； 双向链表实现的同步队列# AQS里面有一个volatile int类型的锁状态state，多线程CAS竞争修改。 AQS同步器内部有一个同步队列，每次线程获取锁失败就会增加一个Node到队尾，释放锁成功就会唤起队列最前面的Node中的线程，这个线程再去尝试。 队列中的头节点head就是当前已经获取了锁，正在执行的线程对应的节点；而之后的这些节点，则对应着获取锁失败，正在排队的线程。 AQS持有链表的head和tail节点，每个Node节点里面除了pre和next还有当前的线程。 当一个线程获取锁失败，它会被封装成一个Node，加入同步队列的尾部排队，同时线程会进入阻塞状态。 而当头节点对应的线程释放锁时，它会唤醒它的下一个节点。 被唤醒的节点对应的线程开始尝试获取锁，若获取成功，它就会将自己置为head，然后将原来的head移出队列。 AQS加锁的源码# acquire入口—核心方法# ReentrantLock的lock()方法调用了AQS的下面方法： 12345678// 原文注释说：这是一个独占模式、忽略被打断。通过至少一次成功的tryAcquire就能拿到锁。// 否则线程入队，反复调用tryAcquire被阻塞、解阻塞，直到返回true。// 这个方法可以用来实现Lock.lock()public final void acquire(int arg) &#123; // FiarSync这里直接传了1进来调用 if (!tryAcquire(arg) &amp;&amp; // tryAcquire成功则啥也没干地结束，失败继续，公平锁实现的时候如果有等的更久的会不去抢--------只有自己的时候不会排队 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 先包装Node，addWriter续尾，再acquireQueued去阻塞 selfInterrupt(); // 如果里面在队列等待锁的过程中，被别人interrupt了是无法响应的。解锁后这里要继续处理响应interruput方法。&#125; 首先调用tryAcquire尝试获取一次锁，若返回true，表示获取成功，则acquire方法将直接返回（没有构建同步队列）；若返回false，则会继续向后执行acquireQueued方法；-------公平和非公平此处tryAcquire的实现有差异，非公平先去CAS竞争state了一次再去判断重入，公平的直接判断没有等待的(hasQueuedPredecessors)的线程才acquire。 tryAcquire返回false后，将执行acquireQueued，但是这个方法传入的参数调用了addWaiter方法； addWaiter方法的作用是将当前线封装成同步队列的节点，然后加入到同步队列的尾部进行排队，并返回此节点；（CAS去设置head、tail，失败则for死循环再来一轮。第一个head是一个空节点） addWaiter方法执行完成后，将它的返回值作为参数，调用acquireQueued方法。acquireQueued方法的作用是让当前线程在同步队列中阻塞，然后在被其他线程唤醒时去获取锁；-----这里会阻塞park 若线程被唤醒并成功获取锁后，将从acquireQueued方法中退出，同时返回一个boolean值表示当前线程是否被中断，若被中断，则会执行下面的selfInterrupt方法，响应中断； tryAcquire子类实现的模板# tryAcquire是一个模板方法，留给子类的公平锁、非公平锁按场景去实现。不同的场景根据这个arg去修改state字段。 1234// 模板方法，留给子类去实现protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 公平锁实现的时候如果有等的更久的会不去抢，非公平锁上来就CAS抢state从0为1。成功就返回，没成功判断重入，重入返回true，否则false。 如果tryAcquire没竞争到锁，下面开始排队： addWaiter-线程如何排队— 自旋添加到尾部，直到成功为止# 获取锁失败后到达addWaiter添加一个等待者： 将当前线程new 一个Node放到队列尾部，如果队列为空创建一个傀儡节点再添加尾部（傀儡节点就代表现在正在运行的那个线程）。如果加入失败就自旋(enq)直到添加成功，最后返回此节点。 （CAS去setTail一遍，失败的话后面enq循环一遍一遍CAS保证成功入队续上） 123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 拿出尾，作为前序节点，第一次是null Node pred = tail; if (pred != null) &#123; // 如果有尾，说明不是第一次，否则是第一次队列未初始化执行下面enq循环再试 node.prev = pred; // 新节点的前指针，指向上一个尾 // CAS将新节点node设置为新尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; // 设置成功，前尾的后指针指向当前新尾 return node; &#125; // 尾为空，执行下面enq初始化队列 &#125; enq(node); // 初始化并CAS续尾（CAS设置head、tail） return node; // 返回 &#125; 没初始化则初始化，然后入队尾，注意初始化的时候new了一个空的傀儡节点作为header，然后再来一轮for循环CAS续上的。（如果没抢到就再来for循环，直到CAS抢到再返回） 1234567891011121314151617181920/** * Inserts node into queue, initializing if necessary 把node进行一次入队，需要的时候进行初始化 * @param node the node to insert * @return node's predecessor */ private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 拿出尾 if (t == null) &#123; // Must initialize 没有尾，说明是第一次，需要初始化一个空的head再往后排 if (compareAndSetHead(new Node())) // head使用CAS初始化了一个虚拟的傀儡节点！这里是重点！！！！此时多线程的锁会竞争 tail = head; // 初始化首尾都是同一个，然后重新来for一次添加尾 &#125; else &#123; //第二轮以上for，初始化过，往最后排 node.prev = t; // 当前节点的前一个设置为前尾 if (compareAndSetTail(t, node)) &#123; // CAS去看前尾变化没，没变化就变更新尾，此时多线程的锁会竞争 t.next = node; // 前尾的next指向新尾，尾巴成功修改 return t; // CAS续成功才会返回，否则永远来续-----------------------唯一出口 &#125;// CAS失败，说明前尾变更，被别的线程抢先续尾了，重新来入队续尾 &#125; &#125; &#125; 所以ReentrantLock排队的过程是：# AQS使用一个双向链表来代表线程的先后顺序，head永远是空。AQS内部有status，0-free，&gt;0-lock。Node内部有线程信息和waitStatus(CANCLE/SIGNAL/CONDITION/和共享锁的PROPAGATE)。 初始状态（也就是锁未被任何线程占用的时候）线程A申请锁此时，成功获取到锁，无排队线程（tryAcquire直接拿到true并返回） 线程B申请该锁，且上一个线程未释放：enq方法的for循环先创建一个空的Head(只有next指向)初始化队列，再来一个for循环添加当前Node（包含自身线程信息，和pre指向，模式独占或者共享）。 再来一个线程C申请该锁，且占有该锁的线程未释放：CAS来续尾成功就返回，失败的话去enq里面for的CAS续尾到成功为止。(成功后修改pre和自己的互相指向) 上面加入到队尾后，返回节点，传入下面的方法去获取锁。 acquireQueued—尾入队获取锁# acquireQueued方法就是把获取锁失败的Node放入队列中，让这个线程不断进行“获锁”,直到它**“成功获锁”**或者“不再需要锁（如被中断）” 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 对队列里的节点node进行独占的、不可打断的获取锁。 * acquire()中和condition对象的各种await方法中被使用。 * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return &#123;@code true&#125; if interrupted while waiting */final boolean acquireQueued(final Node node, int arg) &#123; // acquire方法传入了刚刚加入队尾的一个节点，await方法传入的是一个节点 boolean failed = true; try &#123; boolean interrupted = false; // 是否被打断的标识 for (;;) &#123; final Node p = node.predecessor(); // 拿到当前Node的前序节点 // 如果前序是head才会去CAS抢占锁。(现在这个线程解锁后也成为新的head了) if (p == head &amp;&amp; tryAcquire(arg)) &#123; //(tryAcquire是模板方法，子类FairSync等实现的，去尝试CAS修改state获取锁后，下面再来把自己变成head) // 到这里就是已经获取到锁了，旧头换新头（上面是CAS的，这里没有线程安全问题） setHead(node); // 这个是把当前节点设置为傀儡节点头，删除里面的thread等信息（已经拿到锁了，放thread没有意义，无助于GC） p.next = null; // help GC 释放之前的傀儡头引用，帮助回收 failed = false; return interrupted; //----------------------------唯一出口。 返回打断标识 &#125; // 自己不是老二（前序不是head）或者老二获取锁tryAcquire失败了，踏踏实实的先看是否应该park // 如果可以的话park等待，然后阻塞检查是否打断。打断了进入if内，没打断就结束这一轮获取。（不可能让一直死循环for来判断，CPU该爆炸了） // 不应该park的话就继续下一轮for再来抢占 // shouldParkAfterFailedAcquire方法判断当前线程是否能够进入等待状态， // 若当前线程的节点不是头节点的下一个节点，则需要进入等待状态， // 在此方法内部，当前线程会找到它的前驱节点中，第一个还在正常等待或执行的节点， // 让其作为自己的直接前驱，然后在需要时将自己唤醒（因为其中有些线程可能被中断）， // 若找到，则返回true，表示自己可以进入等待状态了； // 则继续调用parkAndCheckInterrupt方法，当前线程在这个方法中等待， // 直到被其他线程唤醒，或者被中断后返回，返回时将返回一个boolean值， // 表示这个线程是否被中断，若为true，则将执行下面一行代码，将中断标志置为true if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 前面节点是SIGNAL，返回true可以阻塞自己 parkAndCheckInterrupt()) // 阻塞等待被唤醒，使用LockSupport.park() ------------------------------------此时外面lock.lock()会阻塞，业务代码等待。 interrupted = true; &#125; &#125; finally &#123; // 上面代码中只有一个return语句，且return的前一句就是failed = false; // 所以只有当异常发生时，failed才会保持true的状态运行到此处； // 异常可能是线程被中断，也可能是其他方法中的异常， // 比如我们自己实现的tryAcquire方法 // 此时将取消线程获取锁的动作，将它从同步队列中移除 if (failed) cancelAcquire(node); &#125; &#125; 方法的主流程如下： shouldParkAfterFailedAcquire 判断获取锁失败后是否应该park阻断# 首先记着这个方法是在一个死循环中，获取锁失败就来执行一遍。为了方式for死循环大量占用CPU，可以想象绝大部分节点必然是返回true，然后park的。 1234567891011121314151617181920212223242526272829303132333435363738/** * 检查并更新无法获取锁的节点的状态。在所有循环里返回true就阻塞。要求传入的pred 就是node的前序Node.pre指向的那个 * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return &#123;@code true&#125; if thread should block */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 前序节点等待状态 // Node的WaitStatus，这里的SIGNAL是release方法写入的，下面再说 if (ws == Node.SIGNAL) // 前序节点已经release，发出信号了，返回true标识可以park阻塞---------------这是唯一一个可以阻塞的true返回 /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; // 前序节点是取消状态，一直往前反向找到一个非取消的，这些Cancelled都被删掉了 /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; //--------------其实是删掉了所有中途取消的节点，继续外面的for死循环来进下一轮 &#125; else &#123; // 前一节点是0或者传播状态，我们需要一个信号，但是还没park阻塞，此轮CAS设置把前一节点为SIGNAL状态，让调用者重新再来一遍就会阻塞他。 /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); // pre设置为SIGNAL，下一轮来入口返回true，会阻塞 &#125; return false; //-----------删掉了cancel节点，或者SIGNAL了0或者传播节点，下一轮来阻塞 &#125; 上面方法的流程图如下： https://zhuanlan.zhihu.com/p/54297968 公平锁和非公平锁的体现# “不管公平还是非公平模式下，ReentrantLock对于排队中的线程都能保证，排在前面的一定比排在后面的线程优先获得锁”但是，非公平模式不保证“队列中的第一个线程一定就比新来的（未加入到队列）的线程优先获锁”因为队列中的第一个线程尝试获得锁时，可能刚好来了一个线程也要获取锁，而这个刚来的线程都还未加入到等待队列，此时两个线程同时随机竞争，很有可能，队列中的第一个线程竞争失败（而该线程等待的时间其实比这个刚来的线程等待时间要久）。 因为非公平锁上来就CAS开抢： 12345678910final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); //AQS,会调用下面的方法，直接开枪，可能和队列最前面那个一起竞争。 &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; 而公平锁hasQueuedPredecessors()返回false，没有排在自己前面的才能去抢： 123456789101112131415161718192021222324252627final void lock() &#123; acquire(1); &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; // 没有排在自己前面的，才能抢 compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; // 线程的等待被取消 /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; // SIGNAL后继节点即将被唤醒（表示该线程一切都准备好了,就等待锁空闲出来给我） /** waitStatus value to indicate successor's thread needs unparking */ static final int SIGNAL = -1; // 线程在等待某一个条件（Condition）被满足 /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; //下一个共享获取应该是 无条件传播（当线程处在“SHARED”模式时，该字段才会被使用上，EXCLUSIVE独占模式不会） /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; /** * Status field, taking on only the values 后继节点正在被park block，所以当前节点释放锁或者取消的时候必须要unpark唤醒后继。 为了避免竞争，获取方法必须首先表明他们需需要一个信号， 然后会尝试原子性的获取锁，如果失败才会block。 * SIGNAL: The successor of this node is (or will soon be) * blocked (via park), so the current node must * unpark its successor when it releases or * cancels. To avoid races, acquire methods must * first indicate they need a signal, * then retry the atomic acquire, and then, * on failure, block. 这个节点因为超时或者打断被取消，节点再也不会离开这个状态 特别是一个线程取消后再也不会block * CANCELLED: This node is cancelled due to timeout or interrupt. * Nodes never leave this state. In particular, * a thread with cancelled node never again blocks. 条件：这个节点正在一个条件队列中，他不会用作同步队列的节点，直到被transfer，这时候状态会被设置为0 * CONDITION: This node is currently on a condition queue. * It will not be used as a sync queue node * until transferred, at which time the status * will be set to 0. (Use of this value here has * nothing to do with the other uses of the * field, but simplifies mechanics.) 传播：一个释放锁应该被传播到其他节点，在doReleaseShared中被设置来保证连续传播，除非其他操作介入。 * PROPAGATE: A releaseShared should be propagated to other * nodes. This is set (for head node only) in * doReleaseShared to ensure propagation * continues, even if other operations have * since intervened. * 0: None of the above * waitStatus以数值型排列以简化使用，非负数代表节点不需要signal 大多数代码不想要检查特定的数值（只用判断符号） * The values are arranged numerically to simplify use. * Non-negative values mean that a node doesn't need to * signal. So, most code doesn't need to check for particular * values, just for sign. * 正常同步代码初始化为0，contidion节点的时候设置为CONDITION(-2),使用CAS修改。 * The field is initialized to 0 for normal sync nodes, and * CONDITION for condition nodes. It is modified using CAS * (or when possible, unconditional volatile writes). */ volatile int waitStatus; Node 的类注释机翻 12345678910111213141516171819202122232425&lt;p&gt;等待队列是“ CLH”（Craig，Landin和Hagersten）锁定队列的变体。 CLH锁通常用于自旋锁。相反，我们将它们用于阻塞同步器，但是使用相同的基本策略，将有关线程的某些控制信息保存在其节点的前身中。每个节点中的“状态”字段将跟踪线程是否应阻塞。节点的前任释放时会发出信号。否则，队列的每个节点都充当一个特定通知样式的监视器，其中包含一个等待线程。虽然状态字段不控制是否授予线程锁等。线程可能会尝试获取它是否在队列中的第一位。但是先行并不能保证成功。它只赋予了抗辩的权利。因此，当前发布的竞争者线程可能需要重新等待。&lt;p&gt;要加入CLH锁，您可以自动将其作为新尾部拼接。要出队，您只需设置头字段。&lt;p&gt;插入到CLH队列中，只需要对“ tail”执行一次原子操作，因此有一个从非排队到排队的简单原子分界点。同样，出队仅涉及更新“头”。但是，节点需要花费更多的精力来确定其后继者是谁，部分原因是要处理由于超时和中断而可能导致的取消。&lt;p&gt;“ prev”链接（在原始CLH锁中未使用）主要用于处理取消。如果取消某个节点，则其后继节点（通常）会重新链接到未取消的前任节点。有关自旋锁情况下类似机制的解释，请参见Scott和Scherer的论文，网址为http:&#x2F;&#x2F;www.cs.rochester.edu&#x2F;u&#x2F;scott&#x2F;synchronization&#x2F;。&lt;p&gt;我们还使用“下一个”链接来实现阻止机制。每个节点的线程ID保留在其自己的节点中，因此，前任通过遍历下一个next以确定它是哪个线程，来发信号给下一个节点唤醒。确定后继者必须避免与新排队的节点竞争以设置其前任节点的“ next”字段。----？ Determination of successor must avoid races with newly queued nodes to set the &quot;next&quot; fields of their predecessors. 在必要时，可以通过在节点的后继者似乎为空时从原子更新的“尾部”反向检查来解决此问题。 （或者换句话说，next是一种优化，因此我们通常不需要反向扫描。）&lt;p&gt;Cancellation 对基本算法引入了一些保守性。由于我们必须轮询其他节点的取消，因此我们可能会遗漏没有注意到已取消的节点在我们前面还是后面。要解决此问题，必须始终在取消时取消后继者，使他们能够稳定在新的前任者身上，除非我们能确定一个未取消的前任者将承担这一责任。 &lt;p&gt; CLH队列需要一个虚拟标头节点才能开始。但是，我们不会在构建过程中创建它们，因为如果没有争执，那将是浪费时间。取而代之的是，构造节点，并在第一次争用时设置头和尾指针。 &lt;p&gt;等待条件的线程使用相同的节点，但是使用附加的链接。条件只需要在简单（非并行）链接队列中链接节点，因为仅当它们专用时才可以访问它们。等待时，将节点插入条件队列。收到信号后，该节点将转移到主队列。状态字段的特殊值用于标记节点所在的队列。 &lt;p&gt;感谢Dave Dice，Mark Moir，Victor Luchangco，Bill Scherer和Michael Scott以及JSR-166专家组的成员，对本课程的设计提供了有益的想法，讨论和批评。 AQS锁释放的源码# AbstractQueuedSynchronizer#release() 释放锁的方法，是底层释放锁的实现。 12345678910// unlock的实现,就一行代码调用这个AQS的releasepublic final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 尝试释放锁，子类ReentrantLock实现了，如见下面（就是看独占线程ok，state-1，清除独占线程，返回free==0。） Node h = head; // 拿到head，head不为空，而且不是刚初始化 if (h != null &amp;&amp; h.waitStatus != 0) // waitStatus != 0 说明刚刚释放的过程中，又有一个新的来了，被后代把自己的waitStatus改成了SIGNAL unparkSuccessor(h); // 解除后继的阻塞 return true; &#125; return false; &#125; ReentrantLock#tryRelease(1)释放锁，不用CAS，因为线程不一样释放不了。 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; // 锁的总数-释放数量 0的话就释放完了，&gt;0的话说明有重入没释放完 if (Thread.currentThread() != getExclusiveOwnerThread()) // 解锁线程不是当前正在独占的线程就抛异常 throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; // 释放完了，清空独占线程 free = true; setExclusiveOwnerThread(null); &#125; setState(c); // 给stat设置剩余量，返回是否释放完了 return free; &#125; 解锁时唤醒后代： 1234567891011121314151617181920212223242526272829// 解锁时唤醒后代private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) // SIGNAL的，修改自己的wait状态为0 compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; // 后代为空（可能是队列从前往后唤醒到最后一个了，或者后代被取消） if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从尾巴反向往前走，如果队列是右边这种，就一直往前捋到一个正常的为止(head--cancle---cancle--...---node---tail) for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 后代不为空，解除park if (s != null) LockSupport.unpark(s.thread); &#125; 后继节点唤醒之后，又回到上面的acquireQueued()方法，去进行下一轮死循环，判断pre是不是head，是不是已经解锁了，CAS抢占锁。 抢到后：head的next置为null，GC回去干掉head。把唤起的自己这个node变成新head，清理新head里面的thread信息和head里的pre信息。 然后当前唤起节点获取到锁的线程开始继续执行后面的业务方法。。。 ReentrantReadWriteLock读写锁（共享锁）# 独享锁：也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁：是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 下面是JDK的读写分离锁代码实现： 读写分离锁,在读比较多(耗时)的场合比常规的重入锁更加有效率。 读-读线程互不阻塞,多少各线程都可以并行一起读。 但是当读-写或者写-写线程相互竞争的时候会阻塞获取锁才可以操作 ReentrantReadWriteLock内部： 持有一个int类型的status锁状态。 一个Sync同步器，同步器继承自AQS，并有公平非公平两种实现。 持有一个共享的ReadLock，一个独占的WriteLock。 可以看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 类图如下： 读写锁的status设计# AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。 在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。 但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。 于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示： 代码中搞了一个EXCLUSIVE_MASK，是2^16-1。 通过和state求&amp;可以拿到低16位的数据。 通过和state&gt;&gt;16位拿到高16位的读锁数据。 写锁的代码# 了解了概念之后我们再来看代码，先看写锁的加锁源码： 123456789101112131415161718192021222324252627282930protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero and owner is a different thread, fail. //读锁非0，写锁非0，或线程非当前，返回失败 * 2. If count would saturate, fail. (This can only happen if count is already nonzero.) // 数据超max，返回失败（max是2^16-1，因为status的int劈成两半一半给读，一半给写了） * 3. Otherwise, this thread is eligible for lock if // 其他情况则可以获取锁并设置占有线程 * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); // 获得锁的个数 int w = exclusiveCount(c); // 获取写锁的个数 if (c != 0) &#123; // 已经有线程获取锁了 // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 写锁为0，即读锁不为0. 或 非当前线程持有写锁，就返回失败 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 超过2^16-1个写线程最大数量，失败 throw new Error(\"Maximum lock count exceeded\"); // Reentrant acquire setState(c + acquires); return true; &#125; // w=0，且当前线程需要阻塞，返回失败false（非公平writerShouldBlock永远返回false不用阻塞，公平锁看队列有没有排队，有就true排队） if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 否则CAS增加写线程数量失败也返回false return false; setExclusiveOwnerThread(current); // c=0,w=0 或者 c&gt;0,w&gt;0重入，设置当前线程占有，返回true return true; &#125; 这段代码首先取到当前锁的个数c（这个数可能很大，是由高16位和低16位组合起来的），然后再通过c来获取写锁的个数w。： 因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; return c &amp; EXCLUSIVE_MASK;这个EXCLUSIVE_MASK是2^16-1，是全1 ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了任何锁（c!=0），则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有写锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。 如果本轮写后，写入锁的地位数量大于最大数（65535，2的16次方-1）就抛出一个Error。 如果当前写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；（非公平writerShouldBlock永远返回false，公平锁看队列有没有排队，有就true）如果通过CAS增加写线程数失败也返回失败。 如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！ 后面的添加队列阻塞和唤醒与ReentrantLock相同。 上面可以看到tryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。 因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。 接着是读锁的代码：# 读锁的lock()方法调用了这个 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) // 上来先去try获取共享锁一下 doAcquireShared(arg); &#125; 下面是获取一次共享锁： 123456789101112131415161718192021222324252627282930313233343536373839404142protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1. If write lock held by another thread, fail. 写锁再用，fail * 2. Otherwise, this thread is eligible for 写锁没用，就直接去看队列是否应该排队阻塞。不用的话直接CAS改读锁数量。 * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant 没有检查重入，推迟到后面的全版本doAcquireShared中 * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread 如果写锁占有，或者CAS失败，就去doAcquireShared里面轮循加锁 * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 其他线程占用写锁，返回-1 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current); &#125; 可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。 获取一次读锁失败，进入下面进入队列阻塞，循环获取： 1234567891011121314151617181920212223242526272829303132/** * Acquires in shared uninterruptible mode. * @param arg the acquire argument */ private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); // 添加节点 boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); // 前一个是头，获取一次 if (r &gt;= 0) &#123; // 成功了 setHeadAndPropagate(node, r); // 从前往后叫醒所有的节点 p.next = null; // help GC // 删掉头 if (interrupted) // 响应park时候的interrupt selfInterrupt(); failed = false; return; // 返回 &#125; &#125; // 前一个SIGNAL了才true阻塞，否则删掉前面所有CANCLE的，CAS修改pre的状态为SIGNAL，返回false再来一轮阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 阻塞 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 此时，我们再回头看一下互斥锁ReentrantLock中公平锁和非公平锁的加锁源码： 我们发现在ReentrantLock虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。 根据源码所示，当某一个线程调用lock方法获取锁时，如果同步资源没有被其他线程锁住，那么当前线程在使用CAS更新state成功后就会成功抢占该资源。 而如果公共资源被占用且不是被当前线程占用，那么就会加锁失败。所以可以确定ReentrantLock无论读操作还是写操作，添加的锁都是都是独享锁。 AQS的ConditionObject、await/signal# ConditionObject是同步器AbstractQueuedSynchronizer的内部类，因为Condition的操作需要获取相关联的锁，它实现了java.util.concurrent.locks.Condition接口。（下文的Condition都指的是ConditionObject） Condition的实现，主要包括：等待队列、等待和通知。 Condition使用了一个等待队列来记录wait的节点们（和之前的同步队列不是一个） API示例# lock.newCondition();给一个锁创建一个条件 123456789101112131415161718192021222324// 使用lock构造conditionReentrantLock lock = new ReentrantLock();Condition fullCondition = lock.newCondition();Condition emptyCondition = lock.newCondition();public T take()&#123; lock.lock(); // 先获取锁 if(queue.isEmpty())&#123; try &#123; // 通知因队列满而阻塞到fullCondition上的线程唤起 fullCondition.signalAll(); // 唤醒等待在Condition上所有的线程。 // 队列空的condition开始挂起 emptyCondition.await(); // 当前线程进入等待状态，直到被通知（signal）或者被中断时，当前线程进入运行状态，从await()返回； &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // take元素 T obj = queue.remove(); //通知因队列满而阻塞到fullCondition上的线程唤起 fullCondition.signalAll(); lock.unlock(); // 解锁 return obj; &#125; Condition的等待队列# FIFO的队列，每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程。并不复杂。 如果一个线程调用了**Condition.await()**方法，那么该线程将会： 构造节点加入等待队列（没有CAS设置尾巴，因为前面必然获取到锁了） 释放当前线程的同步状态，唤醒后继节点，且当前线程进入WATING等待状态 当从await()方法返回时，当前线程一定获取了Condition相关联的锁。 节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类AbstractQueuedSynchronizer.Node。 1234567891011121314151617181920212223public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; private transient Node firstWaiter; // 头 private transient Node lastWaiter; // 尾 // 添加waiter到队列 private Node addConditionWaiter() &#123; Node t = lastWaiter; // 整理尾巴,删掉CANCLE的 // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; // 构造一个节点，续到tail后面即可 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; await等待# 需要先lock.lock() 然后 condition.await()，await会释放掉锁，线程进入等待队列，状态变成Wating。 下次唤醒后再重新获取锁（不一定能获取到，获取不到再次for死循环获取进入同步队列，park） 123456789101112131415161718192021222324// await核心APIpublic final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 添加一个尾巴 Node node = addConditionWaiter(); // 释放当前线程节点的同步状态，唤醒后继节点； int savedState = fullyRelease(node); int interruptMode = 0; // 线程进入等待状态； while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; // 线程被【唤醒后】，从while循环中退出，继续执行后面的方法去获取锁 &#125; // 调用acquireQueued尝试获取同步状态；（ReentrantLock也使用了这个方法，就是获取一次，然后for死循环获取，或者park等待） if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; 调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。 当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。 await具体执行流程如下： 调用addConditionWaiter将当前线程加入等待队列； 调用fullRelease释放当前线程节点的同步状态，唤醒后继节点； 线程进入等待状态； 线程被唤醒后，从while循环中退出，调用acquireQueued尝试获取同步状态； 同步状态获取成功后，线程从await方法返回。 如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。（获取锁的时候，同步队列的一个header必然释放了。然后等待队列尾巴新增加了一个Node，线程是当前线程。但从内容上讲几乎相当于移动。） signal唤醒# 调用Condition的signal()方法将会唤醒再等待队列中的首节点，该节点也是到目前为止等待时间最长的节点。 1234567public final void signal() &#123; if (!isHeldExclusively()) // 当前运行线程t1是否是获取了锁的线程，如果不是抛出异常IllegalMonitorStateException throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) // 取得等待队列的头结点，头结点不为空执行doSignal doSignal(first);&#125; step1：前置检查，判断当前线程是否是获取了锁的线程，如果不是抛出异常IllegalMonitorStateException，否则，执行step2； step2：取得等待队列的头结点，头结点不为空执行doSignal，否则，signal结束。 1234567891011121314/** * Removes and transfers nodes until hit non-cancelled one or * null. Split out from signal in part to encourage compilers * to inline the case of no waiters. * @param first (non-null) the first node on condition queue */ private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; // 调用transferForSignal将节点从等待队列的first移动到同步队列.将该节点从等待队列删除。 (first = firstWaiter) != null); &#125; 整个doSignal完成了这两个操作：调用transferForSignal将节点从等待队列移动到同步队列，并且，将该节点从等待队列删除。 怎么transfer的： 1234567891011121314151617181920212223242526/** * Transfers a node from a condition queue onto sync queue. * Returns true if successful. * @param node the node * @return true if successfully transferred (else the node was * cancelled before signal) */final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) //CAS修改CONDITION return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node); // 这里和上面ReentrantLock的enq方法是一样的，初始化队列，或者加入同步队列尾巴，for死循环去续尾巴成功为止，没有park int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); // 到达这里unpark去唤醒这个节点里面的线程t2。 return true;&#125; step1：将节点waitStatus设置为0，设置成功执行step2，否则(CANCLE)返回false； step2：调用enq方法将该节点加入同步队列； step3：使用LockSuppor.unpark()方法唤醒该节点的线程。 再次回顾我们AQS的enq方法： 1234567891011121314151617181920/** * Inserts node into queue, initializing if necessary node节点进行一次入队，需要的时候进行初始化 * @param node the node to insert * @return node's predecessor */ private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 拿出尾 if (t == null) &#123; // Must initialize 没有尾，说明是第一次，需要初始化一个空的head再往后排 if (compareAndSetHead(new Node())) // head使用CAS初始化了一个虚拟的傀儡节点！这里是重点！！！！此时多线程的锁会竞争 tail = head; // 初始化首尾都是同一个，然后重新来for一次添加尾 &#125; else &#123; //第二轮以上for，初始化过，往最后排 node.prev = t; // 当前节点的前一个设置为前尾 if (compareAndSetTail(t, node)) &#123; // CAS去看前尾变化没，没变化就变更新尾，此时多线程的锁会竞争 t.next = node; // 前尾的next指向新尾，尾巴成功修改 return t; // CAS续成功才会返回，否则永远来续-----------------------唯一出口 &#125;// CAS失败，说明前尾变更，被别的线程抢先续尾了，重新来入队续尾 &#125; &#125; &#125; 整个signal系列方法将线程从等待队列移动到同步队列可以总结为下图： 就是把等待队列（wait队列）的第一个节点transfer，通过enq方法丢到同步队列的tail上，更新tail。然后再unpark这个tail里面的线程。 被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。 成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。 Condition的signalAll()方法，将等待队列中的所有节点全部唤醒，相当于将等待队列中的每一个节点都执行一次signal()。 参考# 《Java并发编程的艺术》 https://www.cnblogs.com/tuyang1129/p/12670014.html 美团技术公众号的共享锁部分","categories":[{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程","permalink":"https://blog.sofunnyai.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"BeanFactory和FactoryBean","slug":"BeanFactory和FactoryBean","date":"2018-06-19T15:32:42.000Z","updated":"2020-07-24T17:22:03.845Z","comments":true,"path":"article/BeanFactory-and-FactoryBean.html","link":"","permalink":"https://blog.sofunnyai.com/article/BeanFactory-and-FactoryBean.html","excerpt":"","text":"BeanFactory BeanFactory的子接口ListableBeanFactory 子接口ApplicationContext Spring实现DefaultListableBeanFactory FactoryBean 典型案例—mybatis的SqlSessionFactoryBean BeanFactory# 是访问spring的IOC容器核心接口，提供访问spring容器中对象的功能，给IOC容器提供了基础规范。他里面有： BeanDefinition信息，根据这些BeanDefinition，Spring可以创建这些对象。 注册中心，创建的各种Bean都注册在这里 Spring的依赖注入功能使用这个BeanFactory接口和子接口来实现。 会加载XML、注解，来配置Bean 核心方法有：各种重载的getBean、 getBeanProvider(Class)、 getType(name)、isSingleton(name)/isPrototype(name)、isTypeMatch(name, ResolvableType) 实现Bean生命周期回，全套的初始化方法以及它们的标准顺序是： BeanNameAware的setBeanName BeanClassLoaderAware的setBeanClassLoader 实现BeanFactoryAware的setBeanFactory EnvironmentAware的setEnvironment EmbeddedValueResolverAware的setEmbeddedValueResolver ResourceLoaderAware的setResourceLoader （仅适用于应用程序上下文中运行时） ApplicationEventPublisherAware的setApplicationEventPublisher （仅适用于应用程序上下文中运行时） MessageSourceAware的setMessageSource （仅适用于应用程序上下文中运行时） 了ApplicationContextAware的setApplicationContext （仅适用于应用程序上下文中运行时） ServletContextAware的setServletContext （仅适用于Web应用程序上下文中运行时） postProcessBeforeInitialization BeanPostProcessor的方法的InitializingBean的afterPropertiesSet自定义的初始化方法定义 postProcessAfterInitialization BeanPostProcessor的方法 在一个bean工厂的关闭，下列生命周期方法适用于： posProcessBeforeDestruction DestructionAwareBeanPostProcessors的方法 DisposableBean的destroy方法 BeanFactory的子接口ListableBeanFactory# 是BeanFactory的一个拓展，可以枚举所有的bean实例，所以是listable 下面是一堆可以listable的方法，一次可以拿出来一大堆bean的名称或者对象 String[] getBeanDefinitionNames(); 各种重载的String[] getBeanNamesForType(ResolvableType type); Map getBeansOfType( Class&lt;T&gt; type) Map&lt;String, Object&gt; getBeansWithAnnotation(Class&lt;? extends Annotation&gt; annotationType) 子接口ApplicationContext# ApplicationContext作为ListableBeanFactory的子接口（还有一大堆别的接口） 12public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123; 又有一大堆功能，提供了配置application的功能，还有 工厂方法来访问应用程序组件。 继承自ListableBeanFactory 。 以通用的方式的能力，加载文件资源。 继承了org.springframework.core.io.ResourceLoader接口。 发布事件注册的侦听器的能力。 继承了ApplicationEventPublisher接口。 有能力解决的消息，支持国际化。 继承了MessageSource接口。 继承自父上下文。 在子上下文定义将始终优先。 这意味着，例如，单个父上下文可以被整个web应用程序被使用，而每个servlet有其自己的子上下文无关的任何其他的servlet。 除了标准的org.springframework.beans.factory.BeanFactory生命周期的能力，ApplicationContext实现检测并调用ApplicationContextAware Bean以及ResourceLoaderAware ， ApplicationEventPublisherAware和MessageSourceAware。 Spring实现DefaultListableBeanFactory# BeanFactory，以Factory结尾，表示它是一个工厂类(接口)， 它负责生产和管理bean的一个工厂。在Spring中，BeanFactory是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。 BeanFactory只是个接口，并不是IOC容器的具体实现，但是Spring容器给出了很多种实现，如 DefaultListableBeanFactory、XmlBeanFactory、ApplicationContext等，其中****XmlBeanFactory就是常用的一个，该实现将以XML方式描述组成应用的对象及对象间的依赖关系。XmlBeanFactory类将持有此XML配置元数据，并用它来构建一个完全可配置的系统或应用。 都是附加了某种功能的实现。 它为其他具体的IOC容器提供了最基本的规范，例如DefaultListableBeanFactory,XmlBeanFactory,ApplicationContext 等具体的容器都是实现了BeanFactory，再在其基础之上附加了其他的功能。 BeanFactory和ApplicationContext就是spring框架的两个IOC容器，现在一般使用ApplicationnContext，其不但包含了BeanFactory的作用，同时还进行更多的扩展。 FactoryBean# 一般情况下，Spring通过反射机制利用&lt;bean&gt;的class属性指定实现类实例化Bean，在某些情况下，实例化Bean过程比较复杂，如果按照传统的方式，则需要在&lt;bean&gt;中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。Spring为此提供了一个org.springframework.bean.factory.FactoryBean的工厂类接口，用户可以通过实现该接口定制实例化Bean的逻辑,底层是基于FactoryBeanRegistrySupport实现的。FactoryBean接口对于Spring框架来说占用重要的地位，Spring自身就提供了70多个FactoryBean的实现。 它们隐藏了实例化一些复杂Bean的细节，给上层应用带来了便利。从Spring3.0开始，FactoryBean开始支持泛型，即接口声明改为FactoryBean&lt;T&gt;的形式。 以Bean结尾，表示它是一个Bean，不同于普通Bean的是：它是实现了FactoryBean&lt;T&gt;接口的Bean，根据该Bean的ID从BeanFactory中获取的实际上是FactoryBean的getObject()返回的对象，而不是FactoryBean本身，如果要获取FactoryBean对象，请在id前面加一个&amp;符号来获取。 例如自己实现一个FactoryBean，功能：用来代理一个对象，对该对象的所有方法做一个拦截，在调用前后都输出一行LOG，模仿ProxyFactoryBean的功能。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 代理一个类，拦截该类的所有方法，在方法的调用前后进行日志的输出 */public class MyFactoryBean implements FactoryBean&lt;Object&gt;, InitializingBean, DisposableBean &#123; private static final Logger logger = LoggerFactory.getLogger(MyFactoryBean.class); private String interfaceName; private Object target; private Object proxyObj; @Override public void destroy() throws Exception &#123; logger.debug(\"destroy......\"); &#125; @Override public void afterPropertiesSet() throws Exception &#123; proxyObj = Proxy.newProxyInstance( this.getClass().getClassLoader(), new Class[] &#123; Class.forName(interfaceName) &#125;, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; logger.debug(\"invoke method......\" + method.getName()); logger.debug(\"invoke method before......\" + System.currentTimeMillis()); Object result = method.invoke(target, args); logger.debug(\"invoke method after......\" + System.currentTimeMillis()); return result; &#125; &#125;); logger.debug(\"afterPropertiesSet......\"); &#125; @Override public Object getObject() throws Exception &#123; logger.debug(\"getObject......\"); return proxyObj; &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return proxyObj == null ? Object.class : proxyObj.getClass(); &#125; @Override public boolean isSingleton() &#123; return true; &#125; public String getInterfaceName() &#123; return interfaceName; &#125; public void setInterfaceName(String interfaceName) &#123; this.interfaceName = interfaceName; &#125; public Object getTarget() &#123; return target; &#125; public void setTarget(Object target) &#123; this.target = target; &#125; public Object getProxyObj() &#123; return proxyObj; &#125; public void setProxyObj(Object proxyObj) &#123; this.proxyObj = proxyObj; &#125;&#125; 12345678public static void testFactoryBean(ConfigurableApplicationContext context)&#123; Car car = (Car) context.getBean(Car.class); System.out.println(car.toString()); // 这里拿出来的才是CarFactoryBean System.out.println(context.getBean(\"&amp;carFactoryBean\").hashCode()); // 这里拿出来的是Car System.out.println(context.getBean(\"carFactoryBean\").getClass()); &#125; 典型案例—mybatis的SqlSessionFactoryBean# 使用来创建SqlSessionFactory对象的一个FactoryBean，如果没有他直接去创建DefaultSqlSessionFactory，里面需要依赖一个Configuration，这个里面又依赖org.apache.ibatis.mapping.Environment， Environment里面才有DataSource和TransactionFactory，这是一个很繁琐的链式依赖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612// 便捷创建SqlSessionFactory对象public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SqlSessionFactoryBean.class); private static final ResourcePatternResolver RESOURCE_PATTERN_RESOLVER = new PathMatchingResourcePatternResolver(); private static final MetadataReaderFactory METADATA_READER_FACTORY = new CachingMetadataReaderFactory(); private Resource configLocation; private Configuration configuration; private Resource[] mapperLocations; private DataSource dataSource; private TransactionFactory transactionFactory; private Properties configurationProperties; private SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); private SqlSessionFactory sqlSessionFactory; // EnvironmentAware requires spring 3.1 private String environment = SqlSessionFactoryBean.class.getSimpleName(); private boolean failFast; private Interceptor[] plugins; private TypeHandler&lt;?&gt;[] typeHandlers; private String typeHandlersPackage; @SuppressWarnings(\"rawtypes\") private Class&lt;? extends TypeHandler&gt; defaultEnumTypeHandler; private Class&lt;?&gt;[] typeAliases; private String typeAliasesPackage; private Class&lt;?&gt; typeAliasesSuperType; private LanguageDriver[] scriptingLanguageDrivers; private Class&lt;? extends LanguageDriver&gt; defaultScriptingLanguageDriver; // issue #19. No default provider. private DatabaseIdProvider databaseIdProvider; private Class&lt;? extends VFS&gt; vfs; private Cache cache; private ObjectFactory objectFactory; private ObjectWrapperFactory objectWrapperFactory; /** * 在spring的context刷新完毕的时候触发 */ @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (failFast &amp;&amp; event instanceof ContextRefreshedEvent) &#123; // fail-fast -&gt; check all statements are completed this.sqlSessionFactory.getConfiguration().getMappedStatementNames(); &#125; &#125; // 扫描包 private Set&lt;Class&lt;?&gt;&gt; scanClasses(String packagePatterns, Class&lt;?&gt; assignableType) throws IOException &#123; Set&lt;Class&lt;?&gt;&gt; classes = new HashSet&lt;&gt;(); String[] packagePatternArray = tokenizeToStringArray(packagePatterns, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS); for (String packagePattern : packagePatternArray) &#123; Resource[] resources = RESOURCE_PATTERN_RESOLVER.getResources(ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX + ClassUtils.convertClassNameToResourcePath(packagePattern) + \"/**/*.class\"); for (Resource resource : resources) &#123; try &#123; ClassMetadata classMetadata = METADATA_READER_FACTORY.getMetadataReader(resource).getClassMetadata(); Class&lt;?&gt; clazz = Resources.classForName(classMetadata.getClassName()); if (assignableType == null || assignableType.isAssignableFrom(clazz)) &#123; classes.add(clazz); &#125; &#125; catch (Throwable e) &#123; LOGGER.warn(() -&gt; \"Cannot load the '\" + resource + \"'. Cause by \" + e.toString()); &#125; &#125; &#125; return classes; &#125; /** 核心方法，创建一个SqlSessionFactory * Build a &#123;@code SqlSessionFactory&#125; instance. * * The default implementation uses the standard MyBatis &#123;@code XMLConfigBuilder&#125; API to build a * &#123;@code SqlSessionFactory&#125; instance based on a Reader. Since 1.3.0, it can be specified a &#123;@link Configuration&#125; * instance directly(without config file). * * @return SqlSessionFactory * @throws Exception * if configuration is failed */ protected SqlSessionFactory buildSqlSessionFactory() throws Exception &#123; final Configuration targetConfiguration; XMLConfigBuilder xmlConfigBuilder = null; if (this.configuration != null) &#123; targetConfiguration = this.configuration; if (targetConfiguration.getVariables() == null) &#123; targetConfiguration.setVariables(this.configurationProperties); &#125; else if (this.configurationProperties != null) &#123; targetConfiguration.getVariables().putAll(this.configurationProperties); &#125; &#125; else if (this.configLocation != null) &#123; xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties); targetConfiguration = xmlConfigBuilder.getConfiguration(); &#125; else &#123; LOGGER.debug( () -&gt; \"Property 'configuration' or 'configLocation' not specified, using default MyBatis Configuration\"); targetConfiguration = new Configuration(); Optional.ofNullable(this.configurationProperties).ifPresent(targetConfiguration::setVariables); &#125; Optional.ofNullable(this.objectFactory).ifPresent(targetConfiguration::setObjectFactory); Optional.ofNullable(this.objectWrapperFactory).ifPresent(targetConfiguration::setObjectWrapperFactory); Optional.ofNullable(this.vfs).ifPresent(targetConfiguration::setVfsImpl); if (hasLength(this.typeAliasesPackage)) &#123; scanClasses(this.typeAliasesPackage, this.typeAliasesSuperType).stream() .filter(clazz -&gt; !clazz.isAnonymousClass()).filter(clazz -&gt; !clazz.isInterface()) .filter(clazz -&gt; !clazz.isMemberClass()).forEach(targetConfiguration.getTypeAliasRegistry()::registerAlias); &#125; if (!isEmpty(this.typeAliases)) &#123; Stream.of(this.typeAliases).forEach(typeAlias -&gt; &#123; targetConfiguration.getTypeAliasRegistry().registerAlias(typeAlias); LOGGER.debug(() -&gt; \"Registered type alias: '\" + typeAlias + \"'\"); &#125;); &#125; if (!isEmpty(this.plugins)) &#123; Stream.of(this.plugins).forEach(plugin -&gt; &#123; targetConfiguration.addInterceptor(plugin); LOGGER.debug(() -&gt; \"Registered plugin: '\" + plugin + \"'\"); &#125;); &#125; if (hasLength(this.typeHandlersPackage)) &#123; scanClasses(this.typeHandlersPackage, TypeHandler.class).stream().filter(clazz -&gt; !clazz.isAnonymousClass()) .filter(clazz -&gt; !clazz.isInterface()).filter(clazz -&gt; !Modifier.isAbstract(clazz.getModifiers())) .forEach(targetConfiguration.getTypeHandlerRegistry()::register); &#125; if (!isEmpty(this.typeHandlers)) &#123; Stream.of(this.typeHandlers).forEach(typeHandler -&gt; &#123; targetConfiguration.getTypeHandlerRegistry().register(typeHandler); LOGGER.debug(() -&gt; \"Registered type handler: '\" + typeHandler + \"'\"); &#125;); &#125; targetConfiguration.setDefaultEnumTypeHandler(defaultEnumTypeHandler); if (!isEmpty(this.scriptingLanguageDrivers)) &#123; Stream.of(this.scriptingLanguageDrivers).forEach(languageDriver -&gt; &#123; targetConfiguration.getLanguageRegistry().register(languageDriver); LOGGER.debug(() -&gt; \"Registered scripting language driver: '\" + languageDriver + \"'\"); &#125;); &#125; Optional.ofNullable(this.defaultScriptingLanguageDriver) .ifPresent(targetConfiguration::setDefaultScriptingLanguage); if (this.databaseIdProvider != null) &#123;// fix #64 set databaseId before parse mapper xmls try &#123; targetConfiguration.setDatabaseId(this.databaseIdProvider.getDatabaseId(this.dataSource)); &#125; catch (SQLException e) &#123; throw new NestedIOException(\"Failed getting a databaseId\", e); &#125; &#125; Optional.ofNullable(this.cache).ifPresent(targetConfiguration::addCache); if (xmlConfigBuilder != null) &#123; try &#123; xmlConfigBuilder.parse(); LOGGER.debug(() -&gt; \"Parsed configuration file: '\" + this.configLocation + \"'\"); &#125; catch (Exception ex) &#123; throw new NestedIOException(\"Failed to parse config resource: \" + this.configLocation, ex); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; targetConfiguration.setEnvironment(new Environment(this.environment, this.transactionFactory == null ? new SpringManagedTransactionFactory() : this.transactionFactory, this.dataSource)); if (this.mapperLocations != null) &#123; if (this.mapperLocations.length == 0) &#123; LOGGER.warn(() -&gt; \"Property 'mapperLocations' was specified but matching resources are not found.\"); &#125; else &#123; for (Resource mapperLocation : this.mapperLocations) &#123; if (mapperLocation == null) &#123; continue; &#125; try &#123; XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(mapperLocation.getInputStream(), targetConfiguration, mapperLocation.toString(), targetConfiguration.getSqlFragments()); xmlMapperBuilder.parse(); &#125; catch (Exception e) &#123; throw new NestedIOException(\"Failed to parse mapping resource: '\" + mapperLocation + \"'\", e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; LOGGER.debug(() -&gt; \"Parsed mapper file: '\" + mapperLocation + \"'\"); &#125; &#125; &#125; else &#123; LOGGER.debug(() -&gt; \"Property 'mapperLocations' was not specified.\"); &#125; return this.sqlSessionFactoryBuilder.build(targetConfiguration); &#125; // 下面都是一堆设置sqlSessionFactory属性的set方法，类似与&lt;bean&gt;的各个属性 /** * Sets the ObjectFactory. * * @since 1.1.2 * @param objectFactory * a custom ObjectFactory */ public void setObjectFactory(ObjectFactory objectFactory) &#123; this.objectFactory = objectFactory; &#125; /** * Sets the ObjectWrapperFactory. * * @since 1.1.2 * @param objectWrapperFactory * a specified ObjectWrapperFactory */ public void setObjectWrapperFactory(ObjectWrapperFactory objectWrapperFactory) &#123; this.objectWrapperFactory = objectWrapperFactory; &#125; /** * Gets the DatabaseIdProvider * * @since 1.1.0 * @return a specified DatabaseIdProvider */ public DatabaseIdProvider getDatabaseIdProvider() &#123; return databaseIdProvider; &#125; /** * Sets the DatabaseIdProvider. As of version 1.2.2 this variable is not initialized by default. * * @since 1.1.0 * @param databaseIdProvider * a DatabaseIdProvider */ public void setDatabaseIdProvider(DatabaseIdProvider databaseIdProvider) &#123; this.databaseIdProvider = databaseIdProvider; &#125; /** * Gets the VFS. * * @return a specified VFS */ public Class&lt;? extends VFS&gt; getVfs() &#123; return this.vfs; &#125; /** * Sets the VFS. * * @param vfs * a VFS */ public void setVfs(Class&lt;? extends VFS&gt; vfs) &#123; this.vfs = vfs; &#125; /** * Gets the Cache. * * @return a specified Cache */ public Cache getCache() &#123; return this.cache; &#125; /** * Sets the Cache. * * @param cache * a Cache */ public void setCache(Cache cache) &#123; this.cache = cache; &#125; /** * Mybatis plugin list. * * @since 1.0.1 * * @param plugins * list of plugins * */ public void setPlugins(Interceptor... plugins) &#123; this.plugins = plugins; &#125; /** * Packages to search for type aliases. * * &lt;p&gt; * Since 2.0.1, allow to specify a wildcard such as &#123;@code com.example.*.model&#125;. * * @since 1.0.1 * * @param typeAliasesPackage * package to scan for domain objects * */ public void setTypeAliasesPackage(String typeAliasesPackage) &#123; this.typeAliasesPackage = typeAliasesPackage; &#125; /** * Super class which domain objects have to extend to have a type alias created. No effect if there is no package to * scan configured. * * @since 1.1.2 * * @param typeAliasesSuperType * super class for domain objects * */ public void setTypeAliasesSuperType(Class&lt;?&gt; typeAliasesSuperType) &#123; this.typeAliasesSuperType = typeAliasesSuperType; &#125; /** * Packages to search for type handlers. * * &lt;p&gt; * Since 2.0.1, allow to specify a wildcard such as &#123;@code com.example.*.typehandler&#125;. * * @since 1.0.1 * * @param typeHandlersPackage * package to scan for type handlers * */ public void setTypeHandlersPackage(String typeHandlersPackage) &#123; this.typeHandlersPackage = typeHandlersPackage; &#125; /** * Set type handlers. They must be annotated with &#123;@code MappedTypes&#125; and optionally with &#123;@code MappedJdbcTypes&#125; * * @since 1.0.1 * * @param typeHandlers * Type handler list */ public void setTypeHandlers(TypeHandler&lt;?&gt;... typeHandlers) &#123; this.typeHandlers = typeHandlers; &#125; /** * Set the default type handler class for enum. * * @since 2.0.5 * @param defaultEnumTypeHandler * The default type handler class for enum */ public void setDefaultEnumTypeHandler( @SuppressWarnings(\"rawtypes\") Class&lt;? extends TypeHandler&gt; defaultEnumTypeHandler) &#123; this.defaultEnumTypeHandler = defaultEnumTypeHandler; &#125; /** * List of type aliases to register. They can be annotated with &#123;@code Alias&#125; * * @since 1.0.1 * * @param typeAliases * Type aliases list */ public void setTypeAliases(Class&lt;?&gt;... typeAliases) &#123; this.typeAliases = typeAliases; &#125; /** * If true, a final check is done on Configuration to assure that all mapped statements are fully loaded and there is * no one still pending to resolve includes. Defaults to false. * * @since 1.0.1 * * @param failFast * enable failFast */ public void setFailFast(boolean failFast) &#123; this.failFast = failFast; &#125; /** * Set the location of the MyBatis &#123;@code SqlSessionFactory&#125; config file. A typical value is * \"WEB-INF/mybatis-configuration.xml\". * * @param configLocation * a location the MyBatis config file */ public void setConfigLocation(Resource configLocation) &#123; this.configLocation = configLocation; &#125; /** * Set a customized MyBatis configuration. * * @param configuration * MyBatis configuration * @since 1.3.0 */ public void setConfiguration(Configuration configuration) &#123; this.configuration = configuration; &#125; /** * Set locations of MyBatis mapper files that are going to be merged into the &#123;@code SqlSessionFactory&#125; configuration * at runtime. * * This is an alternative to specifying \"&amp;lt;sqlmapper&amp;gt;\" entries in an MyBatis config file. This property being * based on Spring's resource abstraction also allows for specifying resource patterns here: e.g. * \"classpath*:sqlmap/*-mapper.xml\". * * @param mapperLocations * location of MyBatis mapper files */ public void setMapperLocations(Resource... mapperLocations) &#123; this.mapperLocations = mapperLocations; &#125; /** * Set optional properties to be passed into the SqlSession configuration, as alternative to a * &#123;@code &amp;lt;properties&amp;gt;&#125; tag in the configuration xml file. This will be used to resolve placeholders in the * config file. * * @param sqlSessionFactoryProperties * optional properties for the SqlSessionFactory */ public void setConfigurationProperties(Properties sqlSessionFactoryProperties) &#123; this.configurationProperties = sqlSessionFactoryProperties; &#125; /** * Set the JDBC &#123;@code DataSource&#125; that this instance should manage transactions for. The &#123;@code DataSource&#125; should * match the one used by the &#123;@code SqlSessionFactory&#125;: for example, you could specify the same JNDI DataSource for * both. * * A transactional JDBC &#123;@code Connection&#125; for this &#123;@code DataSource&#125; will be provided to application code accessing * this &#123;@code DataSource&#125; directly via &#123;@code DataSourceUtils&#125; or &#123;@code DataSourceTransactionManager&#125;. * * The &#123;@code DataSource&#125; specified here should be the target &#123;@code DataSource&#125; to manage transactions for, not a * &#123;@code TransactionAwareDataSourceProxy&#125;. Only data access code may work with * &#123;@code TransactionAwareDataSourceProxy&#125;, while the transaction manager needs to work on the underlying target * &#123;@code DataSource&#125;. If there's nevertheless a &#123;@code TransactionAwareDataSourceProxy&#125; passed in, it will be * unwrapped to extract its target &#123;@code DataSource&#125;. * * @param dataSource * a JDBC &#123;@code DataSource&#125; * */ public void setDataSource(DataSource dataSource) &#123; if (dataSource instanceof TransactionAwareDataSourceProxy) &#123; // If we got a TransactionAwareDataSourceProxy, we need to perform // transactions for its underlying target DataSource, else data // access code won't see properly exposed transactions (i.e. // transactions for the target DataSource). this.dataSource = ((TransactionAwareDataSourceProxy) dataSource).getTargetDataSource(); &#125; else &#123; this.dataSource = dataSource; &#125; &#125; /** * Sets the &#123;@code SqlSessionFactoryBuilder&#125; to use when creating the &#123;@code SqlSessionFactory&#125;. * * This is mainly meant for testing so that mock SqlSessionFactory classes can be injected. By default, * &#123;@code SqlSessionFactoryBuilder&#125; creates &#123;@code DefaultSqlSessionFactory&#125; instances. * * @param sqlSessionFactoryBuilder * a SqlSessionFactoryBuilder * */ public void setSqlSessionFactoryBuilder(SqlSessionFactoryBuilder sqlSessionFactoryBuilder) &#123; this.sqlSessionFactoryBuilder = sqlSessionFactoryBuilder; &#125; /** * Set the MyBatis TransactionFactory to use. Default is &#123;@code SpringManagedTransactionFactory&#125; * * The default &#123;@code SpringManagedTransactionFactory&#125; should be appropriate for all cases: be it Spring transaction * management, EJB CMT or plain JTA. If there is no active transaction, SqlSession operations will execute SQL * statements non-transactionally. * * &lt;b&gt;It is strongly recommended to use the default &#123;@code TransactionFactory&#125;.&lt;/b&gt; If not used, any attempt at * getting an SqlSession through Spring's MyBatis framework will throw an exception if a transaction is active. * * @see SpringManagedTransactionFactory * @param transactionFactory * the MyBatis TransactionFactory */ public void setTransactionFactory(TransactionFactory transactionFactory) &#123; this.transactionFactory = transactionFactory; &#125; /** * &lt;b&gt;NOTE:&lt;/b&gt; This class &lt;em&gt;overrides&lt;/em&gt; any &#123;@code Environment&#125; you have set in the MyBatis config file. This is * used only as a placeholder name. The default value is &#123;@code SqlSessionFactoryBean.class.getSimpleName()&#125;. * * @param environment * the environment name */ public void setEnvironment(String environment) &#123; this.environment = environment; &#125; /** * Set scripting language drivers. * * @param scriptingLanguageDrivers * scripting language drivers * @since 2.0.2 */ public void setScriptingLanguageDrivers(LanguageDriver... scriptingLanguageDrivers) &#123; this.scriptingLanguageDrivers = scriptingLanguageDrivers; &#125; /** * Set a default scripting language driver class. * * @param defaultScriptingLanguageDriver * A default scripting language driver class * @since 2.0.2 */ public void setDefaultScriptingLanguageDriver(Class&lt;? extends LanguageDriver&gt; defaultScriptingLanguageDriver) &#123; this.defaultScriptingLanguageDriver = defaultScriptingLanguageDriver; &#125; /** * &#123;@inheritDoc&#125; */ @Override public void afterPropertiesSet() throws Exception &#123; notNull(dataSource, \"Property 'dataSource' is required\"); notNull(sqlSessionFactoryBuilder, \"Property 'sqlSessionFactoryBuilder' is required\"); state((configuration == null &amp;&amp; configLocation == null) || !(configuration != null &amp;&amp; configLocation != null), \"Property 'configuration' and 'configLocation' can not specified with together\"); this.sqlSessionFactory = buildSqlSessionFactory(); &#125; /** * &#123;@inheritDoc&#125; */ @Override public SqlSessionFactory getObject() throws Exception &#123; if (this.sqlSessionFactory == null) &#123; afterPropertiesSet(); &#125; return this.sqlSessionFactory; &#125; /** * &#123;@inheritDoc&#125; */ @Override public Class&lt;? extends SqlSessionFactory&gt; getObjectType() &#123; return this.sqlSessionFactory == null ? SqlSessionFactory.class : this.sqlSessionFactory.getClass(); &#125; /** * &#123;@inheritDoc&#125; */ @Override public boolean isSingleton() &#123; return true; &#125; &#125; https://www.cnblogs.com/aspirant/p/9082858.html","categories":[{"name":"xx","slug":"xx","permalink":"https://blog.sofunnyai.com/categories/xx/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"https://blog.sofunnyai.com/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"https://blog.sofunnyai.com/tags/tag2/"}]},{"title":"Spring-Aop原理","slug":"spring-aop","date":"2018-06-17T08:01:08.000Z","updated":"2020-07-28T16:21:40.578Z","comments":true,"path":"article/spring-aop.html","link":"","permalink":"https://blog.sofunnyai.com/article/spring-aop.html","excerpt":"","text":"AOP 面向切面编程 Aop是什么 aop的应用场景 概念（spring官网） Spring实现 声明一个Pointcut切入点的方式: 切入点表达式： AOP的实现 声明式事务 SpringAOP的原理 AOP 面向切面编程# Aop是什么# 与OOP对比，传统的OOP开发中的代码逻辑是自上而下的，而这些过程会产生一些横切性问题，这些横切性的问题和我们的主业务逻辑关系不大，这些横切性问题不会影响到主逻辑实现的，但是会散落到代码的各个部分，难以维护。 AOP是处理一些横切性问题，AOP的编程思想就是把这些问题和主业务逻辑分开，达到与主业务逻辑解耦的目的。使代码的重用性和开发效率更高。 AspectJ AOP是一个AOP实现，同样还有Jboos Aop、Spring AOP实现。 虽然spring本身有springAop实现，但是它的语法太复杂，所以它继承了aspectJ的语法来表现springAop。（使用了aspectJ注解而已，运行时仍然是纯Spring AOP，并且不依赖于AspectJ编译器或编织器。） springAOP是动态织入，也就是运行时织入的。AspectJ是静态织入，编译的时候就织入进去代码了。 aop的应用场景# 日志记录、权限验证、效率检查、事务管理、分布式锁、exception… 概念（spring官网）# target 目标对象，就是aop增强前的原始对象 aop Proxy 代理对象，包含了原始对象的代码和增加后的代码的增强后的对象。（类比装饰模式） Joinpoint:连接点目标对象中的方法。springAOP中最小的AOP单元是连接点，也就是方法。一系列连接点的集合称为切点PointCut。 ----------------&gt; （要关注和增强的方法，也就是我们要作用的点） pointcut:切点表示连接点的集合 -------------------&gt; （是告诉通知连接点在哪里，切点表达式决定 JoinPoint 的数量） Advice:通知，通知到哪里去，通知什么逻辑。 (位置 + logic)，一般是拦截器实现。 advice通知类型: Before 连接点执行之前，但是无法阻止连接点的正常执行，除非该段执行抛出异常 After 连接点正常执行之后，执行过程中正常执行返回退出，非异常退出 After throwing 执行抛出异常的时候 After (finally) 无论连接点是正常退出还是异常退出，都会执行 Around advice: 围绕连接点执行，例如方法调用。这是最有用的切面方式。around通知可以在方法调用之前和之后执行自定义行为。它还负责选择是继续加入点还是通过返回自己的返回值或抛出异常来快速建议的方法执行。 Aspect: 切面：切点、连接点、通知的一个载体。就是对连接点、通知的逻辑要写到哪里去的一个地方。（aspectJ实现的话是一个类，spring的话是一个xml标签）一定要给spring去管理，是一个抽象。 Weaving :把代理逻辑加入到目标对象方法上的过程叫做织入。将Aspect切面与其他Class或对象链接以创建Advice的对象的过程。 这可以在编译时（例如，使用AspectJ编译器），加载时或在运行时完成。 Spring AOP在运行时执行编织 Proceedingjoinpoint 和JoinPoint的区别: Proceedingjoinpoint 继承了JoinPoint,proceed()这个是aop代理链执行的方法。并扩充实现了proceed()方法，用于继续执行连接点。JoinPoint仅能获取相关参数，无法执行连接点。 JoinPoint的方法 java.lang.Object[] getArgs()：获取连接点方法运行时的入参列表； Signature getSignature() ：获取连接点的方法签名对象； java.lang.Object getTarget() ：获取连接点所在的目标对象； java.lang.Object getThis() ：获取代理对象本身； proceed()有重载,有个带参数的方法,可以修改目标方法的的参数 Introductions perthis 使用方式如下： @Aspect(“perthis(this(com.chenss.dao.IndexDaoImpl))”) 要求： \\1. AspectJ对象的注入类型为prototype \\2. 目标对象也必须是prototype的 原因为：只有目标对象是原型模式的，每次getBean得到的对象才是不一样的，由此针对每个对象就会产生新的切面对象，才能产生不同的切面结果。 Spring实现# 默认使用JDK动态代理实现（但是需要接口），也可以使用CGlib实现。 开启AspectJ支持，两种方式： 首先引入aspectjweaver.jar xml方式： &lt;aop:aspectj-autoproxy/&gt; 或者javaconfig方式: @Configuration @EnableAspectJAutoProxy public class AppConfig { } &lt;!--￼0--&gt; Aspect(也就是上面用@Aspect注释的类)可以有方法和字段，还可以包含切入点joinPoint、Advice通知和introduction(inter-type)声明。 Aspect本身不能被其他的Aspect进行增强 声明一个Pointcut切入点的方式:# 切入点确定了感兴趣的连接点（也就是PointCut是一系列JoinPoint的集合），从而使我们能够控制执行通知Advice的时间。 Spring AOP仅支持Spring Bean的方法执行连接点，因此可以将**PointCut视为Spring Bean上的方法执行**。 切入点声明由两部分组成：一个包含名称和任何参数的签名，以及一个切入点表达式，该切入点表达式准确确定我们感兴趣的方法执行。在AOP的@AspectJ批注样式中，常规方法定义提供了切入点签名。 并使用@Pointcut批注指示切入点表达式（用作切入点签名的方法必须具有void返回类型），一般是一个空方法。 切入点表达式：# execution: For matching method execution join points.匹配方法的表达式，最齐全，是springAOP最重要的匹配符。 下面是execution的一个完整的各部分含义，带？的是可选的，也就是可以省略的 execution(modifiers-pattern? ret-type-pattern declaring-type-pattern?name-pattern(param-pattern) throws-pattern?) 其中各项的语义如下 modifiers-pattern：方法的可见性，如public，protected；不可是*，可以省略。 ret-type-pattern：方法的返回值类型，如int，void等； declaring-type-pattern：方法所在类的全路径名，如com.spring.Aspect； name-pattern：方法名类型，如buisinessService()； param-pattern：方法的参数类型，如java.lang.String； throws-pattern：方法抛出的异常类型，如java.lang.Exception； // 案例 @Pointcut(\"execution(* com.sam.dao.*.*(..))\")//匹配com.sam.dao包下的任意接口和类的任意方法 @Pointcut(\"execution(public * com.sam.dao.*.*(..))\")//匹配com.sam.dao包下的任意接口和类的public方法 @Pointcut(\"execution(public * com.sam.dao.*.*())\")//匹配com.sam.dao包下的任意接口和类的public 无方法参数的方法 @Pointcut(\"execution(* com.sam.dao.*.*(java.lang.String, ..))\")//匹配com.sam.dao包下的任意接口和类的第一个参数为String类型的方法 @Pointcut(\"execution(* com.sam.dao.*.*(java.lang.String))\")//匹配com.sam.dao包下的任意接口和类的只有一个参数，且参数为String类型的方法 @Pointcut(\"execution(* com.sam.dao.*.*(java.lang.String))\")//匹配com.sam.dao包下的任意接口和类的只有一个参数，且参数为String类型的方法 @Pointcut(\"execution(public * *(..))\")//匹配任意的public方法 @Pointcut(\"execution(* query*(..))\")//匹配任意的以query开头的方法 @Pointcut(\"execution(* com.sam.dao.IndexDao.*(..))\")//匹配com.sam.dao.IndexDao接口中任意的方法 @Pointcut(\"execution(* com.sam.dao..*.*(..))\")//匹配com.sam.dao包及其子包中任意的方法 &lt;!--￼1--&gt; 测试introduction引入机制： 123456789System.out.println(\"================================introduction==============\");ICBCService icbcService = context.getBean(ICBCService.class);// 原生ICBCService这个类，没有任何接口，只是有一个otherMethod方法icbcService.otherMethod(\"param\");// ICBCService 没有实现UserBankService接口，但是可以强转为UserBankService，因为AOP使用了introduction为他引入了UserBankService接口的实现：UserServiceImplUserBankService icbcBankService = (UserBankService) icbcService;// 所以此处调用是UserServiceImpl的逻辑icbcBankService.addMoney(\"lisi\",300);System.out.println(\"\\n================================introduction==============\"); within: Limits matching to join points within certain types。限定于某些方法内的匹配符表达式。 @After(\"within(com.sam.bootdemo.service.impl.UserServiceImpl)\") // UserServiceImpl类的所有方法 &lt;!--￼3--&gt; args：限制参数类型，如： @Pointcut(\"args(java.lang.String)\") //匹配一个String类型的参数，也常常组合使用 &lt;!--￼4--&gt; introduction：引入，给一个Bean引入一个接口的实现。使得这个Bean可以当作另外一个接口的实现类使用。 AOP的实现# 先看一个现象： 123// spring.aop.proxy-target-class= false 时候是JDK动态代理。和UserBankServiceImpl同样接口、具有相同行为，但是不是UserBankServiceImpl，所以下面是false// spring.aop.proxy-target-class= true 时候是CGlib继承。行为和类型都相同，下面是trueSystem.out.println(bankService instanceof UserBankServiceImpl); 代理的结果默认JDK动态代理通过接口实现，不等于我们的目标对象。 声明式事务# 上面讲的只是AOP，只能在方法之前之后进行增强，无法在方法代码内部进行插入增强。需要这么做只能advisor实现。 但是advisor在@AspectJ Support中不能支持，可以使用XML进行实现。非要在Java中实现只能更换一种方式： 待续… SpringAOP的原理# 待续","categories":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/tags/java/"},{"name":"aop","slug":"aop","permalink":"https://blog.sofunnyai.com/tags/aop/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.sofunnyai.com/tags/Spring/"}]},{"title":"代理模式的一切","slug":"proxy-jdk-cglib","date":"2018-03-15T04:43:38.000Z","updated":"2020-07-19T15:27:29.786Z","comments":true,"path":"article/proxy.html","link":"","permalink":"https://blog.sofunnyai.com/article/proxy.html","excerpt":"","text":"代理模式的背景 静态代理： 动态代理 人肉朴素思想的手动代理 JDK 动态代理 JDK动态代理为什是接口不是继承？ CGlib Javassist 代理模式的背景# 假如我们有一个用户实现接口，如UserService，和实现类UserServiceImpl。现在想在UserServiceImpl的某些方法前后打印参数日志，可以选择的方式有： 静态代理：# 继承：写一个子类继承这个UserServiceImpl，然后方法前后加上日志功能。但是如果要再实现另外一个增强需求，就需要再次继承。或者对多个接口的方法同时进行增强，就要链式继承。长此以往产生类爆炸。 聚合：装饰模式。实现同一个接口UserService，装饰器的构造方法传入一个同样的类，进行包装。在包装方法里面进行前后的增强，再去调用父类。[Java的IO流使用了大量的装饰模式]。和上面的代理很像，但是装饰模式只能装饰一个特定的对象，在构造方法里面传进来，实现同样的接口进行增强。 12345678910111213141516171819/** * 装饰模式增强，实现相同接口 */public class UserServiceDeractor implements UserService &#123; UserService userService; /** * 构造方法传入同样的对象进行包装 */ public UserServiceDeractor(UserService userService)&#123; this.userService = userService; &#125; @Override public User getUser(String name) &#123; System.out.println(\"--------------装饰模式增强，传入参数\"+name); return userService.getUser(name); &#125;&#125; 缺点：实现起来简单，但是代理类会比较多，比较复杂。 动态代理# 基于以上的静态代理，会产生大量的class，如何改进？最浅显的想法就是 程序拼装这一段动态代理的java文件代码—&gt;然后生成class字节码—&gt;然后加载到项目中—&gt;创建对象并使用。 人肉朴素思想的手动代理# 基于以上思想我们试着实现一个山寨版 先来一个函数接口，用于动态封装我们的代理增强功能： 123456789101112131415161718/** * 动态代理接口 */@FunctionalInterfacepublic interface MyInvocationHandler &#123; /** * 代理增强 * @param proxy 代理类 * @param method 代理方法 * @param target 目标包装对象 * @param args 参数 * @return * @throws Exception */ public Object invoke(Object proxy, Method method,Object target, Object... args) throws Exception;&#125; 如果需要对某个对象进行增强，就写一个Handler接口的实现，然后在invoke方法中增强。 将这个invoke传入到我们下面的ProxyUtil中去创建一个代理对象： public static &lt;T&gt; T getProxy(Object target, MyInvocationHandler handler, Class&lt;T&gt; ... interfaces) throws Exception有三个参数，目标对象、增强实现（或者Lambda）、要实现的接口列表。 这个方法会把所有target的public方法进行重新生成java，每个方法里面调用handler.invoke进行增强 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152/** * 人工模拟动态代理， 不用任何第三方jar，也不用JDK */public class ProxyUtil &#123; static JavaCompiler javaCompiler = ToolProvider.getSystemJavaCompiler(); /** * 需要生成一个代理对象，必然要： * 1.先得到java代码 * 2.然后把java代码变成class * 3.然后把class变成对象 * * 我们动态实现那个装饰模式的静态代理 * @param &lt;T&gt; */ public static &lt;T&gt; T getProxy(Object target, MyInvocationHandler handler, Class&lt;T&gt; ... interfaces) throws Exception &#123; //Class clazz = target.getClass(); if(interfaces == null || interfaces.length==0)&#123; System.out.println(\"该对象没有实现接口，无法代理！\"); return null; &#125; //Class interfaceClazz = clazz.getInterfaces()[0]; System.out.println(\"即将针对接口\"+interfaces+\"进行动态代理...\"); // 拼装java类 StringBuffer java = new StringBuffer(); String proxyPackage = \"com.sam.proxy\"; java.append(\"package \"+proxyPackage+\";\\n\\n\"); // 引入接口 java.append(Arrays.stream(interfaces).map(c-&gt;\"import \"+c.getName()).collect(Collectors.joining(\";\\n\"))+\";\\n\"); java.append( \"import \"+target.getClass().getName()+\";\\n\" + \"import java.util.Arrays;\\n\" + \"import \"+MyInvocationHandler.class.getName()+\";\\n\\n\" + // import MyInvocationHandler \"// TODO 这个类是由ProxyUtil自动生成的\\n\"+ // 接口$Myproxy 此处也可以使用 \"public class MyProxyOf\"+target.getClass().getSimpleName()+\" implements \"+ Arrays.stream(interfaces).map(Class::getSimpleName).collect(Collectors.joining(\",\"))+\" &#123;\\n\" + // private 接口 target \" private \"+target.getClass().getSimpleName()+\" target;\\n\" + \" private \"+MyInvocationHandler.class.getSimpleName()+\" handler;\\n\\n\" + // 构造方法包装 \" public MyProxyOf\"+target.getClass().getSimpleName()+\"(\"+target.getClass().getSimpleName()+\" target, \"+MyInvocationHandler.class.getSimpleName()+\" h)&#123;\\n\" + \" this.target = target;\\n\" + \" this.handler = h;\\n\" + \" &#125;\\n\"); // 不用在每个方法处理，使用动态处理 for(Method method : target.getClass().getDeclaredMethods())&#123; // public com.xx.xx.User getUser(java.lang.String java.append(\"\\n\\t@Override\\n\\tpublic \"+method.getReturnType().getName()+\" \"+method.getName()+\"(\"); // String name)&#123; List&lt;String&gt; params = IntStream.range(0,method.getParameterTypes().length).mapToObj(i-&gt;method.getParameterTypes()[i].getName() +\" var\"+i).collect(Collectors.toList()); java.append(String.join(\", \",params));// java.lang.String var1, java.lang.Integer var2 java.append(\")\"); if(method.getExceptionTypes().length &gt; 0)&#123; java.append(\"thorws \"+ Arrays.stream(method.getExceptionTypes()).map(Class::getName).collect(Collectors.joining(\", \"))); &#125; java.append(\"&#123;\\n\"); // 开始调用invoke或者lambda进行代理增强！ java.append(\"\\t\\tSystem.out.println(\\\"代理对象中即将调用invoke.....\\\");\\n\"); // 调用包装类target的方法，进行增强 java.append(\"\\t\\ttry&#123;\\n\"); if(method.getParameterTypes().length == 0)&#123; java.append(\"\\t\\t\\t\"+(method.getReturnType()==void.class?\"\":(\"return (\"+method.getReturnType().getName()+\")\"))+\"handler.invoke(this, target.getClass().getMethod(\\\"\"+method.getName()+\"\\\"), target);\\n\"); &#125;else&#123; List&lt;String&gt;vars = IntStream.range(0,method.getParameterTypes().length).mapToObj(i-&gt;\"var\"+i).collect(Collectors.toList()); List&lt;String&gt;paramClazz = Arrays.stream(method.getParameterTypes()).map(c-&gt;c.getName()+\".class\").collect(Collectors.toList()); java.append(\"\\t\\t\\tClass[] paramClazz = new Class[]&#123;\"+String.join(\",\",paramClazz)+\"&#125;;\\n\"); java.append(\"\\t\\t\\t\"+(method.getReturnType()==void.class?\"\":(\"return (\"+method.getReturnType().getName()+\")\"))+\"handler.invoke(this, target.getClass().getMethod(\\\"\"+method.getName()+\"\\\", paramClazz), target, \"+String.join(\",\",vars)+\");\\n\"); &#125; java.append(\"\\t\\t&#125;catch(Exception ex)&#123;\\n\"); //method.getExceptionTypes() if(method.getExceptionTypes().length &gt; 0)&#123; java.append(\"\\t\\tList&lt;Class&gt; methodExs = Arrays.asList(\"+ String.join(\",\",Arrays.stream(method.getExceptionTypes()).map(c-&gt;c.getName()+\".class\").collect(Collectors.toList()))+\");\\n\"); java.append(\"\\t\\t\\tif(methodExs.contains(ex.getClass()))&#123;throw ex;&#125;\\n\"); &#125; java.append(\"\\t\\t\\tex.printStackTrace();\\n\"); if(method.getReturnType() != void.class)&#123; // 异常时候返回null java.append(\"\\t\\t\\treturn null;\\n\"); &#125; java.append(\"\\t\\t&#125;\\n\"); // 结束catch java.append(\"\\t&#125;\\n\");// 结束方法 &#125; java.append(\"&#125;\\n\"); //System.out.println(java); // 落盘 String filePath = System.getProperty(\"user.dir\")+\"/src/main/java/\"+proxyPackage.replaceAll(\"\\\\.\",\"/\"); String fileprefix = \"MyProxyOf\"+target.getClass().getSimpleName(); File dir = new File(filePath); if(!dir.exists())&#123; dir.mkdirs(); &#125; File javaFile = new File(filePath + \"/\" +fileprefix +\".java\"); if(javaFile.exists())&#123; javaFile.delete(); &#125; FileWriter fw = new FileWriter(javaFile); fw.write(java.toString()); fw.flush(); fw.close(); boolean result = compilerJavaFile(filePath + \"/\" + fileprefix +\".java\",System.getProperty(\"user.dir\")+\"/target/classes/\"); if(result)&#123; // 因为上一步编译到了当前工程的target中，在classpath里面，所以可以Class.forName // TODO 如果是线上编译到一个类似/tmp目录，这里需要使用URLClassloader去LoadClass加载进来才行 Class tClass = Class.forName(proxyPackage+\".MyProxyOf\"+target.getClass().getSimpleName()); // 找到装饰模式的那个构造方法，传入装饰器包装的原始对象 return (T) tClass.getConstructor(target.getClass(),MyInvocationHandler.class).newInstance(target,handler); &#125; return null; &#125; /** * 动态编译java文件到class字节码，需要把JDK/lib/tools.jar加入到环境变量中 * @param sourceFileInputPath * @param classFileOutputPath * @return */ public static boolean compilerJavaFile(String sourceFileInputPath, String classFileOutputPath) &#123; System.out.println(\"sourceFileInputPath=\"+sourceFileInputPath); System.out.println(\"classFileOutputPath=\"+classFileOutputPath); try&#123; // 设置编译选项，配置class文件输出路径 System.out.println(\"输出到:\"+classFileOutputPath); Iterable&lt;String&gt; options = Arrays.asList(\"-d\", classFileOutputPath); StandardJavaFileManager fileManager = javaCompiler.getStandardFileManager(null, null, null); Iterable&lt;? extends JavaFileObject&gt; compilationUnits = fileManager.getJavaFileObjectsFromFiles(Arrays.asList(new File(sourceFileInputPath))); boolean flag = javaCompiler.getTask(null, fileManager, null, options, null, compilationUnits).call(); if(flag)&#123; System.out.println(\"动态编译成功！\"); &#125; return flag; &#125;catch (Exception ex)&#123; ex.printStackTrace(); if(ex instanceof ClassNotFoundException)&#123; System.out.println(\"动态编译失败！\"); System.out.println(\"把JDK/lib/tools.jar加入到环境变量中\"); &#125; return false; &#125; &#125; public static void main(String[] args) throws Exception&#123; UserService instance = getProxy(new UserServiceImpl(), (proxy,method,target,params)-&gt;&#123; System.out.println(\"在lambda中的增强代理.....\");return method.invoke(target,params); &#125;, UserService.class); System.out.println(\"-----------------开始运行\"); instance.addUser(new User(\"wangwu\",20)); &#125;&#125; 生成效果： 12345678910111213141516171819202122232425262728293031323334353637383940414243// TODO 这个类是由ProxyUtil自动生成的public class MyProxyOfUserServiceImpl implements UserService &#123; private UserServiceImpl target; private MyInvocationHandler handler; public MyProxyOfUserServiceImpl(UserServiceImpl target, MyInvocationHandler h)&#123; this.target = target; this.handler = h; &#125; @Override public com.sam.bootdemo.model.User getUser(java.lang.String var0)&#123; System.out.println(\"代理对象中即将调用invoke.....\"); try&#123; Class[] paramClazz = new Class[]&#123;java.lang.String.class&#125;; return (com.sam.bootdemo.model.User)handler.invoke(this, target.getClass().getMethod(\"getUser\", paramClazz), target, var0); &#125;catch(Exception ex)&#123; ex.printStackTrace(); return null; &#125; &#125; @Override public void addUser(com.sam.bootdemo.model.User var0)&#123; System.out.println(\"代理对象中即将调用invoke.....\"); try&#123; Class[] paramClazz = new Class[]&#123;com.sam.bootdemo.model.User.class&#125;; handler.invoke(this, target.getClass().getMethod(\"addUser\", paramClazz), target, var0); &#125;catch(Exception ex)&#123; ex.printStackTrace(); &#125; &#125; @Override public void initService()&#123; System.out.println(\"代理对象中即将调用invoke.....\"); try&#123; handler.invoke(this, target.getClass().getMethod(\"initService\"), target); &#125;catch(Exception ex)&#123; ex.printStackTrace(); &#125; &#125;&#125; 可以正常运行并输出： 1234567动态编译成功！-----------------开始运行代理对象中即将调用invoke.....在lambda中的增强代理.....UserServiceImpl假装addUser：User(userName&#x3D;wangwu, age&#x3D;20)Process finished with exit code 0 JDK 动态代理# JDK动态代理使用InvocationHandler实现，和我们上面的思想很像： 123456789101112131415161718192021222324// 实现一个增强器，来拦截我们包装target的方法，进行业务增强public class UserServiceInvocationHandler implements InvocationHandler &#123; private Object target; public UserServiceInvocationHandler(Object target)&#123; this.target = target; &#125; /** * 代理方法的增强器 * 调用代理对象的业务对象的时候会来执行这个方法 * @param proxy * @param method * @param args * @return * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"-------UserServiceInvocationHandler.invoke代理增强\"); // 此处进行拦截增强 return method.invoke(target, args); // 执行target的真正业务逻辑 &#125;&#125; 测试JDK的动态代理： 123456789System.out.println(\"===================JDKProxy InvocationHandler=========================\");// jdk动态代理// 为啥要classloader？因为JVM启动的时候已经加载了project的所有class。// 但是项目运行过程中动态生成了calss，所以要传入classloader去加载这个class。// 为啥不是URLClassLoader去远程加载？因为JDK动态代理产生的项目是在classpath下的// 传入classloader、接口、和要增强的InvocationHandlerUserService service3 = (UserService) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;UserService.class&#125;, new UserServiceInvocationHandler(new UserServiceImpl()));service3.getUser(\"小马\"); 原理： Class使用来描述一个类的，看起来是废话。但是很重要，仔细体会。 Class对象如 Class userClazz = Clazz.forname(&quot;com.xxx.User&quot;)就可以拿到User类的详细信息，包括属性、方法、构造方法等等。 一个java文件---&gt;编译成class文件---&gt;解析成byte[]到JVM中---&gt;构建为类对象Class-----&gt;newInstance变成实例 判断两个对象是否相等，首先判断类加载器是否同一个，不是的话就不相等。这块动态代理判断了。传进去的接口列表使用用户的ClassLoader先加载一遍forName的结果，看看和传进来的是否相同。 默认生成的代理类在com.sun.proxy这个包名下如com.sun.proxy.$Proxy0，除非有interface不是public的，会生成到这个interface同包名下（否则无法外部implements访问到）。 12//java.lang.reflect.Proxy中获取到包名后生成class字节流的方法，使用了native方法生成byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); 结果： JDK上面那一步动态生成的类，我们反编译后看一眼： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import com.sam.bootdemo.model.User;import com.sam.bootdemo.service.UserService;import java.io.FileNotFoundException;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;import java.sql.SQLException;// 继承了JDK的Proxy，所以不能继承我们的目标对象，只能是实现接口public class UserServiceProxy extends Proxy implements UserService &#123; private static Method m1; private static Method m3; private static Method m5; private static Method m2; private static Method m4; private static Method m0; // 反射获取了我们UserService接口中需要覆盖的方法，同时反射拿到要覆盖的hashCode、equals、toString方法 static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"com.sam.bootdemo.service.UserService\").getMethod(\"initService\"); m5 = Class.forName(\"com.sam.bootdemo.service.UserService\").getMethod(\"addUser\", Class.forName(\"com.sam.bootdemo.model.User\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m4 = Class.forName(\"com.sam.bootdemo.service.UserService\").getMethod(\"getUser\", Class.forName(\"java.lang.String\")); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125; // 构造方法传入了我们写的增强类InvocationHandler，塞到父类Proxy中了 // 这个handler里面有包装我们的原始userServiceImpl对象 public UserServiceProxy(InvocationHandler var1) throws &#123; super(var1); &#125; // 因为实现了同样的UserService接口，这里代理实现 public final User getUser(String var1) throws &#123; try &#123; // 调用了invocationHandler的invoke方法，传入 代理对象、method、参数。（但是缺少真正的target，target在invocationhandler中，也就是我们要增强的userServiceImpl对象） return (User)super.h.invoke(this, m4, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; // 同上 public final void initService() throws &#123; try &#123; super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; // 同上 public final void addUser(User var1) throws FileNotFoundException, SQLException &#123; try &#123; super.h.invoke(this, m5, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | FileNotFoundException | SQLException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; // toString、equals、hashCode也调用了invocationHandler的invoke方法。 public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125;&#125; 可以发现JDK生成代理类的逻辑和我们之前手动山寨版的很像。只是JDK是调用native方法直接生成字节流数组。我们是拼装java，再动态编译为class的。 虽然是native方法，但JDK也是通过反射生成的，他反射读取了我们接口中的方法列表，逐个实现，然后生成到class流里的。 缺点： 必须要有接口，才能生成动态代理。如果对象没有接口就无法进行代理。 JDK动态代理为什是接口不是继承？# 因为Java是单继承的，JDK底层源码已经继承了proxy对象， 里面存放了invocationHandler（invocationHandler里面包装了我们的目标对象）。所以不能再继承我们的目标对象。 只能去和目标对象实现相同的接口，包装一下，具有相同行为。 CGlib# 使用基于继承的方式，使用ASM进行字节码操作完成代理增强。都是直接操作字节码和JDK比起来性能差异不大。 Javassist# 也可以实现字节码增强的代理，使用不太多。","categories":[{"name":"spring","slug":"spring","permalink":"https://blog.sofunnyai.com/categories/spring/"}],"tags":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.sofunnyai.com/tags/spring/"}]},{"title":"CacheLine和伪共享","slug":"cacheline","date":"2018-03-11T01:44:53.000Z","updated":"2020-06-15T03:12:53.309Z","comments":true,"path":"article/cacheline-contended.html","link":"","permalink":"https://blog.sofunnyai.com/article/cacheline-contended.html","excerpt":"","text":"CacheLine简介 为什么CacheLine并发慢？ MESI缓存一致性协议 FalseSharing伪共享问题 伪共享的解决方案 原始有缓存行竞争的问题 JDK8以前人肉解决： JDK8以后@Contended解决： 确认内存布局 效果测试 测试原始问题、人肉优化、@Contended优化。 CacheLine简介# CPU缓存系统中是以缓存行（cache line）为单位存储的。缓存行是2的整数幂个连续字节，目前主流的CPU Cache的Cache Line大小都是64Bytes（和操作系统、CPU有关）。**当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。**缓存行上的写竞争是运行在SMP系统中并行线程实现可伸缩性最重要的限制因素。 由于共享变量在CPU缓存中的存储是以缓存行为单位，一个缓存行可以存储多个变量（存满当前缓存行的字节数）；而CPU对缓存的修改又是以缓存行为最小单位的，如果多线程同时修改同一缓存行上的两个变量，那么就会出现上诉的伪共享问题。 伪共享是无声的性能杀手，因为从代码中很难看清楚是否会出现伪共享。对于多线程编程来说，特别是多线程处理列表和数组的时候，要非常注意伪共享的问题。否则不仅无法发挥多线程的优势，还可能比单线程性能还差。 为什么CacheLine并发慢？# 下面的图中，X和Y在同一缓存行中，读取的时候只能一起从“内存–L3–L2–L1–寄存器”去加载。使用的时候反着从“寄存器-L1-L2-L3-主存”去拿，走得越远越慢。 所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中。另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据。 但是当core1修改X的时候，把这个CacheLine读取进来修改完毕，根据MESI缓存一致性协议，缓存行会失效。需要从下级Cache或者其他核心的Cache，甚至主存重新load。 MESI缓存一致性协议# 是多种一致性协议中的一种实现，规定缓存在同一时间只有一种状态： 在MESI协议中，每个Cache line有4个状态，可用2个bit表示，它们分别是： M(Modified)：这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中； E(Exclusive)：这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中； S(Shared)：这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中； I(Invalid)：这行数据无效。 那么，假设有一个变量i=3（应该是包括变量i的缓存块，块大小为缓存行大小）； 已经加载到多核（a,b,c）的缓存中，此时该缓存行的状态为S(Share共享有效)； 此时其中的一个核a改变了变量i的值，那么在核a中的当前缓存行的状态将变为M（有效但修改了，和内存不一致），b,c核中的当前缓存行状态将变为I（无效）。如下图： FalseSharing伪共享问题# 在上面的情况下a核心修改后缓存状态变为M，b和c核心的缓存变为I无效，去重新load（从其他核心的缓存中同步，或者从主存同步，看CPU实现了）。 此时在核b上运行的线程，正好想要修改变量Y，那么就会出现相互竞争，相互失效的情况，这就是伪共享啦。 伪共享的解决方案# 下面使用一个带有long类型的简单对象来测试（使用一个long数组测试也行，略不直观） 原始有缓存行竞争的问题# 如下，假设一个数组有多个Obj1对象。我们多线程需要对不同位置的Obj1的x进行并发赋值，在修改的时候会因为一次load了多个Obj1到内存中，就会产生缓存行互相失效的竞争问题。这就是原始的伪共享问题。 123456789// 抽象一个父类，为了完成缓存行通用测试，无意义。abstract class Obj&#123; long x;&#125;// 普通未进行缓存行优化的对象class Obj1 extends Obj&#123; long x; // 假设一个数组有多个Obj1对象，我们多线程需要对不同位置的Obj1的x进行赋值，在修改的时候会因为一次load了多个Obj1到内存中，就会产生缓存行竞争&#125; JDK8以前人肉解决：# 前后各加8个long（64位）来规避缓存行竞争，在诸如Disruptor等追求极致性能的地方会见到这种代码： 12345678910// 缓存行优化对象class Obj2 extends Obj&#123; long p1,p2,p3,p4,p5,p6,p7; /** * 因为对象前7个long+x是64个字节，正好一个缓存行。后面也是。 * 所以多线程写的时候，两个线程永远不在一个缓存行中，效率更高。 */ long x; long p8,p9,p10,p11,p12,p13,p14;&#125; JDK8以后@Contended解决：# 使用@Contended注解自动进行缓存行填充，防止多线程竞争缓存行。JVM会给我们前后各加128bit的padding，保证规避了缓存行竞争。 12345678/** * 使用@Contended注解自动进行缓存行填充，防止多线程竞争缓存行 * 执行时，必须加上虚拟机参数-XX:-RestrictContended，@Contended注释才会生效。 */@Contendedclass Obj3 extends Obj&#123; long x;&#125; 确认内存布局# 我们的两种优化是不是真的有效呢？JOL看一下这三个对象的内存布局： 123456Obj1 obj1 = new Obj1();Obj2 obj2 = new Obj2();Obj3 obj3 = new Obj3();System.out.println(ClassLayout.parseInstance(obj1).toPrintable());System.out.println(ClassLayout.parseInstance(obj2).toPrintable());System.out.println(ClassLayout.parseInstance(obj3).toPrintable()); 可以看到： 没加缓存行优化的Obj1：我们的核心属性，前后没有缓存行对齐，直接多线程修改它是有伪共享问题的（两个Obj1的x在同一个缓存行中） 使用人肉8个long进行缓存行优化的Obj2：我们的核心属性，前后都有64位的填充，多线程竞争也不会使得两个Obj2对象的x在同一个缓存行中 使用JDK自带@Contended修饰的Obj3：前后各有一个长达128字节的填充，多线程竞争也不会使得两个Obj2对象的x在同一个缓存行中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 没加缓存行优化的简单extends的Obj1：com.xxxx.Obj1 object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 81 c1 00 f8 (10000001 11000001 00000000 11111000) (-134168191) 12 4 (alignment/padding gap) 16 8 long Obj.x 0 24 8 long Obj1.x 0 # 我们的核心属性，前后没有缓存行对齐，直接多线程修改它是有伪共享问题的（两个Obj1的x在同一个缓存行中）Instance size: 32 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total# 人肉使用了一堆long进行占位com.xxxx.Obj2 object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) bf c1 00 f8 (10111111 11000001 00000000 11111000) (-134168129) 12 4 (alignment/padding gap) 16 8 long Obj.x 0 # 这个是继承的，不用管 24 8 long Obj2.p1 0 32 8 long Obj2.p2 0 40 8 long Obj2.p3 0 48 8 long Obj2.p4 0 56 8 long Obj2.p5 0 64 8 long Obj2.p6 0 72 8 long Obj2.p7 0 80 8 long Obj2.x 0 # 我们的核心属性，前后都有64位的填充，多线程竞争也不会使得两个Obj2对象的x在同一个缓存行中 88 8 long Obj2.p8 0 96 8 long Obj2.p9 0 104 8 long Obj2.p10 0 112 8 long Obj2.p11 0 120 8 long Obj2.p12 0 128 8 long Obj2.p13 0 136 8 long Obj2.p14 0Instance size: 144 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total# 使用JDK的@Contended修饰的classcom.xxxx.Obj3 object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 05 c2 00 f8 (00000101 11000010 00000000 11111000) (-134168059) 12 4 (alignment/padding gap) 16 8 long Obj.x 0 24 128 (alignment/padding gap) # 前面有一个长达128字节的填充 152 8 long Obj3.x 0 # 我们的核心对象 160 128 (loss due to the next object alignment) # 后面也有一个长达128的填充Instance size: 288 bytesSpace losses: 132 bytes internal + 128 bytes external = 260 bytes total 效果测试# 下面是工具方法： 1234567891011121314151617181920212223242526272829/** * 测试缓存行工具方法 */ private static void testCacheLine(Obj[] arr) throws InterruptedException &#123; StopWatch watch = new StopWatch(); watch.start(); // 一亿次 long times = 1_0000_0000l; CountDownLatch latch = new CountDownLatch(2); // 启动2个线程，对数组的两个位置进行竞争修改 new Thread(()-&gt;&#123; for (Long i = 0l; i &lt; times; i++) &#123; arr[0].x = i; &#125; latch.countDown(); &#125;).start(); new Thread(()-&gt;&#123; for (Long i = 0l; i &lt; times; i++) &#123; arr[1].x = i; &#125; latch.countDown(); &#125;).start(); // 等待两个线程都执行完毕，计时 latch.await(); watch.stop(); System.out.println(watch.getTime()); &#125; 测试原始问题、人肉优化、@Contended优化。# 注意@Contended需要运行的时候加上-XX:-RestrictContended参数才生效 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static void main(String[] args) &#123; try &#123; /** * 结果很慢，因为对象里只有一个long是8个字节，缓存行64个字节。 * 多个线程并发写的时候，必然需要进行缓存行同步。 */ Obj [] arr1 = new Obj1[2]; arr1[0] = new Obj1(); arr1[1] = new Obj1(); // 缓存行伪共享测试 testCacheLine(arr1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; /** * 快，因为对象前7个long+x是64个字节，正好一个缓存行。后面也是。 * 所以多线程写的时候，两个线程永远不在一个缓存行中，效率更高。 */ Obj [] arr2 = new Obj2[2]; arr2[0] = new Obj2(); arr2[1] = new Obj2(); // 缓存行伪共享优化测试 testCacheLine(arr2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; /** * 快，因为@Contended会自动填充，正好一个缓存行。后面也是。 * 所以多线程写的时候，两个线程永远不在一个缓存行中，效率更高。 * @Contended 需要加上-XX:-RestrictContended才生效 */ Obj [] arr3 = new Obj3[2]; arr3[0] = new Obj3(); arr3[1] = new Obj3(); testCacheLine(arr3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 多次运行可以发现未优化的速度明显慢于后两者优化后的： 后两者优化后的差异不大，通常都很接近。 1231802674874","categories":[{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"spring源码浅析","slug":"spring","date":"2018-03-07T16:24:39.000Z","updated":"2020-07-24T18:05:54.204Z","comments":true,"path":"article/spring-start.html","link":"","permalink":"https://blog.sofunnyai.com/article/spring-start.html","excerpt":"","text":"Spring BeanDefinition IOC 一些细节 xml细节 注解细节 其他细节 启动过程 spring解决循环依赖方案 SpringFramework的拓展点 通过 BeanPostProcesso定制化Bean 通过拓展BeanFactoryPostProcessor自定义配置信息 BeanFactory和FactoryBean 自定义初始化器initializer拓展 自定义监听器listener拓展 Spring# 虽然编码多年，我们再来重新认识Spring这个老朋友： spring有一大堆项目，核心的spring framework，以及发展而来的springboot、springcloud，工具类的spring-data、spring-security等 spring framework通常的误区大家说他有IOC和AOP，然而并不是。 他的核心至少有： IoC Container, Events, Resources, i18n, Validation, Data Binding, Type Conversion, SpEL, AOP. 常用附加的还有：Transactions、JDBC、Spring MVC, WebSocket、JMS 以及新兴的：Spring WebFlux BeanDefinition# 用来描述我们的Bean的信息，Bean不是普通的对象。不像Java使用一个XXX.getClass()就能描述这个对象（包括接口、字段、方法等）。Bean的信息更多（是否Singleton、是否是Spring特有的、DependsOn、Lazy） IOC# 控制反转（Inversion of Control，缩写为IoC），是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（Dependency Injection，简称DI），还有一种方式叫“依赖查找”（Dependency Lookup） 我们使用DI完成IOC看起来编码似乎复杂度增加，有啥优势呢： 我们推荐面向抽象编程，这样可以更灵活。而面向抽象编程会产生类的依赖（具体使用哪个实现的问题） 基于抽象编程除了更灵活外，接触耦合可以给我们带来更强大的增强和拓展（如AOP增强）。最经典的基于代理的事务管理就可以实现。 spring给我们提供一种机制来管理我们的依赖关系，就是IOC容器。 一些细节# xml和annotation是可以混用的。如果在XMLApplicationContext中默认是没有开启注解的，此时想要使用annotation-based还是需要一个xml，在里面配置&lt;context:component-scan base-package=&quot;com.xxx&quot;&gt; 。这一行会开启注解+自动扫描两个功能。 JavaConfig使用AnnotationConfigApplicationContext就不需要再次开启，默认是开启的。 xml细节# 可以schema-based的XML方式管理 ，annotaion-based注解方式管理，java-based使用javabean管理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:c=\"http://www.springframework.org/schema/c\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--spring的p、c、contecxt等标签的xsd在jar包里，所以不用写远程xsd地址也会自动提示--/&gt; &lt;!-- https://blog.csdn.net/fox_bert/article/details/80793030 --&gt; &lt;!-- 这一行就可以开启注解自动扫描，此时就是注解+xml混用 --&gt; &lt;context:component-scan base-package=\"com.sam.bean\"/&gt; &lt;bean id=\"school\" class=\"com.sam.bean.School\"&gt; &lt;property name=\"schoolName\" value=\"xxx小学\"&gt;&lt;/property&gt; &lt;property name=\"student\" ref=\"zhangsan\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--可以使用p属性完成属性注入--&gt; &lt;bean id=\"zhangsan\" class=\"com.sam.bean.Student\" p:age=\"5\"&gt; &lt;property name=\"name\" value=\"张三\"&gt;&lt;/property&gt;&lt;!-- &lt;property name=\"age\" value=\"5\"&gt;&lt;/property&gt;--&gt; &lt;property name=\"dad\" ref=\"laozhang\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"laozhang\" class=\"com.sam.bean.Person\"&gt; &lt;property name=\"name\" value=\"老张\"/&gt; &lt;property name=\"company\" ref=\"school\"/&gt; &lt;property name=\"job\" value=\"teacher\"/&gt; &lt;/bean&gt; &lt;!-- 构造器的循环依赖，无法解决 --&gt; &lt;!--构造器也可以用c属性实现--&gt;&lt;!-- &lt;bean id=\"school\" class=\"com.sam.bean.School\" c:schoolName=\"xxx小学\" c:student-ref=\"zhangsan\"/&gt;--&gt;&lt;!-- &lt;bean id=\"school\" class=\"com.sam.bean.School\"&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"schoolName\" value=\"xxx小学\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"student\" ref=\"zhangsan\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;/bean&gt;--&gt;&lt;!-- &lt;bean id=\"zhangsan\" class=\"com.sam.bean.Student\"&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"age\" value=\"5\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"name\" value=\"张三\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"dad\" ref=\"laozhang\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;/bean&gt;--&gt;&lt;!-- &lt;bean id=\"laozhang\" class=\"com.sam.bean.Person\"&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"company\" ref=\"school\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"name\" value=\"老张\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;constructor-arg name=\"job\" value=\"teacher\"&gt;&lt;/constructor-arg&gt;--&gt;&lt;!-- &lt;/bean&gt;--&gt;&lt;/beans&gt; 注解细节# @Autowired默认使用byType进行配置，重复的话去byName，多个实现的Class驼峰和属性name不一样就不知道哪个会报错。此时可以用@Primary指定优先一个。或者用@Qualifier (&quot;xxxImpl&quot;)去配合使用 @Resource默认使用byName进行配置。 当一个单例对象引用另一个多例对象的时候，直接@Autowaired或者@Resource会有问题，被引用的多例对象只会创建一次，变成一个单例对象。此时解决方案： 给单例对象实现ApplicationContextAware注入context，每次去context里面getBean就会拿到多例对象，但是侵入性太高。 用Lookup Method Injection方法注入：@Lookup注解放到一个抽象方法上去获取bean，那么spring会直接每次给你一个新的（必然是代理模式实现的） 1234567891011121314// 一个单例对象@Servicepublic abstract class CommandManager &#123; public Object process(Object commandState) &#123; MyCommand command = createCommand(); command.setState(commandState); return command.execute(); &#125; // 引用一个多例对象 @Lookup protected abstract MyCommand createCommand();&#125; 其他细节# profile当前生效的配置环境，可以自己起名字，默认是default-profile。可以在@Configuration（或者在单独一个Class，但是很少用）的类名上写上@Profile(&quot;test&quot;),那么就只有测试环境test的时候才会生效。 profile怎么获取到的呢？他是放在environment里面的，可以从applicatoincontext.xml加载，或者java里面设置context.getEnvirionment().setActiveprofiles(&quot;test&quot;),但是java设置之后要使用context.resresh()才能生效。 启动过程# BeanDefinitionRegistryPostProcessor是BeanFactoryPostProcessor的子接口 注解启动的ConfigurationClassPostProcessor就是典型实现。 spring解决循环依赖方案# 首先有两种循环依赖（一般都是说单例的问题），constructor的循环依赖问题无法解决。setter的循环依赖可以解决。 注册到DefaultSingletonBeanRegistry的对象有三级缓存，getSingleton获取的时候可以提前暴露暂时还没setter完的对象。 这个DefaultSingletonBeanRegistry是默认Bean工厂DefaultListableBeanFactory的父类。所以beanFactory也是注册中心： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; // 一级缓存，放单例对象 /** Cache of singleton objects: bean name to bean instance. */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); // 三级缓存，从factory获取对象 /** Cache of singleton factories: bean name to ObjectFactory. */ private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16); // 二级缓存，刚创建好还没setter的对象 /** Cache of early singleton objects: bean name to bean instance. */ private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); // 已经注册好的bean的名字 /** Set of registered singletons, containing the bean names in registration order. */ private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;&gt;(256); // 正在创建的bean的名字 /** Names of beans that are currently in creation. */ private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); /** Names of beans currently excluded from in creation checks. */ private final Set&lt;String&gt; inCreationCheckExclusions = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16)); /** List of suppressed Exceptions, available for associating related causes. */ @Nullable private Set&lt;Exception&gt; suppressedExceptions; /** Flag that indicates whether we're currently within destroySingletons. */ private boolean singletonsCurrentlyInDestruction = false; /** Disposable bean instances: bean name to disposable instance. */ private final Map&lt;String, Object&gt; disposableBeans = new LinkedHashMap&lt;&gt;(); /** Map between containing bean names: bean name to Set of bean names that the bean contains. */ private final Map&lt;String, Set&lt;String&gt;&gt; containedBeanMap = new ConcurrentHashMap&lt;&gt;(16); /** Map between dependent bean names: bean name to Set of dependent bean names. */ private final Map&lt;String, Set&lt;String&gt;&gt; dependentBeanMap = new ConcurrentHashMap&lt;&gt;(64); /** Map between depending bean names: bean name to Set of bean names for the bean's dependencies. */ private final Map&lt;String, Set&lt;String&gt;&gt; dependenciesForBeanMap = new ConcurrentHashMap&lt;&gt;(64); // 创建对象的时候要分别往三个缓存作用域合适的里面put // 解决setter循环依赖的核心代码，使用了三级缓存 /** * Return the (raw) singleton object registered under the given name. * &lt;p&gt;Checks already instantiated singletons and also allows for an early 允许提前暴露，来解决循环依赖的问题 * reference to a currently created singleton (resolving a circular reference). * @param beanName the name of the bean to look for * @param allowEarlyReference whether early references should be created or not * @return the registered singleton object, or &#123;@code null&#125; if none found */ @Nullable protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); // 一级缓存 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); // 二级缓存 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); // 三级缓存，把bean对象提前暴露出出来了 if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject; &#125; /** * Return the (raw) singleton object registered under the given name, * creating and registering a new one if none registered yet. * @param beanName the name of the bean * @param singletonFactory the ObjectFactory to lazily create the singleton * with, if necessary * @return the registered singleton object */ public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, \"Bean name must not be null\"); synchronized (this.singletonObjects) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; if (this.singletonsCurrentlyInDestruction) &#123; throw new BeanCreationNotAllowedException(beanName, \"Singleton bean creation not allowed while singletons of this factory are in destruction \" + \"(Do not request a bean from a BeanFactory in a destroy method implementation!)\"); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Creating shared instance of singleton bean '\" + beanName + \"'\"); &#125; beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) &#123; this.suppressedExceptions = new LinkedHashSet&lt;&gt;(); &#125; try &#123; singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch (IllegalStateException ex) &#123; // Has the singleton object implicitly appeared in the meantime -&gt; // if yes, proceed with it since the exception indicates that state. singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; throw ex; &#125; &#125; catch (BeanCreationException ex) &#123; if (recordSuppressedExceptions) &#123; for (Exception suppressedException : this.suppressedExceptions) &#123; ex.addRelatedCause(suppressedException); &#125; &#125; throw ex; &#125; finally &#123; if (recordSuppressedExceptions) &#123; this.suppressedExceptions = null; &#125; afterSingletonCreation(beanName); &#125; if (newSingleton) &#123; addSingleton(beanName, singletonObject); &#125; &#125; return singletonObject; &#125; &#125; @Override public void registerSingleton(String beanName, Object singletonObject) throws IllegalStateException &#123; Assert.notNull(beanName, \"Bean name must not be null\"); Assert.notNull(singletonObject, \"Singleton object must not be null\"); synchronized (this.singletonObjects) &#123; Object oldObject = this.singletonObjects.get(beanName); if (oldObject != null) &#123; throw new IllegalStateException(\"Could not register object [\" + singletonObject + \"] under bean name '\" + beanName + \"': there is already object [\" + oldObject + \"] bound\"); &#125; addSingleton(beanName, singletonObject); &#125; &#125; /** * Add the given singleton object to the singleton cache of this factory. * &lt;p&gt;To be called for eager registration of singletons. * @param beanName the name of the bean * @param singletonObject the singleton object */ protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, singletonObject); // 注册到一级缓存singletonObjects中 this.singletonFactories.remove(beanName); // 同时从二级、三级缓存删除这个bean this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); // 把bean的名字注册到set中去 &#125; &#125; /** * Add the given singleton factory for building the specified singleton * if necessary. * &lt;p&gt;To be called for eager registration of singletons, e.g. to be able to * resolve circular references. * @param beanName the name of the bean * @param singletonFactory the factory for the singleton object */ protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, \"Singleton factory must not be null\"); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; &#125;&#125; SpringFramework的拓展点# 官网关于拓展点的链接： https://docs.spring.io/spring/docs/5.2.7.RELEASE/spring-framework-reference/core.html#beans-factory-extension 先说结论：一般来说开发者无需自己去实现一个ApplicationContext进行拓展（虽然在诸如refresh方法中预留了拓展类），而是选用实现spring的插件式接口进行拓展。 通过 BeanPostProcesso定制化Bean# 如果要更改实际的bean实例（即从配置元数据创建的对象），则需要使用BeanPostProcessor进行拓展。可以插手Bean创建的过程，可以是多个BPP链式执行，可以减轻BF的负担。 如AOP就是Bean实例化的期间通过BPP织入切面逻辑到代理对象的。 what：BeanPostProcessor接口定义回调方法，可以实现这些回调方法来提供您自己的(或覆盖容器的缺省)实例化逻辑、依赖项解析逻辑等。 如果希望在Spring容器完成实例化、配置和初始化bean之后实现一些自定义逻辑，可以插入一个或多个自定义BeanPostProcessor实现。 后处理器可以对bean实例执行任何操作，如回调接口、包装Bean。比如 一些Spring AOP基础结构类被实现为bean后处理器，以提供代理包装逻辑。 **when：**当类被注册为BeanPostProcessor时，对于容器创建的每个bean实例，后处理器都会在容器初始化方法（如InitializingBean.afterPropertiesSet（）或 任何声明的init方法），并在任何bean初始化回调之后被调用。 how： 自动检测。ApplicationContext自动检测实现BeanPostProcessor接口的所有bean。 ApplicationContext将这些bean注册BFPP，以便以后在bean创建时可以调用它们。 **other：**可以配置多个BeanPostProcessor实例，通过设置order属性并实现Ordered接口来控制这些BeanPostProcessor实例的执行顺序。 1234567891011121314151617package scripting;import org.springframework.beans.factory.config.BeanPostProcessor;public class InstantiationTracingBeanPostProcessor implements BeanPostProcessor &#123; // 在bean的init方法之前执行（constructor-----此方法-----init方法） // simply return the instantiated bean as-is public Object postProcessBeforeInitialization(Object bean, String beanName) &#123; return bean; // we could potentially return any object reference here... &#125; //constructor-----上面方法-----init方法-----此方法 public Object postProcessAfterInitialization(Object bean, String beanName) &#123; System.out.println(\"Bean '\" + beanName + \"' created : \" + bean.toString()); return bean; &#125;&#125; 通过拓展BeanFactoryPostProcessor自定义配置信息# what：BeanFactoryPostProcessor对Bean配置**元数据（METADATA）**进行操作。 也就是说，Spring IoC容器允许BeanFactoryPostProcessor读取配置元数据，并有可能在容器实例化除BeanFactoryPostProcessor实例以外的任何bean之前更改它。（官网原文，说的很严谨）。同样可以使用Orderd进行排序。 wheh：BeanFactoryPostProcessor在ApplicationContext中声明后会自动执行，以便将更改应用于定义容器的配置元数据。 Spring包含许多预定义的BFPP，例如PropertyOverrideConfigurer和PropertySourcesPlaceholderConfigurer。 我们也可以使用自定义BeanFactoryPostProcessor，例如注册自定义属性编辑器 **how：**自动检测，ApplicationContext自动检测实现BeanFactoryPostProcessor接口的Bean。它在适当的时候将这些bean用作BFPP。 BeanFactory和FactoryBean# FactoryBean是一个 12345678910111213141516171819202122232425262728293031323334/** * 一个FactoryBean有三个接口 * getObject()、getObjectType()、isSingleton() */@Data@Component// 此处注册之后，会注册两个对象：// 1.CarFactoryBean本身在BeanFactory中就是一个&amp;carFactoryBean对象，// 2.Car在BeanFactory中是carFactoryBean对象@Slf4jpublic class CarFactoryBean implements FactoryBean&lt;Car&gt; &#123; private String carProperties = \"audiA6,300000\"; // 返回的对象是 @Override public Car getObject() throws Exception &#123; // 这里是FactoryBean创建对象和核心逻辑 String[] properties = carProperties.split(\",\"); log.info(\"即将调用CarFactoryBean#getObject创建一个car...........\"); return new Car(properties[0],Double.parseDouble(properties[1])); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Car.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125;&#125; beanFactory.getBeanNamesForType(Car.class)===carFactoryBean beanFactory.getBeanNamesForType(CarFactoryBean.class)===&amp;carFactoryBean 自定义初始化器initializer拓展# 首先实现ApplicationContextInitializer接口，会有一个initialize(context)方法需要重写。会在resresh()之前进行调用，如：ContextIdApplicationContextInitializer给context设置ID。下面自己实现了一个毫无意义的初始化器： 1234567public class MyApplicationContextInitializer implements ApplicationContextInitializer &lt;ConfigurableApplicationContext&gt;&#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println(\"即将调用refresh---------------applicationContext.getBeanDefinitionNames()=\\n\"); Arrays.stream(applicationContext.getBeanDefinitionNames()).forEach(System.out::println); &#125;&#125; 注册到容器有两种方式： 系统级： 建立META-INF/spring.factories，然后注册，如： # 增加一个自定义初始化器，在new SpringApplication的时候load创建，refresh之前会被调用 org.springframework.context.ApplicationContextInitializer=com.sam.bootdemo.extend.MyApplicationContextInitializer 123456789101112 这种方式将会在系统启动的时候使用&#96;getSpringFactoriesInstances(ApplicationContextInitializer.class)&#96;方式加载到，然后注册到context中去统一执行。- 委派级： - 不用创建spring.factories。直接注册到context和系统级的initlitializeri并列，而是委派给另一个&#96;DelegatingApplicationContextInitializer&#96;调用。如： - 在spring的yaml或者propertiers中添加如下的属性（多个逗号分割）： - &#96;&#96;&#96;properties # 将会被&#96;DelegatingApplicationContextInitializer&#96;解析并反射创建后以一个成员变量list存在。当DelegatingApplicationContextInitializer执行初始化方法的时候，会把这些自定义的初始化器进行排序、然后逐个调用。 context.initializer.classes&#x3D;com.sam.bootdemo.extend.MyApplicationContextInitializer 自定义监听器listener拓展# 实现ApplicationListener接口，有一个onApplicationEvent(ApplicationEvent event)方法需要重写。 1234567891011public class MyApplicationListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; @Override public void onApplicationEvent(ApplicationEvent event) &#123; System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;MyApplicationListener监听到一个事件：event source == \"+event.getSource()); // 可以根据事件类型判断是否处理 if (event instanceof ApplicationPreparedEvent) &#123; //XXXX xxx = ((ApplicationStartedEvent)event).getApplicationContext().getBean(XXXX.class); // 做一些操作，如启动一个调度线程池等等 &#125; &#125;&#125; 有一个顶级派发监听器接口叫做SpringApplicationRunListener，他里面有一个实现：EventPublishingRunListener 系统级的EventPublishingRunListener监听器有多拨器SimpleApplicationEventMulticaster 多拨器里面有我们的所有ApplicationListener列表，可以根据supportsEvent方法判断哪些listener支持这个事件，并在doInvokeListener中调用 所有的系统级监听器里面有一个很特殊的DelegatingApplicationListener，和上面的初始化器很像，也是可以委派分发事件。 流程： 容器发生对应的业务场景时调用ApplicationRunListener#starting/environmentPrepared/contextPrepared/contextLoaded/started/running/failed ApplicationRunListener回去调用多拨器向listener分发事件，如ApplicationStartingEvent、ApplicationEnvironmentPreparedEvent、ApplicationContextInitializedEvent、ApplicationPreparedEvent、ApplicationStartedEvent、ApplicationReadyEvent等等 多拨器分发到一个特殊的DelegatingApplicationListener时候，它又去加载和环境中的&quot;context.listener.classes&quot;，然后反射创建、排序后向他们转发RunListener发来的事件。 注册到容器： 同上面的初始化器也是两种方式 META-INF/spring.factories里面注册","categories":[{"name":"框架","slug":"框架","permalink":"https://blog.sofunnyai.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://blog.sofunnyai.com/tags/spring/"},{"name":"框架","slug":"框架","permalink":"https://blog.sofunnyai.com/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"CAS比较并交换的原理和ABA问题","slug":"CAS和ABA","date":"2018-03-01T05:05:11.000Z","updated":"2020-06-15T01:14:54.825Z","comments":true,"path":"article/cas-and-aba.html","link":"","permalink":"https://blog.sofunnyai.com/article/cas-and-aba.html","excerpt":"","text":"背景 CAS简介 Atomic修饰的类为啥是线程安全的？如AtomicInteger unsafe.java底层实现： compareAndSwapInt的底层CPU源语实现—lock cmpxchg： CAS缺点 小结 CAS应用 ABA问题是什么？原子更新引用是什么？ CAS导致ABA问题 ABA问题 原子引用AtomicReference 带版本的原子引用解决ABA问题 AtomicStampedReference LongAdder（CAS机制优化） 为什么有了AtomicLong还要新增一个LongAdder呢 参考 文章主线: CAS----&gt;Unsafe----&gt;CAS底层实现和思想----&gt;ABA问题----&gt;原子引用更新----&gt;如何规避ABA问题 这篇博客还不错 https://blog.csdn.net/javazejian/article/details/72772470 背景# 在以前没有CAS的时候，对一个多线程修改i++是有线程安全问题的，因为i++操作底层是三个指令，不是原子的。 使用AtomicInteger替代Integer即可线程安全。AtomicInteger底层就是CAS支持的。 CAS简介# CompareAndSet，比较并交换思想，底层是CPU并发源语言。功能是判断某个内存是为是否是预期的值，true则更新，false放弃。过程是原子的（线程安全）。 CAS是一种轻量级锁，在没有线程阻塞的情况下实现变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁(读多场景被修改后重试或者报错)。 CPU原语音硬件实现，执行必须连续，所以天生就是原子的。线程安全。 底层通过Unsafe类实现，Unsafe中的CAS方法JVM会生成汇编指令。 Atomic修饰的类为啥是线程安全的？如AtomicInteger# AtomicInteger.java 的 getAndIncrement方法，获取值并+1，底层借助了JDK的rt.jar中的unsafe类的native方法。 unsafe类是sun.misc.Unsafe，使用本地方法帮Java操纵底层。如读写操纵特定内存位置的数据。----直接操纵操作系统执行任务 下面代码里直接用unsafe去操纵内存偏移位置上的对象，是不允许中断的连续的指令，是线程安全的，所以没有并发问题。 变量value使用volatile修饰，保证多线程的可见性 AtomicInteger.java 节选： 123456789private volatile int value; // 当前AtomicInteger内部使用了一个volatile修饰的int存储值。/** * Atomically increments by one the current value. * * @return the previous value */ public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); // 传入当前AtomicInteger对象，在内存的地址偏移量对应对象，加1 &#125; unsafe.java底层实现：# 使用了compareAndSwapInt自旋： 123456789101112// unsafe类的 getAndAddInt 方法public final int getAndAddInt(Object var1, long var2, int var4) &#123; // var1 是上面的this对象，就是当前的那个Integer，var2是unsafe找到的内存地址，var4是要新增的值 int var5; // var5 是内存快照里面的值 do &#123; var5 = this.getIntVolatile(var1, var2); // 当前这个var1（上面this对象）在内存地址var2上去取到volatile的快照值放到var5中 &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); // var1对象在var2内存地址上的值和快照值var5比较，相同就给var5+var4，结束do...while。如果拿出来的快照值不相等，继续do...while，上面去继续 return var5; &#125;// getIntVolatile 和 compareAndSwapInt是当前unsafe类中的native方法，借助CPU源语实现线程安全。（后面有个JVM native方法的源码） var5：就是我们从主内存volatile中拷贝到工作内存中的值操作的时候，需要比较工作内存中的值，和主内存中的值进行比较 假设执行 compareAndSwapInt返回false，那么就一直执行 while方法，直到期望的值和真实值一样 val1：AtomicInteger对象本身 var2：该对象值的引用内存地址 var4：需要修改变动的数量 var5：用var1和var2找到的内存中的真实值 用该对象当前的值与var5比较 如果相同，更新var5 + var4 并返回true，结束循环。 如果不同，继续取volatile值然后再比较，直到更新完成 这里没有用synchronized，而用CAS，这样提高了并发性，也能够实现一致性，是因为每个线程进来后，进入的do while循环，然后不断的获取内存中的值，判断是否为最新，然后在进行更新操作。 假设线程A和线程B同时执行getAndAddInt操作（分别跑在不同的CPU上） AtomicInteger里面的value原始值为3，即主内存中AtomicInteger的 value 为3，根据JMM模型，线程A和线程B各自持有一份价值为3的副本，分别存储在各自的工作内存 线程A通过getIntVolatile(var1 , var2) 拿到value值3，这是线程A被挂起（该线程失去CPU执行权） 线程B也通过getIntVolatile(var1, var2)方法获取到value值也是3，此时刚好线程B没有被挂起，并执行了compareAndSwapInt方法，比较内存的值也是3，成功修改内存值为4，线程B打完收工，一切OK 这是线程A恢复，执行CAS方法，比较发现自己手里的数字3和主内存中的数字4不一致，说明该值已经被其它线程抢先一步修改过了，那么A线程本次修改失败，只能够重新读取后在来一遍了，也就是在执行do while 线程A重新获取value值，因为变量value被volatile修饰，所以其它线程对它的修改，线程A总能够看到，线程A继续执行compareAndSwapInt进行比较替换，直到成功。 compareAndSwapInt的底层CPU源语实现—lock cmpxchg：# 汇编语言cmpxchg指令，也是compareAndSwapInt的实现。 多核情况下最终的实现：lock cmpxchg lock指令是锁总线，所以lock cmpxchg Unsafe类 + CAS思想： 也就是自旋，自我旋转 CAS这里不需要经过操作系统的线程管理，所以是轻量级的，synchronized是需要操作系统进行线程管理是总量级的。 CAS缺点# 和synchronized比较，没有加锁每个线程都可以同时竞争并发计算，但是也有以下缺点： 循环太多的时候，自旋太多。do…while太多，CPU开销大。（没有锁，需要大量比较） 只能保证一个变量的原子性，不像synchronized可以对多个变量进行原子性操作。 引出了ABA问题，两个线程在执行CAS竞争的时候，一个线程T1很慢，另一个T2很快。初始的时候快照变量都是A，在拿到线程内存中后，T2修改为B并CAS写回成功。然后T2再来一次CAS把变量从B改为A，后来T1才回来，一看主内存还是A，CAS成功改成C。但这时候的A和刚才的A虽然值一样，但是可能业务发生了变化。造成问题。具体见下一章。 小结# CAS应用# CAS是compareAndSwap，比较当前工作内存中的值和主物理内存中的值，如果相同则执行规定操作，否者继续比较直到主内存和工作内存的值一致为止。 CAS有3个操作数，内存值V，旧的预期值A，要修改的更新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否者什么都不做。 适用于在写少读多的时候，使用CAS完成单变量的同步。 ABA问题是什么？原子更新引用是什么？# 假设现在有两个线程，分别是T1 和 T2，然后T1执行某个操作的时间为10秒，T2执行某个时间的操作是2秒，最开始AB两个线程，分别从主内存中获取A值，但是因为B的执行速度更快，他先把A的值改成B，然后在修改成A，然后执行完毕，T1线程在10秒后，执行完毕，判断内存中的值为A，并且和自己预期的值一样，它就认为没有人更改了主内存中的值，就快乐的修改成B，但是实际上 可能中间经历了 ABCDEFA 这个变换，也就是中间的值经历了狸猫换太子。 所以ABA问题就是：在获取主内存值的时候，该内存值在我们写入主内存的时候，已经被修改了N次，但是最终又改成原来的值了 CAS导致ABA问题# CAS算法实现了一个重要的前提，需要取出内存中某时刻的数据，并在当下时刻比较并替换，那么这个时间差会导致数据的变化。 比如说一个线程one从内存位置V中取出A，这时候另外一个线程two也从内存中取出A，并且线程two进行了一些操作将值变成了B，然后线程two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后线程one操作成功 尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的，看业务情况。 ABA问题# 如果业务只管最终的数值是无所谓的，最终都是A即可。ABA问题就可以接受。（只看结果） 但是如果业务要求中间不能被别的线程偷偷改变还不知道（如支付类）。ABA问题就无法被接受。（要求过程） 原子引用AtomicReference# 原子引用其实和原子包装类是差不多的概念，就是将一个java类，用原子引用类进行包装起来，那么这个类就具备了原子性。可以完成类似AtomicInteger等同样的原子性效力。 但是原子引用打来了ABA问题。 带版本的原子引用解决ABA问题 AtomicStampedReference# 通过一个版本号stamp来解决ABA问题，内同一致但是版本号不一致还是不能提交修改。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package com.sam.phoenix.concurrent;import lombok.AllArgsConstructor;import lombok.Data;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * CAS虽然可以自旋解决变量竞争的线程安全问题，但是会带来ABA问题 * * CAS算法实现了一个重要的前提：**需要取出内存中某时刻的数据，并在当下时刻比较并替换，那么这个时间差会导致数据的变化。** * 比如说一个线程one从内存位置V中取出A，这时候另外一个线程two也从内存中取出A，并且线程two进行了一些操作将值变成了B，然后线程two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后线程one操作成功 * * `尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的，看业务情况。` * * ## ABA问题 * 如果业务只管最终的数值是无所谓的，最终都是A即可。ABA问题就可以接受。（只看结果） * 但是如果业务要求中间不能被别的线程偷偷改变还不知道（如支付类）。ABA问题就无法被接受。（要求过程） */public class CAS_ABA &#123; public static void main(String[] args) &#123; System.out.println(\"--------------------以下是一个CAS引发的ABA问题的demo-------------------------\"); casABA(); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"-----------------------以下是一个ABA解决，使用带版本号的stampRefference-------------------------\"); resolveABA(); try &#123; TimeUnit.SECONDS.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; /** * 演示CAS带来的ABA问题 */ private static void casABA()&#123; // 初始化原子引用 // 定义一个原子引用（包装了一个自定义类），初始化值是张三 AtomicReference&lt;User&gt; atomicUser = new AtomicReference&lt;User&gt;(); User z3 = new User(\"z3\", 33); atomicUser.set(z3); new Thread(()-&gt;&#123; // 完成一次ABA User l4 = new User(\"l4\", 44); atomicUser.compareAndSet(z3, l4); // 对比主内存，如果是张三，就修改为李四 atomicUser.compareAndSet(l4,z3); // 对比主内存，如果是李四，就修改为张三 &#125;,\"t1\").start(); new Thread(()-&gt;&#123; try &#123; // 睡眠1秒，等待上面ABA完成(上面偷梁换柱，偷偷改过一次) TimeUnit.SECONDS.sleep(1); User w5 = new User(\"w5\", 55); boolean result = atomicUser.compareAndSet(z3, w5); // 虽然更新成功，但是其实里面的z3已经被修改过一次了 System.out.println(\"最终t2\"+result+\",atomicUser中的user：\"+atomicUser.get()); System.out.println(\"虽然更新成功，但是其实里面的z3已经被修改过一次了,某些业务场景会出错!!!\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;,\"t2\").start(); &#125; /** * 延时使用版本号解决ABA问题 */ private static void resolveABA()&#123; User z3 = new User(\"z3\", 33); // 初始化一个张三进去，版本号是1 AtomicStampedReference&lt;User&gt; stampedReference = new AtomicStampedReference&lt;&gt;(z3, 1); new Thread(()-&gt;&#123; User l4 = new User(\"l4\", 44); // 期待是张三，相等的话就改成李四，同时期待版本号是1 int stamp = stampedReference.getStamp(); // 休眠1秒，等待下面的线程获取同样的版本号 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean result = stampedReference.compareAndSet(z3, l4, stamp,stamp+1); System.out.println(Thread.currentThread().getName()+\"尝试更新版本号\"+stamp+\"，结果：\"+result+\",stampedReference中最新的数据：\"+stampedReference.getReference()+\"最新版本号\"+stampedReference.getStamp()); stamp = stampedReference.getStamp(); result = stampedReference.compareAndSet(l4, z3, stamp,stamp+1); System.out.println(Thread.currentThread().getName()+\"尝试更新版本号\"+stamp+\"，结果：\"+result+\",stampedReference中最新的数据：\"+stampedReference.getReference()+\"最新版本号\"+stampedReference.getStamp()); &#125;,\"t3\").start(); // 因为持有的版本号是老的，会更新失败！ new Thread(()-&gt;&#123; User w5 = new User(\"w5\", 55); int stamp = stampedReference.getStamp(); // 睡3秒，等上面完成sleep和CAS try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean result = stampedReference.compareAndSet(z3, w5, stamp,stamp+1); System.out.println(Thread.currentThread().getName()+\"尝试更新版本号\"+stamp+\"，结果：\"+result+\",stampedReference中最新的数据：\"+stampedReference.getReference()+\"最新版本号\"+stampedReference.getStamp()); &#125;,\"t4\").start(); &#125;&#125;@Data@AllArgsConstructorclass User&#123; private String name; private int age;&#125; LongAdder（CAS机制优化）# LongAdder是java8在atomic包里为我们提供的新的类，跟AtomicLong有相同的效果。是对CAS机制的优化 类似的还有一个DoubleAdder： 1234567LongAdder：//变量声明public static LongAdder count = new LongAdder();//变量操作count.increment();//变量取值count 为什么有了AtomicLong还要新增一个LongAdder呢# 原因是：CAS底层实现是在一个死循环中不断地尝试修改目标值，直到修改成功。如果竞争不激烈的时候，修改成功率很高，否则失败率很高。在失败的时候，这些重复的原子性操作会耗费性能。（不停的自旋，进入一个无限重复的循环中） 核心思想：将热点数据分离。 比如说它可以将AtomicLong内部的内部核心数据value分离成一个数组，每个线程访问时，通过hash等算法映射到其中一个数字进行计数，而最终的计数结果则为这个数组的求和累加，其中热点数据value会被分离成多个单元的cell，每个cell独自维护内部的值。当前对象的实际值由所有的cell累计合成，这样热点就进行了有效地分离，并提高了并行度。这相当于将AtomicLong的单点的更新压力分担到各个节点上。在低并发的时候通过对base的直接更新，可以保障和AtomicLong的性能基本一致。而在高并发的时候通过分散提高了性能。 12345678910111213public void increment() &#123; add(1L);&#125;public void add(long x) &#123; Cell[] as; long b, v; int m; Cell a; if ((as = cells) != null || !casBase(b = base, b + x)) &#123; //cas失败一次 boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 给cell数组里面找一个线程的格子添加一个，然后下面再accumulate累加 longAccumulate(x, null, uncontended); &#125;&#125; CAS有没有问题呢？肯定是有的。比如说大量的线程同时并发修改一个AtomicInteger，可能有很多线程会不停的自旋，进入一个无限重复的循环中。 这些线程不停地获取值，然后发起CAS操作，但是发现这个值被别人改过了，于是再次进入下一个循环，获取值，发起CAS操作又失败了，再次进入下一个循环。 在大量线程高并发更新AtomicInteger的时候，这种问题可能会比较明显，导致大量线程空循环，自旋转，性能和效率都不是特别好。 于是，当当当当，Java 8推出了一个新的类，LongAdder，他就是尝试使用分段CAS以及自动分段迁移的方式来大幅度提升多线程高并发执行CAS操作的性能！ 在LongAdder的底层实现中，首先有一个base值，刚开始多线程来不停的累加数值，都是对base进行累加的，比如刚开始累加成了base = 5。 接着如果发现并发更新的线程数量过多，在发生竞争的情况下，会有一个Cell数组用于将不同线程的操作离散到不同的节点上去 ==(会根据需要扩容，最大为CPU核）==就会开始施行分段CAS的机制，也就是内部会搞一个Cell数组，每个数组是一个数值分段。 这时，让大量的线程分别去对不同Cell内部的value值进行CAS累加操作，这样就把CAS计算压力分散到了不同的Cell分段数值中了！ 这样就可以大幅度的降低多线程并发更新同一个数值时出现的无限循环的问题，大幅度提升了多线程并发更新数值的性能和效率！ 而且他内部实现了自动分段迁移的机制，也就是如果某个Cell的value执行CAS失败了，那么就会自动去找另外一个Cell分段内的value值进行CAS操作。 这样也解决了线程空旋转、自旋不停等待执行CAS操作的问题，让一个线程过来执行CAS时可以尽快的完成这个操作。 最后，如果你要从LongAdder中获取当前累加的总值，就会把base值和所有Cell分段数值加起来返回给你。 如上图所示，LongAdder则是内部维护多个Cell变量，每个Cell里面有一个初始值为0的long型变量，在同等并发量的情况下，争夺单个变量的线程会减少，这是变相的减少了争夺共享资源的并发量，另外多个线程在争夺同一个原子变量时候， 如果失败并不是自旋CAS重试，而是尝试获取其他原子变量的锁，最后当获取当前值时候是把所有变量的值累加后再加上base的值返回的。 LongAdder维护了要给延迟初始化的原子性更新数组和一个基值变量base数组的大小保持是2的N次方大小，数组表的下标使用每个线程的hashcode值的掩码表示，数组里面的变量实体是Cell类型。 Cell 类型是Atomic的一个改进，用来减少缓存的争用，对于大多数原子操作字节填充是浪费的，因为原子操作都是无规律的分散在内存中进行的，多个原子性操作彼此之间是没有接触的，但是原子性数组元素彼此相邻存放将能经常共享缓存行，也就是伪共享。所以这在性能上是一个提升。（补充：可以看到Cell类用Contended注解修饰，这里主要是解决false sharing(伪共享的问题)，不过个人认为伪共享翻译的不是很好，或者应该是错误的共享，比如两个volatile变量被分配到了同一个缓存行，但是这两个的更新在高并发下会竞争，比如线程A去更新变量a，线程B去更新变量b，但是这两个变量被分配到了同一个缓存行，因此会造成每个线程都去争抢缓存行的所有权，例如A获取了所有权然后执行更新这时由于volatile的语义会造成其刷新到主存，但是由于变量b也被缓存到同一个缓存行，因此就会造成cache miss，这样就会造成极大的性能损失） LongAdder的add操作图 可以看到，只有从未出现过并发冲突的时候，base基数才会使用到，一旦出现了并发冲突，之后所有的操作都只针对Cell[]数组中的单元Cell。 如果Cell[]数组未初始化，会调用父类的longAccumelate去初始化Cell[]，如果Cell[]已经初始化但是冲突发生在Cell单元内，则也调用父类的longAccumelate，此时可能就需要对Cell[]扩容了。 另外由于Cells占用内存是相对比较大的，所以一开始并不创建，而是在需要时候再创建，也就是惰性加载，当一开始没有空间时候，所有的更新都是操作base变量。 如上图代码： 例如32、64位操作系统的缓存行大小不一样，因此JAVA8中就增加了一个注@sun.misc.Contended解用于解决这个问题,由JVM去插入这些变量，具体可以参考openjdk.java.net/jeps/142 ，但是通常来说对象是不规则的分配到内存中的，但是数组由于是连续的内存，因此可能会共享缓存行，因此这里加一个Contended注解以防cells数组发生伪共享的情况。 为了降低高并发下多线程对一个变量CAS争夺失败后大量线程会自旋而造成降低并发性能问题，LongAdder内部通过根据并发请求量来维护多个Cell元素(一个动态的Cell数组)来分担对单个变量进行争夺资源。 可以看到LongAdder继承自Striped64类，Striped64内部维护着三个变量，LongAdder的真实值其实就是base的值与Cell数组里面所有Cell元素值的累加，base是个基础值，默认是0，cellBusy用来实现自旋锁，当创建Cell元素或者扩容Cell数组时候用来进行线程间的同步。 在无竞争下直接更新base，类似AtomicLong高并发下，会将每个线程的操作hash到不同的cells数组中，从而将AtomicLong中更新一个value的行为优化之后，分散到多个value中 从而降低更新热点，而需要得到当前值的时候，直接 将所有cell中的value与base相加即可，但是跟AtomicLong(compare and change -&gt; xadd)的CAS不同，incrementAndGet操作及其变种可以返回更新后的值，而LongAdder返回的是void。 由于Cell相对来说比较占内存，因此这里采用懒加载的方式，在无竞争的情况下直接更新base域，在第一次发生竞争的时候(CAS失败)就会创建一个大小为2的cells数组，每次扩容都是加倍，只到达到CPU核数。同时我们知道扩容数组等行为需要只能有一个线程同时执行，因此需要一个锁，这里通过CAS更新cellsBusy来实现一个简单的spin lock。 数组访问索引是通过Thread里的threadLocalRandomProbe域取模实现的，这个域是ThreadLocalRandom更新的，cells的数组大小被限制为CPU的核数，因为即使有超过核数个线程去更新，但是每个线程也只会和一个CPU绑定，更新的时候顶多会有cpu核数个线程，因此我们只需要通过hash将不同线程的更新行为离散到不同的slot即可。 我们知道线程、线程池会被关闭或销毁，这个时候可能这个线程之前占用的slot就会变成没人用的，但我们也不能清除掉，因为一般web应用都是长时间运行的，线程通常也会动态创建、销毁，很可能一段时间后又会被其他线程占用，而对于短时间运行的，例如单元测试，清除掉有啥意义呢？ 参考# AtomicLong与LongAdder（CAS机制的优化） 大白话聊聊Java并发面试问题之Java 8如何优化CAS性能？ https://blog.csdn.net/wolf_love666/article/details/87693771 https://gitee.com/moxi159753/LearningNotes","categories":[{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"jdk","slug":"jdk","permalink":"https://blog.sofunnyai.com/tags/jdk/"},{"name":"源码","slug":"源码","permalink":"https://blog.sofunnyai.com/tags/%E6%BA%90%E7%A0%81/"},{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"多线程之volatile和synchronized","slug":"thread-volatile-synchronized","date":"2018-02-10T07:40:20.000Z","updated":"2020-06-15T09:08:26.968Z","comments":true,"path":"article/volatile-and-synchronized.html","link":"","permalink":"https://blog.sofunnyai.com/article/volatile-and-synchronized.html","excerpt":"","text":"计算机基础 CPU缓存 处理器优化和指令重排 带来的问题： CPU缓存一致性协议： 缓存行与缓存行对齐： 缓存行CacheLine： 上下文切换 线程间通信 并发编程问题 内存模型 JMM Java虚拟机内存模型 JMM是啥？ JVM基本规定： JMM和Java内存区域堆栈结构没关系： JMM的解决方案 1.共享对象对各个线程的可见性，类似CPU的缓存一致性【可见性】 2.共享对象的竞争现象【原子性】 3.编译器指令重排【有序性】 as-if-serial 和 happens-before as-if-serial Happens-Before 对象的创建过程 Volatile关键字 线程可见性： volatile只能保证可见性，不能保证并发线程安全性： 禁止指令重排（重点） volatile通过内存屏障解决指令重排 内存屏障 JVM层面对volatile的实现 Hotspot底层对volatile的实现（汇编 lock addl 0） final的内存屏障 重量级锁Synchronized Synchronized可以保证： 有三种表现形式： JVM的synchronized实现： 存储位置： Wait和Notify必须和synchronized一起用 各种锁的大全 乐观锁和悲观锁： 自旋锁和适应性自旋锁： 无锁(轻量级锁)VS偏向锁 VS 轻量级锁 VS 重量级锁 公平锁和非公平锁 可重入锁和不可重入锁 独享锁 VS 共享锁（读写锁！） 锁升级过程： Monitor 1.普通对象-无锁 2.偏向锁 3.轻量级锁–自旋锁 4.重量级锁 升级过程记录在markword上： 锁消除 锁粗化 超线程： 锁重入 锁降级 DCL单例 线程基础 创建线程的方式： ObjectMonitor： Wait/Notify wait方法要放在锁里面！！！ wait的实现： Notify的实现： 为啥要放到synchronized里面？否则会抛出 IllegalMonitorStateException？ callable/futrue 常见问题QA synchronized和ReentrantLock有什么区别？ 避免死锁： 并发一定会提高效率？ 实现 计算机基础# CPU缓存# 这是最基础的本科大一讲的： 因为CPU的速度比主内存快很多，所需CPU内部有高速缓存，每个线程都会把主存数据load到高速缓存进行计算。这就导致了一个多线程的多份线程缓存中的数据可能和主内存不一致： 数据获取流程(速度递减)：L0寄存器-L1级缓存-L2级缓存-L3级缓存(高端CPU才有)-L4主存-L5磁盘-L6远程文件（寄存器和内存读写速度1:100左右） L1-L3是CPU的三级高速缓存。 多个CPU共享主存，一个CPU内部的多核共享L3，一个核心内部共享L1和L2. 处理器优化和指令重排# 因为CPU的速度比主内存快很多，所以不可能一条指令一条指令挨着执行。某些没有依赖关系的指令可能会重排序。（运行时重排） 带来的问题：# 因为CPU使用了高速缓存、而且是多核心的，会有指令重排。会带来CPU硬件层面的问题-----------缓存不一致和原子性、可见性问题。在CPU和主存之间增加缓存，在多线程场景下就可能存在缓存一致性问题，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。 缓存不一致解决方案：缓存一致性协议 原子性和有序性问题解决方案：总线锁来解决 CPU缓存一致性协议：# 下面讲的和Volatile没关系，是CPU层面的类似场景下的实现技术。 总线锁：CPU和内存的通信锁住，期间不允许线程访问其他地址的数据，开销太大，不合适。------------汇编lock指令，不过可以解决原子性问题。 缓存一致性协议（有多个实现）：每个缓存的缓存控制器除了读写自己的数据，还要监听其他缓存的数据。规定了其他各个缓存处于什么状态能否读/写。这也造成了指令重排。（假如当前修改的是CPU0，其他CPU线程简称为CPU1）过程就是CPU0引入了storebuff，将数据的修改执行放到storebuff，然后发送消息给CPU1，这时候CPU0可以继续执行接下来的代码，当storebuff收到CPU1线程的ack应答消息后，storebuff将修改的数据同步到缓存行，再同步到主内存当中。 MESI是缓存一致性协议的一种，Intel的X86架构实现规范。Modify(修改了)/Exclusive(独占)/Shared(都可以读)/Invalid(失效)。 缓存行与缓存行对齐：# 缓存行CacheLine：# 如果内存一个很小的byte和CPU交互，缓存到L3。但是只交互一个很小的对象浪费，也不经济。所以经常是把这个值旁边的一小块内存一起访问（按页读取），下次要读取的时候直接就有了（局部性原理） 缓存行越大，局部空间越大效率高，但是读取慢。 缓存行越小，局部空间越小效率低，但是读取快。 目前多用64字节 上下文切换# Java的线程主流JVM是映射到OS的线程上的。阻塞或者唤醒线程需要OS帮忙，是重量级操作，用户态和内核态转换，耗费不少时间。 所以在每个线程消耗时间很短的场景下，太多线程不一定比单线程快，频繁的线程切换可能反而带来更大的开销。 降低上下文切换的方法： 无锁并发 CAS 尽量用最少的线程并发 考虑使用协程 线程间通信# 内存共享和传递消息 内存共享：在共享内存的并发模型中线程之间共享程序的公共数据状态，线程之前通过读写内存中的公共内存区域来进行信息的传递，典型的共享内存通信方式就是通过共享对象来进行通信。 消息传递：比如在Linux系统中同步机制有管道、信号、消息队列、信号量、套接字这几种方式。JVM的wait()跟notify() 并发编程问题# 前面说的都是跟硬件相关的问题，软件在这样的硬件层面上运行就会出现原子性、可见性、有序性问题。 其实，原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性、处理器优化、指令重排问题。 一般而言并发编程，为了保证数据的安全，需要满足以下三个特性： 原子性：（不可分）指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。只有6个 基本数据类型的访问、 读写都是具备原子性的 synchronized实现原子性 可见性：（变更立即可见）指当一个线程修改了共享变量的值时， 其他线程能够立即得知这个修改。三个关键字都能实现： volatile：新值立即同步到主存，每次从主存刷新。 synchronized：对一个变量执行unlock操作之前， 必须先把此变量同步回主内存中（执行store、 write操 作） final：构造器构造完对象，final的值被赋值。其他线程就能立刻看到。 有序性：（顺序）程序执行的顺序按照代码的先后顺序执行。 volatile：禁止指令重排 synchronized：一个变量只允许一个线程获取锁。 Java原生就有Happens-Before原则来解决大部分有序性问题。 你可以发现缓存一致性问题其实就是可见性问题(CPU缓存层面的，和Java不一样)。而处理器优化是可以导致原子性问题的。指令重排即会导致有序性问题。 内存模型# 为了解决因为缓存一致性、处理器优化、指令重排问题导致的上面的并发编程问题，需要提出内存模型。 内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。 JMM Java虚拟机内存模型# JMM是啥？# 因为CPU的高速缓存和指令重排序，带来CPU硬件层面上的原子性、一致性、有序性问题。CPU各个架构采用了不同的方式来解决（总线锁+不同的缓存一致性协议），Java作为一个跨平台的语言，定义一套JMM来屏蔽底层硬件架构的差异，解决上述三个问题。 所以JMM是Java层面的内存模型的实现，为了解决上面的问题，不是实际的存在。。 只要提到Java内存模型，一般指的是JDK 5 开始使用的新的内存模型，主要由JSR-133: JavaTM Memory Model and Thread Specification 描述。 是一种虚拟的规范，作用于工作内存和主存之间数据同步过程。 目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。(可见性、原子性、有序性) JMM 本身是一种抽象的概念并不是真实存在，它描述的是一组规定或则规范，通过这组规范定义了程序中的访问方式。 JVM基本规定：# 所有的变量(成员、静态字段)都存储在主内存中。 （此处的变量 与Java编程中所说的变量有所区别， 它包括了实例字段、 静态字段和构成数组对象的元素， 但是不包括局部变量与方法参数，因为后两个是私有的） 每条线程还有自己的工作内存。(可以和物理内存和高速缓存类比，但不是一回事儿) **线程的工作内存中保存了被该线程使用的变量的主内存副本。**线程对变量的操作（读取赋值等）必须都工作内存进行。 线程对变量的所有操作（读取、 赋值等） 都必须在工作内存中进行， 而不能直接读写主内存中的数据。 不同的线程之间也无法直接访问对方工作内存中的变量， 线程间变量值的传递均需要通过主内存来完成。 JMM 同步规定 线程加锁前，必须读取主内存的最新值到自己的工作内存 线程解锁前，必须把共享变量的值刷新回主内存 加锁解锁是同一把锁 上述三点保证了synchronized的可见性。 JMM和Java内存区域堆栈结构没关系：# 这里所讲的主内存、 工作内存与第2章所讲的Java内存区域中的Java堆、 栈、 方法区等并不是同一个层次的对内存的划分， 这两者基本上是没有任何关系的。 如果两者一定要勉强对应起来， 那么从变量、 主内存、 工作内存的定义来看， 主内存主要对应于Java堆中的对象实例数据部分， 而工作内存则对应于虚拟机栈中的部分区域。（《深入理解JVM虚拟机第三版》） 主内存直接对应于物理硬件的内存， 而为了获取更好的运行速度， 虚拟机（或者是硬件、 操作系统本身的优化措施） 可能会让工作内存优先存储于寄存器和高速缓存中， 因为程序运行时主要访问的是工作内存。 JMM的解决方案# 1.共享对象对各个线程的可见性，类似CPU的缓存一致性【可见性】# A 线程读取主内存数据修改后还没来得及将修改数据同步到主内存，主内存数据就又被B线程读取了。 volatile解决、synchronized可以解决(单线程+解锁前刷新)、final天然解决。 2.共享对象的竞争现象【原子性】# AB两个线程同时读取主内存数据，然后同时加1，再返回。 synchronized、JUC.Lock (底层都是CAS解决） 3.编译器指令重排【有序性】# --------此处是编译器的指令重排+CPU指令重排。 编译器优化的重排序：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 CPU的指令级并行的重排序：现代处理器采用了指令级并行技术将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序：处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行 使用volatile禁止指令重排、使用synchronized/JUC同步锁解决。 综上，我们发现synchronized似乎是万能的，但是代价也很大。 as-if-serial 和 happens-before# as-if-serial# 上面编译器和CPU都可能重排，但是要保证不管怎么重排，至少在单线程上运行结果不能改变。所以为了这个目标，编译器和CPU都不会对数据依赖关系的指令重排，这会破坏as-if-serial规则。（比如读取，应该在写的后面） 强调重排后单线程内的执行结果也不应该改变。 1234a=1;b=2;int c;c = a+b; // 不管怎么重排序，不应该影响最后的c结果 Happens-Before# 是JVM的重排必须遵守的规则。 先行发生是Java内存模型中定义的两项操作之间的偏序关系， 比如说操作A先行发生于操作B， 其实就是说在发生操作B之前， 操作A产生的影响能被操作B观察到， “影响”包括修改了内存中共享变量的值、 发送了消息、 调用了方法等。 程序顺序规则(Program Order Rule)：一个线程中的每个操作，happens-before于该线程中的任意后续操作。(线程内是有序的，包括调用、判断)【这是编程基础，否则就乱了】 监视器锁规则(Monitor Lock Rule)：对一个锁的解锁，happens-before于随后对这个锁的加锁。（先解锁了才能加锁） volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。（先写完了后面才能读，不能重排） 线程启动规则（Thread Start Rule） ： Thread对象的start()方法先行发生于此线程的每一个动作。 。。。还有几个，一共八种，不用背。 Java无需任何同步手段保障就能成立的先行发生规则有且只有上面这些。其他的都可能被重排序。【强调的是，正确同步的多线程程序是按照Happens-Before执行的】 二者关系：# as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。 as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。 as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。 对象的创建过程# 12345class T&#123; int m = 8;&#125;T t = new T(); 这个对象的Java字节码： 一共有5条指令，核心三条：（可能重排序） 先创建对象，0值初始化。 然后调用构造方法，对象属性赋值。 最后把引用和对象关联起来。 123450 new #2 &lt;T&gt; # 就像在C++里面获取空间一样，给这个对象使用。并0值初始化。此时m&#x3D;0-------此时像是一个半初始化状态3 dup4 invokespecial #1 &lt;T.&lt;init&gt;&gt; # 调用对象的构造方法，此时m&#x3D;87 astore_1 # 把引用和对象内存关联起来8 return Volatile关键字# volatile的两个作用：线程可见性、和防止指令重排序 ，但不能保证原子性！！！ 如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。 线程可见性：# JVM的内存也分为主内存、线程本地内存。不要把它和CPU的缓存去对应，事实上主内存和线程本地内存都可能存在于CPU的缓存区、主内存区。 这里的“可见性”是指当一条线程修改了这个变量的值， 新值对于其他线程来说是可以立即得知的。 而普通变量并不能做到这一点， 普通变量的值在线程间传递时均需要通过主内存来完成。 比如，线程A修改一个普通变量的值， 然后向主内存进行回写， 另外一条线程B在线程A回写完成了之后再对主内存进行读取操作， 新变量值才会对线程B可见。 第一个：主内存和线程本地内存： 线程会把主内存的数据copy到本地内存去执行。当变量被volatile修饰后就不会copy到各个线程本地。每次读取的时候都去主内存拿。 1234567891011121314151617181920// 加了volatie，线程才对其他线程的修改可见 private static volatile boolean stop = false; public static void main(String[] args) throws Exception&#123; new Thread(()-&gt;&#123; while(!stop)&#123; //... &#125; System.out.println(\"end！\"); &#125;).start(); TimeUnit.SECONDS.sleep(1); stop = true; // 修改flag，期望另外一个线程结束。但是如果没有volatile是不行的。 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; volatile只能保证可见性，不能保证并发线程安全性：# 保证可见性，但是并不是说volatile的就是线程安全的！！只是每个线程使用的时候去主存刷新一下而已。 第一项是保证此变量的变更对所有线程的可见性，只是对所有线程是可立即得知的，没有一致性问题。（每个线程物理存储的值可能不一样，但是使用前都会去主存刷新，实际使用时候应用看不到不一样的场景）但还是可能有并发原子性问题。 1234567891011121314151617181920212223242526272829/** * 保证可见性，但是并不是说volatile的就是线程安全的！！只是每个线程使用的时候去主存刷新一下而已。 */public class VolatileTest &#123; static volatile int cnt = 0; // 对所有线程是立即可见的，没有一致性问题。（每个线程物理存储可能不一样，但是使用前都会去主存刷新，应用看不到不一样的场景）但还是可能有并发原子性问题。 /** * 下面并发访问volatile的对象，发现并不能线程安全 * @param args */ public static void main(String[] args) &#123; for (int i = 0; i &lt; 100; i++) &#123; new Thread(()-&gt;&#123; for (int j = 0; j &lt; 100; j++) &#123; cnt++; // 这一行底层是由4个指令完成的，第一个getstatic从主存拿到操作栈顶的时候是取得最新的， // 但是下面几条指令给他iadd的时候别的线程可能会修改它。他最后一条执行完毕写会主存的时候就会是过期的值。 /** * 底层字节码是这四行： * 8 getstatic #7 &lt;com/sam/phoenix/concurrent/thread/demo/sync_volatile/VolatileTest.cnt&gt; * 11 iconst_1 * 12 iadd * 13 putstatic #7 */ &#125; &#125;).start(); &#125; System.out.println(cnt); // 结果并不是1w &#125; ​ 禁止指令重排（重点）# volatile通过内存屏障解决指令重排# 前面提到为了节省CPU的运行时间，允许将没有数据先后依赖顺序要求的指令重排序运行。 但有时候在高并发场景会出现问题，如DCL不用volatile禁止重排，可能会导致极端情况半初始化对象被返回回去（0值未在构造方法顺利初始化）。 内存屏障# 内存屏障是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。 Java编译器也会根据内存屏障的规则禁止重排序。 Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。告诉CPU： 不管什么指令都不能和这条Memory Barrier指令重排序。 Memory Barrier所做的另外一件事是强制刷出各种CPU Cache，如一个Write-Barrier（写入屏障）将刷出所有在Barrier之前写入cache 的数据，因此，任何CPU上的线程都能读取到这些数据的最新版本。 四种内存屏障： LL：序列：Load1,Loadload,Load2 读 读 大白话就是Load1一定要在Load2前执行，及时Load1执行慢Load2也要等Load1执行完。通常能执行预加载指令/支持乱序处理的处理器中需要显式声明Loadload屏障，因为在这些处理器中正在等待的加载指令能够绕过正在等待存储的指令。 而对于总是能保证处理顺序的处理器上，设置该屏障相当于无操作。 SS：序列：Store1，StoreStore，Store2 大白话就是Store1的指令任何操作都可以及时的从高速缓存区写入到共享区，确保其他线程可以读到最新数据，可以理解为确保可见性。通常情况下，如果处理器不能保证从写缓冲或/和缓存向其它处理器和主存中按顺序刷新数据，那么它需要使用StoreStore屏障。 LS：序列： Load1; LoadStore; Store2 大致作用跟第一个类似，确保Load1的数据在Store2和后续Store指令被刷新之前读取。在等待Store指令可以越过loads指令的乱序处理器上需要使用LoadStore屏障。 SL：序列: Store1; StoreLoad; Load2 确保Store1数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 StoreLoad Barriers是一个全能型 的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。 JVM层面对volatile的实现# 上面提到禁止指令重排底层是通过内存屏障实现的。 内存屏障其实就是对指令加屏障，在指令执行前后进行约束。JVM编译的时候，生成字节码底层是插入lock 指令-----总线锁 JVM有8种基础原子操作：lock、unlock、store、load。。。（这里的lock和上面的汇编lock不是一回事儿） 如： 1.在每个volatile写(S)操作的前面插入一个StoreStore屏障（上一个S和这个S不能重排，前面写完了这里才能写） 2.在每个volatile写操作的后面插入一个SotreLoad屏障（上一个S写完了，下面才能读Load） 3.在每个volatile读(L)操作的前面插入一个StoreLoad屏障（上一个写完了你才能读） 4.在每个volatile读操作的后面插入一个LoadStore屏障（这一次读完了，下面才能写） 综上：volatile变量读操作的性能消耗与普通变量几乎没有什么差别， 但是写操作则可能会慢上一些， 因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。 Hotspot底层对volatile的实现（汇编 lock addl 0）# 和缓存一致性协议没关系，很多人误解这里是MESI实现的，然而并不是。 JVM这里判断是否多核CPU，如果是的话，使用了汇编语句。AMD和其他CPU都用了一样的语句 1lock addl 0 esp addl是往某个寄存器上面加一个值，这里加了一个0. addl 0是一个空操作。 lock用于多处理器的时候执行指令时对共享内存独占使用-----锁总线。 作用是对当前处理器的缓存内容刷到内存，并使其他处理器的缓存失效。 同时其他的指令无法越过这个内存屏障。 汇编还有一条nop空指令，但是不能被lock 这里是用lock锁住了空操作指令 下面的例子如果发生指令重排，可能把标识initialized = true;对应的字节码指令重排到读取配置文件configText = readConfigFile(fileName);前面 此时另一个线程看到initialized = true;就去读取，但是config还没准备好，是未初始化的0值对象。 所以必须加volatile 1234567891011121314151617181920Map configOptions;char[] configText;// 此变量必须定义为volatilevolatile boolean initialized = false;// 假设以下代码在线程A中执行// 模拟读取配置信息， 当读取完成后// 将initialized设置为true,通知其他线程配置可用configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;// 假设以下代码在线程B中执行// 等待initialized为true， 代表线程A已经把配置信息初始化完成while (!initialized) &#123;sleep();&#125;// 使用线程A中初始化好的配置信息doSomethingWithConfig(); final的内存屏障# 123456789101112@Getter@Setterclass UserBean &#123; private final String userName; private int age; public UserBean(String name)&#123; this.userName = name; //--------------1 &#125;&#125;UserBean u = new UserBean(); //------------2 在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 也就是赋值完了才能返回，否则会返回一个未初始化final的对象。 会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore屏障。 读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障。 重量级锁Synchronized# synchronized关键字是并发编程中线程同步的常用手段之一，synchronized是悲观锁，是一个非公平的可重入锁。其作用有三个: 并发编程问题 可以看到synchronized有三个功能 Synchronized可以保证：# 原子性：加锁的部分一次性完成。多个线程操作同个代码块或函数必须排队获得锁。 可见性：Synchronized在结束之前会把其中的所有变量写到共享内存，保证多线程可见。 有序性：解决重排序问题。同一时刻只允许一个线程操作代码块。多个synchronized只能逐个串行。 有三种表现形式：# 对于静态同步方法，锁是当前类的Class对象。 对于普通同步方法，锁是当前实例对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 synchronized修饰的实例方法，多线程并发访问时，只能有一个线程进入，获得对象内置锁，其他线程阻塞等待，但在此期间线程仍然可以访问其他方法。 synchronized修饰的静态方法，多线程并发访问时，只能有一个线程进入，获得【类锁】，其他线程阻塞等待，但在此期间线程仍然可以访问其他方法。 synchronized修饰的代码块，多线程并发访问时，只能有一个线程进入，根据括号中的对象或者是类，获得相应的对象内置锁或者是类锁 每个类都有一个类锁，类的每个对象也有一个内置锁，它们是互不干扰的，也就是说一个线程可以同时获得类锁和该类实例化对象的内置锁，当线程访问非synchronzied修饰的方法时，并不需要获得锁，因此不会产生阻塞。 JVM的synchronized实现：# 这个话题有坑，有一个编译器层面和底层的实现。还有一个synchronized的锁升级部分。 synchronized关键字经过Javac编译之后， 会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令插入到synchronized进入和出口位置。 这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。 任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 在执行monitorenter指令时， 首先要去尝试获取对象的锁。 如果这个对象没被锁定， 或者当前线程已经持有了那个对象的锁， 就把锁的计数器的值增加一， 而在执行monitorexit指令时会将锁计数器的值减一。 一旦计数器的值为零， 锁随即就被释放了。 如果获取对象锁失败， 那当前线程就应当被阻塞等待， 直到请求锁定的对象被持有它的线程释放为止。 如果是锁定的方法，有一个ACC_SYNCHRONIZED标识。 下面是DCL语句对应的JVM字节码： 12345synchronized (DCL_Singleton.class)&#123; if (INSTANCE == null)&#123; // 防止在上面if之后，sync之前有多个线程到达，避免多个线程依次进来创建多个实例 INSTANCE = new Object(); // --------------new &#125; &#125; 对应的字节码，先javac编译成class，再javap -v显示这个class的附加信息，就能看到JVM指令 synchronized和CAS底层是这个汇编命令，在Hotspot里面可以看到 1lock cmpechg 存储位置：# 对象布局： mark word：8个字节（锁信息/GC代数/hashcode），数组是12 class pointer：这个对象是属于那个类的，指向方法区的对象 4个字节 数组长度：数组对象才有，4字节。 instance data：成员变量 padding：对齐为8字节的整数倍。 如果是new Object(),就是8markword+4class pointer+4padding=16字节，顺丰、美团面试原题！！！ 12345678910111213141516171819202122232425262728@Data@AllArgsConstructorclass User&#123; String userName; int age;&#125; // 然后在main方法用JOL分析一下一个对象内存布局 User u = new User(\"张三\",16); System.out.println(ClassLayout.parseInstance(u).toPrintable()); // 下面可以看到前两行是mark word 8个字节 // 接下来是默认压缩过的class pointer 4个字节 // 再后面是两个instance data，分别是4个字节的int age，4个字节的 String username 引用 // 上面加起来是20个字节，不能被8整除，所以后面补了4个字节的padding。 /** * com.sam.phoenix.concurrent.jol.User object internals: * OFFSET SIZE TYPE DESCRIPTION VALUE * 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) // markword * 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) // markword * 8 4 (object header) 43 c1 00 f8 (01000011 11000001 00000000 11111000) (-134168253) // class pointer * 12 4 int User.age 16 // instance data 年龄int 4字节 * 16 4 java.lang.String User.userName (object) // instance data 名称String引用 4字节 * 20 4 (loss due to the next object alignment) // padding 4字节，一共24 * Instance size: 24 bytes * Space losses: 0 bytes internal + 4 bytes external = 4 bytes total */ synchronized用的锁是存在Java对象头里的。如果对象是非数组类型，则用8字节存储markword。 Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。（MarWord：hashcode、GC代信息、锁信息） Wait和Notify必须和synchronized一起用# 使用wait()、notify()和notifyAll()时需要先对调用对象加锁。且加锁、解锁、wait、notify必须是同一个锁对象。否则会报错java.lang.IllegalMonitorStateException 调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的等待队列。 notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或notifAll()的线程释放锁之后，等待线程才有机会从wait()返回 notify()是吧一个线程从等待队列移动到同步队列，notifAll是吧所有线程都移动了。被移动的线程状态从WATING变为BLOCKING 各种锁的大全# 乐观锁和悲观锁：# 悲观锁：认为竞争是一直存在的，需要加锁来保证执行的顺序，最终保证我们的业务数据的正确性。lock和synchronized都是悲观锁-----适用于写多的场景。 乐观锁：认为竞争是少的，大部分时候都没什么竞争，读取更多。这时候可以通过版本号或者去多次自旋去加乐观锁，如果写失败通过再次加锁重试、或者抛出异常等方式来实现业务逻辑。比如CAS的多次自旋锁、AtomicXXX。-------适用于写少的场景 自旋锁和适应性自旋锁：# 自旋锁：常规重量级锁是由OS实现的，线程状态切换涉及到内核调用。如果只是一个极小的操作加重量级锁反而效率低。这时候使用CAS自旋锁在用户态就搞定了。（如AtomicInteger底层的getAndAdd） 自旋锁的问题：时间短ok，获取锁时间长则会长时间自旋，占用CPU。也不可能通过sleep去操作，只能在自旋一定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有后进行自适应自旋，升级为线程挂起的重量级锁。 自适应自旋：默认10次，可以使用-XX:PreBlockSpin来更改。在自旋10次还CAS失败，就进行自适应自旋，升级为线程挂起的重量级锁。 自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。（基于统计值的自适应，常见实现:TicketLock、CLHlock和MCSlock） 无锁(轻量级锁)VS偏向锁 VS 轻量级锁 VS 重量级锁# 这四种锁是指锁的状态，专门针对synchronized的。参见后面的 锁升级过程 章节。 公平锁和非公平锁# 公平锁：等待队列严格FIFO，等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁：加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 ReentrantLock默认非公平。 synchronized也是非公平 另一篇博文《AQS#公平锁和非公平锁》 中可以看到。 其实ReentrantLock中就是下面这一行，多了一个判断。公平锁是判断队列里面没有等待的节点，采取获取锁，失败才排队。非公平锁直接去获取，失败就排队。 可重入锁和不可重入锁# 可重入锁：是在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。 不可重入锁：相反，即使是锁定 同一个对象或者class，每次进入都需要单独获取锁。这样在递归或者继承的时候可能会死锁。 首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。 可重入锁是加锁status+=1，同一线程可以加锁多次。释放时候status-=1，当status==0就free了。 不可重入锁加锁status+=1，再次加锁不为0会加锁失败。 独享锁 VS 共享锁（读写锁！）# 独享锁：也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁：是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 下面是JDK的读写分离锁代码实现： 读写分离锁,在读比较多(耗时)的场合比常规的重入锁更加有效率。 读-读线程互不阻塞,多少各线程都可以并行一起读。 但是当读-写或者写-写线程相互竞争的时候会阻塞获取锁才可以操作 可以看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。 高类聚低耦合的要求下，线程要操作资源类。 可重入锁(递归锁)：同一线程外层已经获取锁后，内层递归函数任然可以获取锁（锁的标志位+1）。线程可以进入任何一个他已经拥有锁同步者的代码块。 12345678public synchronized void method1()&#123; System.out.println(\"m1..\"); method12();&#125;public synchronized void method12()&#123; System.out.println(\"m2...\");&#125; 一把锁加锁2次，解锁2次，正常编译、运行？。-----------阿里电话面试。 1234567891011/** * 也可以正常运行 */public void method4()&#123; ReentrantLock lock = new ReentrantLock(true); lock.lock(); lock.lock(); System.out.println(\"m4...\"); lock.unlock(); lock.unlock();&#125; 自旋锁，更多见CAS博文。 循环的方式去获取锁，减少线程切换，但是消耗CPU。 手动基于CAS Thread实现一个自旋锁 读写锁，读不互斥。 锁升级过程：# 先概述：偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 锁升级是通过ObjectMonitor监视器实现的。路径是new-偏向锁-轻量级所（无锁、自旋锁、自适应锁）-重量级锁 Monitor# Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 “阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 1.普通对象-无锁# new出来的对象如果偏向锁没启动就是一个普通对象。（极少）后续批量锁撤销和批量重偏向 一般4s后就偏向锁就自动启动了，new出来的普通对象就是101的匿名偏向。（大多） 多线程CAS去修改一个变量也可视为无锁，失败就重试。 2.偏向锁# 101：普通对象synchronized上锁的时候优先上偏向锁。 MarkWord上面记录当前线程指针，下次在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁（线程指针）。（绝大部分时候没有竞争） 所谓偏向锁，偏向加锁的第一个线程。hashCode备份在线程栈上，线程销毁，锁降级为无锁。 延迟启动，JVM 启动4s以后-XX:BiasLockStartupDely=0。所有不加锁对象创建成功就是101，即匿名偏向锁，后面没有线程号。 竞争严重的应用可以关闭偏向锁，避免锁撤销过程的性能消耗。 为什么要用到偏向锁？ 比如Vector和StringBuffer的所有方法都是synchronized的，StringBuilder不是。不过StringBuffer和StringBuilder底层都是字符串数组去不断扩容实现的。 但是在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。也就是绝大部分时候都不需要用到竞争，或者说没有竞争。如果一上来就给操作系统申请重量级线程锁很浪费资源。提高效率。 所以就有一个偏向锁，给对象一个标识说当前线程正在占用。（偏向第一个线程） 偏向锁的释放？ 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。 偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 如果一上来就竞争特别激烈的场景，不如直接使用轻量级自旋锁。-XX:-UseBiasedLocking=false可以关闭默认打开的偏向锁。 3.轻量级锁–自旋锁# 00：偏向锁有轻度竞争，偏向锁升级为轻量级锁**（就是自旋锁）**。 每个线程有自己的LockRecoder在自己的线程栈上。 用CAS去争用markword的LR的指针。指针指向那个线程的LR，哪个线程就有锁。 当线程很多的时候，CAS的空转很影响效率，这时候就是用重量级锁去交给OS内核态队列处理。 自旋锁在JDK1.4引入，需要加参数-XX:+UseSpinning启用。1.6开始自动启用,并且引入了自适应的自旋锁（适应性自旋锁） 加锁过程： 当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 4.重量级锁# 10:JDK1.6以前默认，可以调优：自旋超过10次，或等待的线程超过CPU核数1/2，升级为重量级锁。1.6之后自适应自旋，JVM自己决定升级。 –如果太多线程自旋消耗CPU太大，不如升级为重量级锁，自动加入等待队列，不消耗CPU。 -XX:PreBlockSpin 重量级锁也是JVM使用ObjectMonitor搞了一个虚拟队列，使用CAS自旋，失败park。（JVM C++代码里，和我们Java的ReentrantLock很像，只是它还搞了一个EntryList另外一个队列去降低竞争） 升级过程记录在markword上：# 其实就是修改下面对象的markword，64位虚拟机看最后两位。所以任何对象都可以被锁： 00 轻量级锁（自旋锁） 10 重量级 11 GC标记要被回收 01：001无锁，101偏向锁 普通对象到偏向锁的过程，是2位计数的epoch，批量锁撤销和批量重偏向。 锁升级为偏向锁后hashCode存到线程栈中LockRecord，对象markword记录线程指针。（对象现在被线程独占） 只有重量级锁是在内核态，需要操作系统线程管理介入。前面的偏向锁和轻量级锁都是用户态。 自旋锁什么时候升级为重量级锁？ 偏向锁是不是一定比自旋锁效率高？ 不一定。在明知道会有很多线程竞争的时候，偏向锁涉及到锁撤销，这时候直接用自旋锁。 JVM启动过程中，会有很多线程竞争？所以默认的时候不打开偏向锁，过一段时间再打开。 轻量级锁和重量级锁的hashcode存储在哪里？ 线程栈中，轻量级锁的LR中，或者是代表重量级锁的ObjectMonitor的成员在中。 为什么有自旋锁还要重量级锁？ 自旋锁消耗CPU资源，锁的时间太长或者自旋线程太多，CPU大量消耗 重量级锁有一个等待队列，拿不到的都在等待，不消耗CPU资源 synchronized优化的过程和mark word息息相关。 如果计算过对象的hashcode，对象无法进入偏向状态。？ 锁消除# 锁粗化# 超线程：# 一个AUL+两组Registers+PC 锁重入# 同一线程允许多次进入同一个锁对象代码块。多次进入需要记录加锁次数，后续需要多次解锁。-----上锁一次就在线程栈里记录一个LockRecord，里面有上锁时候的markword等信息。解锁一次就弹出一次。 synchronized是允许锁重入的，否则继承的时候，重写父类synchronized方法super.xxx()就死锁了。 或者递归synchronized就死锁了。 锁降级# GCThread才会去看锁对象的状态，降级。不常用 注意： 被synchronized修饰的同步块对同一条线程来说是可重入的！！！同一线程反复进入同步块也不会出现自己把自己锁死的情况。(锁计数器+1) 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前， 会无条件地阻塞后面其他线程的进入。 这意味着无法像处理某些数据库中的锁那样， 强制已获取锁的线程释放锁； 也无法强制正在等待锁的线程中断等待或超时退出。 持有锁是一个重量级（Heavy-Weight） 的操作,JDK1.6之后好一些。 测试synchronized(this)和synchronized method()：相同的，都是对象锁。一个对象只能获取一个。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import lombok.Data;import java.util.concurrent.TimeUnit;/** * Synchronized----两个方法加锁，等同于当前对象加锁，只能有一个不加锁的方法运行 */public class Synchronized2_InstanceLock &#123; public static void main(String[] args) &#123; User u = new User(); u.setName(\"sam\"); // 学习线程 Thread studyThread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u.study(); &#125; &#125;,\"study-thread\"); // 吃饭线程 Thread eatThread = new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u.eat(); &#125;,\"eat-thread\"); Thread readingThread = new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u.reading(); &#125;,\"reading-thread\"); // 方法加锁和局部代码块加锁都是一个效果：对象锁。同一个对象上的线程只能多选一 studyThread.start(); eatThread.start(); readingThread.start(); // 但不能阻塞不加锁的线程 u.speaking(); // 多个不同实例化对象的锁不会互相影响 User u2 = new User(); u2.setName(\"joe\"); new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u2.eat(); &#125;,\"u2-eat\").start(); &#125;&#125;@Dataclass User&#123; private String name; private int age; /** * 学习---加锁 */ public synchronized void study()&#123; System.out.println(name+\" start study》》》》》》\"); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name+\" end study《《《《《《《\"); &#125; // 无锁 public void speaking()&#123; System.out.println(\"I'am \"+name); &#125; /** * 吃饭---加锁 */ public synchronized void eat()&#123; System.out.println(name+\" start eat&gt;&gt;&gt;&gt;&gt;&gt;&gt;\"); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name+\" end eat&lt;&lt;&lt;&lt;&lt;&lt;&lt;\"); &#125; /** * this 锁 */ public void reading()&#123; System.out.println(\"开始等待this锁...\"); synchronized (this)&#123; System.out.println(name+\"reading------&gt;&gt;&gt;&gt;\"); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name+\" reading------&lt;&lt;&lt;&lt;\"); &#125; &#125;&#125; 输出： 可以看到sam对象同时study，eat，reading三个线程只有一个在运行，但是joe对象和sam对象无关可以并行。这就是对象锁的效果。 加在方法上和加在this上都是一样的效果。 1234567891011121314study-thread run....sam start study》》》》》》reading-thread run....eat-thread run....I&#39;am sam开始等待this锁...u2-eat run....joe start eat&gt;&gt;&gt;&gt;&gt;&gt;&gt;joe end eat&lt;&lt;&lt;&lt;&lt;&lt;&lt;sam end study《《《《《《《samreading------&gt;&gt;&gt;&gt;sam reading------&lt;&lt;&lt;&lt;sam start eat&gt;&gt;&gt;&gt;&gt;&gt;&gt;sam end eat&lt;&lt;&lt;&lt;&lt;&lt;&lt; 测试类锁和对象锁： 先看结论： 同一个对象的多个对象锁互斥（这是废话） 类锁和对象锁不互斥，对象锁上锁后，类锁可以继续获取并执行。 类锁对多个对象都是互斥的。 底层： 对象锁：是在new出来的对象的markword上放着锁信息 类锁：在类Class的markword上放着锁信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114import lombok.Data;import java.util.concurrent.TimeUnit;/** * Synchronized(XXX.class)----所有对象一起加锁 */public class Synchronized3_clazz &#123; public static void main(String[] args) &#123; User3 u = new User3(); u.setName(\"【sam】\"); // 学习线程 Thread studyThread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u.study(); &#125; &#125;,\"study-thread\"); // 吃饭线程 Thread eatThread = new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u.eat(); &#125;,\"eat-thread\"); Thread speakThread = new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u.speak(); &#125;,\"speak-thread\"); // 加锁的线程只能二选一 studyThread.start(); // 对象锁 eatThread.start(); // 类锁 speakThread.start(); // 对象锁 // 但不能阻塞不加锁的线程 // 多个不同实例化对象的锁不会互相影响，类锁会的 User3 u2 = new User3(); u2.setName(\"(joe)\"); new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+\" run....同时只能有一个线程eat...\"); u2.eat(); &#125;,\"u2-eat\").start(); new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+\" run....\"); u2.speak(); &#125;,\"u2-speak\").start(); &#125;&#125;@Dataclass User3&#123; private String name; private int age; /** * 学习---对象锁，和别的对象不冲突 */ public void study()&#123; synchronized(this)&#123; System.out.println(name+\" start study（对象锁）》》》》》》\"); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name+\" end study（对象锁）《《《《《《《\"); &#125; &#125; /**at speak-thread * 加对象锁 */ public void speak()&#123; synchronized(this)&#123; System.out.println(\"I'am \"+name+\" at \"+ Thread.currentThread().getName()+\"（对象锁）=======&gt;&gt;&gt;&gt;&gt;\"); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name+\" end speak（对象锁） =======&lt;&lt;&lt;&lt;&lt;\"); &#125; &#125; /** * 吃饭---加锁 */ public void eat()&#123; synchronized(User3.class)&#123; System.out.println(name+\" start eat(类锁)&gt;&gt;&gt;&gt;&gt;&gt;&gt;\"); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(name+\" end eat(类锁)&lt;&lt;&lt;&lt;&lt;&lt;&lt;，马上会有下一个eat\"); &#125; &#125;&#125; 输出： 可以看到sam对象锁多个之间会互斥，一个结束才能继续另一个，和上面一节的测试相同。 sam的对象锁和类锁不互斥，可以同时study和eat sam和joe的类锁互斥，sam的eat结束后joe才能eat 123456789101112131415study-thread run....【sam】 start study（对象锁）》》》》》》eat-thread run....【sam】 start eat(类锁)&gt;&gt;&gt;&gt;&gt;&gt;&gt;speak-thread run....u2-eat run....同时只能有一个线程eat...u2-speak run....I&#39;am (joe) at u2-speak（对象锁）&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;&gt;&gt;&gt;&gt;【sam】 end eat(类锁)&lt;&lt;&lt;&lt;&lt;&lt;&lt;，马上会有下一个eat(joe) end speak（对象锁） &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&lt;&lt;&lt;&lt;&lt;(joe) start eat(类锁)&gt;&gt;&gt;&gt;&gt;&gt;&gt;【sam】 end study（对象锁）《《《《《《《I&#39;am 【sam】 at speak-thread（对象锁）&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;&gt;&gt;&gt;&gt;(joe) end eat(类锁)&lt;&lt;&lt;&lt;&lt;&lt;&lt;，马上会有下一个eat【sam】 end speak（对象锁） &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&lt;&lt;&lt;&lt;&lt; DCL单例# 注意最上面的对象要加volatile，锁里面要二次检查 https://www.cnblogs.com/codingmengmeng/p/9846131.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 严格单例，而且需要的时候才创建-----&gt; Double Check Lock DCL写法 */public class DCL_Singleton &#123; /** * 这里必须要加volatle！！！！ 禁止指令重排。 * 否则线程可能在下面---new那一行发生可能指令重排: * 本来是： new-&gt;初始化参数-&gt;建立关系。 * 如果重排成为：new-&gt;建立关联-&gt;初始化参数。 * * 极端情况刚new的对象还是0值，建立了关系，正在准备初始化的时候。 * 另一个线程进来获取了，判断不为NULL(因为重排建立关系了)，直接返回。拿回去的是一个未被正确初始化的0值对象（半初始化对象） */ static volatile Object INSTANCE = null; public static Object getInstance()&#123; if(INSTANCE != null)&#123; // 别一上来就加锁，性能太差。这里绝大部分时候不用加锁。 return INSTANCE; &#125; // 使用sleep来模拟并发，下面不判断会出现多个hashcode// try &#123;// TimeUnit.SECONDS.sleep(1);// &#125; catch (InterruptedException e) &#123;// e.printStackTrace();// &#125; // 为空的时候才会加锁，只有第一次的时候加锁 synchronized (DCL_Singleton.class)&#123; if (INSTANCE == null)&#123; // 防止在上面if之后，sync之前有多个线程到达，避免多个线程依次进来创建多个实例 INSTANCE = new Object(); // --------------new &#125; &#125; return INSTANCE; &#125; //--------------------测试 // 记录对象个数 static volatile Set&lt;Integer&gt; hashCodes = Collections.synchronizedSet(new HashSet&lt;&gt;()); // 记录创建次数 static volatile AtomicInteger cnt = new AtomicInteger(); public static void main(String[] args) &#123; // 测试，创建10w个对象，看看hashcode是不是都一样。使用sleep加剧并发。 for (int i = 0; i &lt; 1000; i++) &#123; new Thread(()-&gt;&#123; for (int j = 0; j &lt; 1000; j++) &#123; hashCodes.add(getInstance().hashCode()); cnt.getAndIncrement(); &#125; &#125;).start(); &#125; while(Thread.activeCount() &gt; 2)&#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"创建对象个数：\"+cnt.get()); System.out.println(\"hash code数量=\"+hashCodes.size()); &#125;&#125; 线程基础# 创建线程的方式：# Thread/Runnable/Callable-Futrue/ExcutorServices 一共有六种状态 NEW RUNNABLE WATING TIMED_WATING BLOCKED TERMINATED ObjectMonitor：# 每一个对象都有一个与之对应的监视器 每一个监视器里面都有一个该对象的锁和一个等待队列和一个同步队列 锁升级是通过ObjectMonitor监视器实现的。路径是new-偏向锁-轻量级所（无锁、自旋锁、自适应锁）-重量级锁 notify()方法也是一样的，用来唤醒一个线程，你要去唤醒，首先你得知道他在哪儿，所以必须先找到该对象，也就是获取该对象的锁，当获取到该对象的锁之后，才能去该对象的对应的等待队列去唤醒一个线程。 ObjectMonitor：里面有waiteSet等待的线程集合，_count重入数量，entryList处于等待状态的线程双向链表。 Wait/Notify# wait方法要放在锁里面！！！# thread.join的底层是基于wait/notify实现的。wait方法来自Object，是Native的C++方法。 1234567891011121314151617181920212223242526272829303132333435/**等待一定的时间，等不到就挂，传入0则永久等待。 * Waits at most &#123;@code millis&#125; milliseconds for this thread todie. A timeout of &#123;@code 0&#125; means to wait forever. * 使用了一个循环去调用是否还或者isAlive(),如果被调用了notifyAll，wait的线程就终止了。 * &lt;p&gt; This implementation uses a loop of &#123;@code this.wait&#125; calls * conditioned on &#123;@code this.isAlive&#125;. As a thread terminates the * 重点，推荐线程对象(Thread对象)不要使用wait/notify或者notifyAll在线程对象上。 * &#123;@code this.notifyAll&#125; method is invoked. It is recommended that * applications not use &#123;@code wait&#125;, &#123;@code notify&#125;, or * &#123;@code notifyAll&#125; on &#123;@code Thread&#125; instances. **/public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125; &#125; wait的实现：# JVM的wait，都会走ObjectMonitor#wait()，调用的时候会把当前线程包装成一个C++的ObjectWaiter对象丢到ObjectMonitor._waitSet（等待队列）里面。会调用park挂起线程。所以： 首先wait的语义就是让这个对象上的线程等待， wait首先需要获取当前对象锁 然后当前线程放到wait对象的阻塞队列 这些操作都是与监视器相关的，当然要指定一个ObjectMonitor监视器才能完成这个操作 Notify的实现：# 唤起的时候，去waitset里面拿到这个线程，给他unpark。 为啥要放到synchronized里面？否则会抛出 IllegalMonitorStateException？# 因为wait的时候要放到ObjectMonitor的等待队列里面，notify的时候要从ObjectMonitor里面拿出来 callable/futrue# 常见问题QA# synchronized和ReentrantLock有什么区别？# synchronized ReentrantLock Java关键字，隐式释放 Lock接口的实现类，手动获取，finally中释放。（可中断/超时） 1.6后有优化，一系列锁升级过程，最终是重量级。底层是’lock cmpchg’汇编 基于AQS实现，底层是CAS 独占式，性能相对低 可以非独占，可以读写锁分离（共享锁） 多变量加锁 单变量加锁 被动 主动性高 避免死锁：# 死锁就是两个线程互相持有一个锁，都在等待对方的一个锁释放。 避免一个线程同时获取多个锁。（最有效的方法） 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况 并发一定会提高效率？# No，要考虑资源限制。比如网络带宽、磁盘IO、CPU能力等资源的限制下即使再多的线程也无济于事，还会因为线程切换带来额外开销。 对于硬件限制可以考虑将进程分到多个机器的集群，最终计算结果聚合。 对于软件的限制，考虑使用连接池、线程池、长连接。 资源限制条件下：调整并法度，如下载依赖于网速和磁盘读写。不超过CPU线程数等。 实现# 打开偏向锁效率一定高么？ 不一定，当很多线程争抢的时候，偏向锁还需要一个锁撤销的过程，把当前线程ID拿掉，效率反而低。 比如JVM启动的时候底层会有多线程竞争，这时候直接上轻量级锁，所以延迟4s才会启动偏向锁。 类加载技术的半加载技术 新生代到你老年代CMS默认6代，PS+PO、G1 默认15，mark word里4位最大16 频繁FGC， https://juejin.im/post/5ea4f5596fb9a03c6a41881a","categories":[{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"深入理解woe和iv","slug":"深入理解woe和iv指标","date":"2018-01-14T03:10:14.000Z","updated":"2020-05-27T11:02:12.351Z","comments":true,"path":"article/woe-iv.html","link":"","permalink":"https://blog.sofunnyai.com/article/woe-iv.html","excerpt":"","text":"WOE(Weight of Evidence) 证据权重 WOE的定义 Woe公式理解 WOE回顾： IV值：可以认为是WOE的加权 计算woe和IV的步骤 计算注意点 WOE和IV的比较----为什么不用WOE，而是用IV值 通用WOE计算实现 WOE(Weight of Evidence) 证据权重# https://blog.csdn.net/kevin7658/article/details/50780391 https://zhuanlan.zhihu.com/p/80134853 https://www.cnblogs.com/hanxiaosheng/p/9831838.html https://www.cnblogs.com/hanxiaosheng/p/9831964.html https://blog.csdn.net/PbGc396Dwxjb77F2je/article/details/99687952 WOE的定义# WOE是一种对原始自变量进行编码的格式，可以屏蔽极值增强鲁棒性。（树模型一般只对离散变量进行编码，对极值不敏感） 要对一个变量进行WOE编码，需要首先把这个变量进行分组处理/离散化处理（等宽切割，等频切割，卡方分箱，或者利用决策树来切割）。 分组后，对于第i组，WOE的计算公式如下： woei=lnpyipni=lnpy1py0=ln(BadiBad/GoodiGood)=ln(BadiBad)−ln(GoodiGood)woe_i = ln\\frac{p_{yi}}{p_{ni}} = ln\\frac{p_{y1}}{p_{y0}} = ln(\\frac{Bad_i}{Bad}/\\frac{Good_i}{Good}) = ln(\\frac{Bad_i}{Bad})-ln(\\frac{Good_i}{Good}) woe​i​​=ln​p​ni​​​​p​yi​​​​=ln​p​y0​​​​p​y1​​​​=ln(​Bad​​Bad​i​​​​/​Good​​Good​i​​​​)=ln(​Bad​​Bad​i​​​​)−ln(​Good​​Good​i​​​​) 其中：pyi为坏样本占所有坏样本的比例，py0好样本占所有好样本的比例； Bad为坏样本总数，Badi为变量i对应的坏样本个数，Good为好样本总数，Goodi为变量i对应的好样本个数 ； 将模型目标变量y为1记为违约用户（坏样本），对于目标变量为0记为正常用户（好样本） Woe公式理解# 基础模式 woei=ln(BadiBad)−ln(GoodiGood) woe_i = ln(\\frac{Bad_i}{Bad})-ln(\\frac{Good_i}{Good}) woe​i​​=ln(​Bad​​Bad​i​​​​)−ln(​Good​​Good​i​​​​) 即 WOE = ln (第i个分箱的坏人数 / 总坏人数) - ln (第i个分箱的好人数 / 总好人数) 此时可以理解为：每个分箱里的坏人(响应)分布相对于好人(未响应)分布之间的差异性。 变换模式 woei=ln(BadiGoodi)−ln(BadGood)woe_i = ln(\\frac{Bad_i}{Good_i})-ln(\\frac{Bad}{Good}) woe​i​​=ln(​Good​i​​​​Bad​i​​​​)−ln(​Good​​Bad​​) WOE = ln (第i个分箱的坏人数 / 第i个分箱的好人数) - ln (总坏人数 / 总好人数) 此时可以理解为：每个分箱里的坏好比(Odds)相对于总体的坏好比之间的差异性。 WOE回顾：# 当前分组中，差异越大，响应的比例越大，WOE值越大； 反应的是特征的重要性，woe的绝对值越大，说明越重要。 当前分组WOE的正负，由当前分组响应和未响应的比例，与样本整体响应和未响应的比例的大小关系决定，当前分组的比例小于样本整体比例时，WOE为负，当前分组的比例大于整体比例时，WOE为正，当前分组的比例和整体比例相等时，WOE为0。 WOE的取值范围是全体实数。(所以就不方便，需要IV缩放) WOE其实描述了变量当前这个分组，对判断个体是否会响应（或者说属于哪个类）所起到影响方向和大小，当WOE为正时，变量当前取值对判断个体是否会响应起到的正向的影响，当WOE为负时，起到了负向影响。而WOE值的大小，则是这个影响的大小的体现。 做完woe之后，LR系数不再代表特征的重要程度。 woe后LR的时候要保证系数全都是正数！ woe的符号代表特征对模型贡献的方向，系数如果不是正数就会改变这个方向。 但是做BiVar的时候已经分析了这个woe特征的贡献方向，如果LR再负数会扭曲推翻之前BiVar的分析。 优点：数值型转化为WOE可以增强鲁棒性，屏蔽极值的影响（极小值和极大值也被分组了） 但是树模型对极值不敏感，只用处理字符型即可 note：如果特征做了WOE，那么LR的系数不能代表特征重要性权重。（WOE绝对值大小已经是特征重要性了，LR的系数仅仅是拟合系数而已） woe后**如果是LR的时候要保证系数全都是正数！ **woe的符号代表特征对模型贡献的方向，系数如果不是正数就会改变这个方向。 但是做BiVar的时候已经分析了这个woe特征的贡献方向，如果LR再负数会扭曲推翻之前BiVar的分析。 核心——分箱逻辑： 实现WOE最重要的是分箱逻辑，不同的分箱会带来不同的WOE。金融常使用“基于负样本占比差异最大化”原则来分箱 一般是5箱内最好，通常最多不超过10箱 每一箱的负样本占比差值尽可能大（箱合并原则） 每一箱的样本量不少于总体5%（不要太小，不要小于三五百个样本） 通过控制划分后的总箱数，来迭代进行分箱合并 IV值：可以认为是WOE的加权# 某个分箱的IV值： IVi=(pyi−pni)∗WOEi=(BadiBadt−GoodiGoodt)∗WOEi=(BadiBadt−GoodiGoodt)∗ln(BadiBadt/GoodiGoodt)IV_i =(p_{yi}-p_{ni}) * WOE_i= (\\frac{Bad_i}{Bad_t}-\\frac{Good_i}{Good_t}) * WOE_i = (\\frac{Bad_i}{Bad_t}-\\frac{Good_i}{Good_t}) * ln(\\frac{Bad_i}{Bad_t}/\\frac{Good_i}{Good_t}) IV​i​​=(p​yi​​−p​ni​​)∗WOE​i​​=(​Bad​t​​​​Bad​i​​​​−​Good​t​​​​Good​i​​​​)∗WOE​i​​=(​Bad​t​​​​Bad​i​​​​−​Good​t​​​​Good​i​​​​)∗ln(​Bad​t​​​​Bad​i​​​​/​Good​t​​​​Good​i​​​​) 有了一个变量各分组的IV值，我们就可以计算整个变量的IV值： IV=∑inIViIV = \\sum_i^n{IV_i} IV=​i​∑​n​​IV​i​​ n是分箱的数量 对于变量的一个分组，这个分组的响应和未响应的比例与样本整体响应和未响应的比例相差越大，IV值越大，否则，IV值越小； 极端情况下，当前分组的响应和未响应的比例和样本整体的响应和未响应的比例相等时，IV值为0； IV值的取值范围是[0,+∞) ，且，当当前分组中只包含响应客户或者未响应客户时，IV = +∞。 故可以计算多个特征的IV值，按照从大到小排序来决定采用哪些特征更容易响应。（类似信息增益或者基尼指数的感觉） IV比如要大于0.05才比较好用 谨慎的时候会要求IV大于0.02就可以先留着，也就是说IV在0.02-0.5之间 超过0.5的特征会被直接拿去作为策略-------------&gt;IV太大的值可能会把模型其他特征的信息覆盖掉，也可能会造成过拟合。（如果这个特征以后抖动，造成线上效果波动） 计算woe和IV的步骤# step 1. 对于连续型变量，进行分箱（binning），可以选择等频、等距，或者自定义间隔；对于离散型变量，如果分箱太多，则进行分箱合并。 step 2. 统计每个分箱里的好人数(bin_goods)和坏人数(bin_bads)。 step 3. 分别除以总的好人数(total_goods)和坏人数(total_bads)，得到每个分箱内的边际好人占比(margin_good_rate)和边际坏人占比(margin_bad_rate)。 step 4. 计算每个分箱里的WOE [公式] step 5. 检查每个分箱（除null分箱外）里woe值是否满足单调性（bivar），若不满足，返回step1。注意⚠️：null分箱由于有明确的业务解释，因此不需要考虑满足单调性。 step 6. 计算每个分箱里的IV，最终求和，即得到最终的IV。 备注：好人 = 正常用户，坏人 = 逾期用户 计算注意点# 分箱时需要注意样本量充足，保证统计意义。 若相邻分箱的WOE值相同(非常相近)，则将其合并为一个分箱。 当一个分箱内只有好人或坏人时（会出现∞），可对WOE公式进行修正如下： Woei=ln(Badi+0.5Badt+0.5/GoodiGoodt)Woe_i = ln(\\frac{Bad_i+0.5}{Bad_t+0.5}/\\frac{Good_i}{Good_t}) Woe​i​​=ln(​Bad​t​​+0.5​​Bad​i​​+0.5​​/​Good​t​​​​Good​i​​​​) 在实践中，我们还需跨数据集检验WOE分箱的单调性。如果在训练集上保持单调，但在验证集和测试集上发生翻转而不单调，那么说明分箱并不合理，需要再次调整。（BIVAR） 或者当分箱中只有好人或坏人的时候，也可以这么做： 如果可能，直接把这个分组做成一个规则，作为模型的前置条件或补充条件；（即不允许这种分箱存在） 重新对变量进行离散化或分组，使每个分组的响应比例都不为0且不为100%，尤其是当一个分组个体数很小时（比如小于100个），强烈建议这样做，因为本身把一个分组个体数弄得很小就不是太合理。 如果上面两种方法都无法使用，建议人工把该分组的响应数和非响应的数量进行一定的调整。如果响应数原本为0，可以人工调整响应数为1，如果非响应数原本为0，可以人工调整非响应数为1.（或者按照上面进行修正，分子分母都加0.5） WOE和IV的比较----为什么不用WOE，而是用IV值# 变量各分组的WOE和IV都隐含着这个分组对目标变量的预测能力这样的意义，但是有以下问题： 1. 各个组的WOE有正有负 解释： 假设构造一个$ WOE=\\sum_i^n{WOE_i} ，那么因为里面的WOE_i$有正有负，所以求和不好表征。 2.每个组的WOE没有考虑到这个各个组在总体的占比 解释： 即使构造一个WOE=∑in∣WOEi∣WOE=\\sum_i^n{|WOE_i|}WOE=∑​i​n​​∣WOE​i​​∣规避上面的负数问题，但是每个组WOEiWOE_iWOE​i​​的信息含量（泛化能力？）是不相同的，比如某个组WOEiWOE_iWOE​i​​很高但是这个组只有很少的样本，把他直接和另外一个很多样本但很低的WOEjWOE_jWOE​j​​相加是很不合适的。 假设某特征A分两组，从这个表我们可以看到，变量取1时，响应比达到90%，对应的WOE很高，但对应的IV却很低，原因就在于IV在WOE的前面乘以了一个系数(pyi−pni)(p_{yi}-p_{ni})(p​yi​​−p​ni​​) 而这个系数很好的考虑了这个分组中样本占整体样本的比例，比例越低，这个分组对变量整体预测能力的贡献越低。 相反，如果直接用WOE的绝对值加和，会得到一个很高的指标，这是不合理的。 通用WOE计算实现# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187# -*- coding: utf-8 -*-import mathimport pandas as pdimport numpy as npfrom pandas import DataFramefrom pandas.core.dtypes import dtypesfrom pandas.core.dtypes.common import is_numeric_dtypefrom sklearn.linear_model import LogisticRegressionfrom sklearn.tree import DecisionTreeRegressor# 自定义实现的离散型变量woeclass charWoe(object): def __init__(self, datases: dict, dep, weight, vars: list): # 数据字典&#123;'dev':xxx,'val':xxx,'off':xxx&#125; 训练集，测试集，时间外样本集 3个dataframe self.datases = datases self.devf = datases.get('dev', '') self.valf = datases.get('val', '') self.offf = datases.get('off', '') self.dep = dep # 标签 self.weight = weight # 样本权重 self.vars = vars # 特征名 self.nrows, self.ncols = self.devf.shape # 样本数，特征数 def char_woe(self): # 得到每一类样本的个数，且加入平滑项是的bad和good都不为0 dic = dict(self.devf.groupby(self.dep).size()) # 根据标签去group，变成&#123;1:xxx,0:yyy&#125;字典 good = dic.get(0, 0) + 1e-10 # 平滑防止组内为0，计算失败 bad = dic.get(1, 0) + 1e-10 # 对每一个特征进行处理 for col in self.vars: # df[[sex,bad]].groupby(['sex','bad']).size() 会得到一个series， # 直接转成字典：&#123;(男, 0): 10553, (男, 1): 518, (女, 0): 233, (女, 1): 3&#125; # key的第一个代表特征值，第二个代表标签值 data = dict(self.devf[[col, self.dep]].groupby([col, self.dep]).size()) ''' 特征值+分类组合超过100的时候，跳过当前取值 假设二分类，dep是0,、1，则这个特征只能有50个特征值 &#123;(col特征值A,0):25,(col特征值A,1):10,(col特征值B,0):33,(col特征值B,1):21...&#125; 因为特征值过多时，WOE分箱效率低，建议进行特征截断 出现频率过低的特征就统一赋值，放到同一个箱里 ''' if len(data) &gt; 100: print(col, '有太多的特征值，建议手动进行特征截断，即将跳过此特征...') continue # 打印特征取取值个数 print('特征【%s】的取值个数是【%d】' % (col, len(data))) dic = dict() # &#123;(男, 0): 10553, (男, 1): 518, (女, 0): 233, (女, 1): 3&#125; # key的第一个代表特征值，第二个代表标签值 for (k, v) in data.items(): fea_value, dp = k # 拿出key中的特征值和标签(fea_value=男，dp=0，v=10553) dic.setdefault(fea_value, &#123;&#125;) # 给对应key设置为一个空字典（如果没有找到的话，找到的话说明之前已经设置过了） #&#123;(男, 0): 10553, (男, 1): 518&#125; ==&gt; &#123;男:&#123;1 = 518，0 = 10553&#125; , 女:&#123;...&#125; &#125; dic[fea_value][int(dp)] = v # 字典中嵌套字典 for(k, v) in dic.items(): # 计算cnt和badrate # 循环上面的嵌套字典，k=男，v=&#123;1 = xxx，0 = yyy&#125;。 # 拿出内部嵌套的字典k1 = 1 v1=xxx,生成---&gt;：&#123;‘男’：&#123; '0': 10553, '1': 518&#125;&#125; dic[k] = &#123;str(int(k1)):v1 for (k1, v1) in v.items()&#125; # 所有正负样本的和v.values(): [10553,518] dic[k]['cnt'] = sum(v.values()) # 4舍5入求bad_rate bad_rate = round(v.get(1,0)/dic[k]['cnt'], 5) dic[k][\"bad_rate\"] = bad_rate # 利用定义的函数进行合并分箱。 dic=&#123;'男': &#123;'cnt': xxx, '0': yy, '1': zz, 'bad_rate': 0.xx&#125;, 'B': &#123;'cnt': xxx, '0': yyy, '1': zz, 'bad_rate': 0.zz&#125;&#125; dic = self.combine_box_char(dic) # 对每个特征计算WOE和IV值 for (k,v) in dic.items(): a = v.get('0', 1) / good+1e-10 b = v.get('1', 1) / bad+1e-10 dic[k]['Good'] = v.get('0',0) dic[k]['Bad'] = v.get('1',0) # 下面两个是 a/b 还是 b/a？ 按照定义应该是ln(pi/pn) = ln(p_bad/p_good)? dic[k]['woe'] = round(math.log(b/a),5) dic[k]['iv'] = round((b-a)*dic[k]['woe'],5) ''' 按照分箱后的点进行分割， 计算得到每一个特征值的WOE值， 将原始特征名加上'_woe'后缀，并赋予WOE值。 ''' for (klis, v) in dic.items(): # 把分箱合并后的key切开 for k in str(klis).split(','): # 数字类型处理一下 if is_numeric_dtype(self.devf[col]): k = float(k) if '.' in k else int(k) # 训练集进行替换 self.devf.loc[self.devf[col] == k, \"%s_woe\" % col] = v[\"woe\"] self.devf.loc[self.devf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 测试集进行替换 if not isinstance(self.valf, str): self.valf.loc[self.valf[col] == k,\"%s_woe\" % col] = v[\"woe\"] self.valf.loc[self.valf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 跨时间验证集进行替换 if not isinstance(self.offf, str): self.offf.loc[self.offf[col] == k,\"%s_woe\" % col] = v[\"woe\"] self.offf.loc[self.offf[col] == k, \"%s_iv\" % col] = v[\"iv\"] # 返回新的字典，其中包含三个数据集。 return &#123;\"dev\": self.devf, \"val\": self.valf, \"off\": self.offf&#125; def combine_box_char(self, dic): ''' 实施两种分箱策略（规则）： 1.不同箱之间负样本占比(bad_rate)差异最大化。----各个特征值按照badrate从小到大排序，分别用后面一个减去前面每一个，计算badrate差值。找到差值最小的两箱合并之 2.每一箱的样本量不能过少。----当有某箱样本小于总样本的0.05，或总箱数&gt;5的时候，还是按照badrate差异最大化原则：按badrate排序后，把最小的一箱和前后比较，与差值较小的一箱合并 :param dic: 等待分箱的数据 :return: ''' # 首先合并至10箱以内。按照每一箱负样本占比差异最大化原则进行分箱。----各个特征值按照badrate从小到大排序，分别用后面一个减去前面每一个，计算badrate差值。找到差值最小的两箱合并之 while len(dic) &gt;= 10: # 拿出所有的特征和badrate，k是特征值，v['bad_rate']是负样本占比 bad_rate_dic = &#123;k:v['bad_rate'] for (k,v) in dic.items()&#125; # 按照负样本占比排序。因为离散型变量是无序的（比如学历、渠道类型） # 可以直接写成负样本占比递增的形式。(所有的dict按照value升序排序) # 得到一堆tuple的list，是(特征值，bad_rate)的一个list bad_rate_sorted = sorted(bad_rate_dic.items(), key=lambda x: x[1]) # 计算每两箱之间的负样本占比差值。 bad_rate_diff = [bad_rate_sorted[i + 1][1] - bad_rate_sorted[i][1] for i in range(len(bad_rate_sorted) - 1)] # 找到差值最小的那个，准备将其进行合并。 min_diff_index = bad_rate_diff.index(min(bad_rate_diff)) # 找到k1和k2，即差值最小的两箱的key. k1, k2 = bad_rate_sorted[min_diff_index][0], bad_rate_sorted[min_diff_index + 1][0] # 得到重新划分后的字典，箱的个数比之前少一 直接改了dic，给他里面插入一个新的分箱。key是两个key的组合！ dic[\"%s,%s\" % (k1, k2)] = dict() # 重新统计新箱的正负样本数（合并两个key的） dic[\"%s,%s\" % (k1, k2)][\"0\"] = dic[k1].get(\"0\", 0) + dic[k2].get(\"0\", 0) dic[\"%s,%s\" % (k1, k2)][\"1\"] = dic[k1].get(\"1\", 0) + dic[k2].get(\"1\", 0) # 重新统计新箱的cnt dic[\"%s,%s\" % (k1, k2)][\"cnt\"] = dic[k1][\"cnt\"] + dic[k2][\"cnt\"] # 重新计算新分箱的bad_rate dic[\"%s,%s\" % (k1, k2)][\"bad_rate\"] = round(dic[\"%s,%s\" % (k1, k2)][\"1\"] / dic[\"%s,%s\" % (k1, k2)][\"cnt\"],5) # 删除之前两个老的分箱 del dic[k1], dic[k2] ''' 结束循环后，箱的个数应该少于10。 下面实施第二种分箱策略规则：每个分箱的样本不能太少！ 将样本数量少的箱合并至其他箱中，以保证每一箱的样本数量不要太少。 ''' # 找出最少样本数的分箱 min_cnt = min([v['cnt'] for (k, v) in dic.items()]) # 当样本数量小于总样本的5%或者总箱的个数大于5的时候，对箱进行合并 【这里的5% 和 5是经验值】 while min_cnt &lt; self.nrows*0.05 or len(dic) &gt; 5: # 可能找到多个符合min_cnt的list，取第一个 min_key = [k for (k,v) in dic.items() if v['cnt'] == min_cnt][0] bad_rate_dic = &#123;k:v['bad_rate'] for (k,v) in dic.items()&#125; # 根据bad_rate升序 bad_rate_sorted = sorted(bad_rate_dic.items(),key=lambda x:x[1]) keys = [item[0] for item in bad_rate_sorted] min_key_index = keys.index(min_key) ''' 不能直接把样本数最小的两个分箱合并，因为 同样想保持合并后箱之间的负样本占比差异最大化。 由于箱的位置不同，按照三种不同情况进行分类讨论。 ''' # 如果是第一箱、第二箱 if min_key_index == 0: k1,k2 = keys[:2] elif min_key_index == len(keys)-1: # 如果是最后一箱，和倒数第二箱合并 k1,k2 = keys[-2:] else: # 如果是中间箱，前后相比和bad_rate值相差最小的箱合并 # 和前面的比 bef_bad_rate = dic[min_key]['bad_rate'] - dic[keys[min_key_index-1]]['bad_rate'] # 后面的当前比（keys是按照bad_rate升序的，不减出负数） aft_bad_rate = dic[keys[min_key_index+1]]['bad_rate'] - dic[min_key]['bad_rate'] if bef_bad_rate &lt;= aft_bad_rate: k1,k2 = keys[min_key_index-1], min_key else: k1,k2 = min_key, keys[min_key_index+1] # 找到k1，k2后合并之，同上 # 新增一个合并后的分箱 dic[\"%s,%s\" % (k1, k2)] = dict() # 重新计算cnt，bad_rate，正负样本数 dic[\"%s,%s\" % (k1, k2)][\"0\"] = dic[k1].get(\"0\", 0) + dic[k2].get(\"0\", 0) dic[\"%s,%s\" % (k1, k2)][\"1\"] = dic[k1].get(\"1\", 0) + dic[k2].get(\"1\", 0) dic[\"%s,%s\" % (k1, k2)][\"cnt\"] = dic[k1][\"cnt\"] + dic[k2][\"cnt\"] dic[\"%s,%s\" % (k1, k2)][\"bad_rate\"] = round(dic[\"%s,%s\" % (k1, k2)][\"1\"] /dic[\"%s,%s\" % (k1, k2)][\"cnt\"], 5) # 删除旧的分箱 del dic[k1], dic[k2] # 重新计算当前最小的箱的样本个数，进入下次循环继续合并分箱 min_cnt = min([v[\"cnt\"] for v in dic.values()]) return dic","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"},{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"}]},{"title":"模型评价指标KS和PSI","slug":"风控模型指标ks和psi","date":"2018-01-12T05:21:10.000Z","updated":"2020-05-25T11:57:12.481Z","comments":true,"path":"article/ks_psi.html","link":"","permalink":"https://blog.sofunnyai.com/article/ks_psi.html","excerpt":"","text":"概述 ROC曲线 回顾混淆矩阵的TPR(True Positive Rate)和FPR(False Positive Rate) ROC曲线 ROC曲线理解 KS指标 KS值定义 模型的KS值 KS(Kolmogorov-Smirnov)计算步骤： KS和ROC的区别 模型评价时: PSI群体稳定性指标 PSI(Population Stability Index)的定义 计算举例： toad底层的PSI实现 Gini指数 捕获率capture rate 减少过拟合方法： 概述# 风控指标千千万，三句话概括版本： Confusion Matrix -&gt; Lift，Gain，ROC。 ROC -&gt; AUC，KS -&gt; GINI。 MSE独立出来。 ROC曲线# 回顾混淆矩阵的TPR(True Positive Rate)和FPR(False Positive Rate)# 混淆矩阵，横着的P、N是预测结果阳性还是阴性。竖着的是说预测是否正确。 Positive Negtive T TP TN F FP FN TP：预测为正向（P），实际上预测正确（T），即判断为正向的正确率 TN：预测为负向（N），实际上预测正确（T），即判断为负向的正确率 FP：预测为正向（P），实际上预测错误（F），误报率，即把负向判断成了正向 FN：预测为负向（N），实际上预测错误（F），漏报率，即把正向判断称了负向 准确率Accuracy=（TP+TN） / （TP+FP+TN+FN）， 即预测正确的比上全部的数据 精确率、查准率 Precision=TP / （TP+FP），即在预测为正向的数据中，有多少预测正确了 召回率、查全率 Recall=TP / （TP+FN），即在所有正向的数据中，有多少预测出来了 TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。(就是召回率，正样本被召回的比例) 【金融里面，分母是所有的good_cnt】 Recall=TPR=TPTP+FNRecall = TPR = \\frac{TP}{TP+FN} Recall=TPR=​TP+FN​​TP​​ FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。（就是漏掉的阴性或判断错的阳性，占总阴性的比例) 【金融里面，分母是所有的bad_cnt】 FPR=FPFP+TNFPR = \\frac{FP}{FP + TN} FPR=​FP+TN​​FP​​ 更多关于TPR： /02_ml/01_THEORY/00_theory.ipynb#TPR(True-Positive-Rate) ROC曲线# 在一个二分类模型中，假设采用逻辑回归分类器，其给出针对每个实例为正类的概率，那么通过设定一个阈值如0.6，概率大于等于0.6的为正类，小于0.6的为负类。对应的就可以算出一组(FPR,TPR)，在平面中得到对应坐标点。随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着真正的负实例，即TPR和FPR会同时增大。阈值最大时，对应坐标点为(0,0)，阈值最小时，对应坐标点(1,1)。 如下面这幅图，(a)图中实线为ROC曲线，线上每个点对应一个阈值。纵坐标TPR，横坐标FPR。 (a) 理想情况下，TPR应该接近1，FPR应该接近0。ROC曲线上的每一个点对应于一个threshold，对于一个分类器，每个threshold下会有一个TPR和FPR。比如Threshold最大时，TP=FP=0，对应于原点；Threshold最小时，TN=FN=1，对应于右上角的点(1,1)。 (b) P和N得分不作为特征间距离d的一个函数，随着阈值theta增加，TP和FP都增加。 横轴FPR：1-TNR，1-Specificity，FPR越大，预测正类中实际负类越多。 纵轴TPR：Sensitivity(正类覆盖率)，TPR越大，预测正类中实际正类越多。 理想目标：TPR=1，FPR=0，即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。 ROC曲线理解# 主要是关于阈值的理解 roc_curve里面有一个阈值数组，里面的原理： 先按照概率值逆序排序 计算排序后所有前后之间的概率差 得到的差值数组里面有很多为0的（排序后前后概率相同），丢掉 源码里还根据二阶导数判断拐点 剩下的作为阈值数组 以上面的阈值数组下标为界，数所有label为1,0的样本【累计值】(cumsum)为tps和fps数组（有权加权） 数组tps除以最后一个tps[-1]得到tpr，fpr同理。（这里并没有判断概率值是否大于或者小于0.5，因为排序后此处这个概率值就是阈值，概率值大于这个阈值的里面，所有的+就是TP，所有的-就是FP。对应tps[i]和fps[i]） 这样计算出来的tpr 、fpr数组比原始样本数少很多（因为阈值的原因），具体理解如下 如果大家对二值分类模型熟悉的话，都会知道其输出一般都是预测样本为正例的概率，而事实上，ROC曲线正是通过不断移动分类器的“阈值”来生成曲线上的一组关键点的。可能这样讲有点抽象，还是举刚才雷达兵的例子。每一个雷达兵用的都是同一台雷达返回的结果，但是每一个雷达兵内心对其属于敌军轰炸机的判断是不一样的，可能1号兵解析后认为结果大于0.9，就是轰炸机，2号兵解析后认为结果大于0.85，就是轰炸机，依次类推，每一个雷达兵内心都有自己的一个判断标准（也即对应分类器的不同“阈值”），这样针对每一个雷达兵（样本输出），都能计算出一个ROC曲线上的关键点（一组FPR,TPR值），把大家的点连起来，也就是最早的ROC曲线了。 为方便大家进一步理解，本菇也在网上找到了一个示例跟大家一起分享【4】。下图是一个二分模型真实的输出结果，一共有20个样本，输出的概率就是模型判定其为正例的概率，第二列是样本的真实标签。 现在我们指定一个阈值为0.9，那么只有第一个样本（0.9）会被归类为正例，而其他所有样本都会被归为负例 因此，对于0.9这个阈值，我们可以计算出FPR为0，TPR为0.1（因为总共10个正样本，预测正确的个数为1），那么我们就知道曲线上必有一个点为(0, 0.1)。 依次选择不同的阈值（或称为“截断点”），画出全部的关键点以后，再连接关键点即可最终得到ROC曲线如下图所示。 sklearn中的绘制原理：（SolveKS和roc_curve代码中）# 其实还有一种更直观的绘制ROC曲线的方法，这边简单提一下。： 就是把横轴的刻度间隔设为1/N，纵轴的刻度间隔设为1/P，N和P分别为负样本与正样本数量。 然后再根据模型的输出结果【概率降序】排列， 依次遍历样本，从0开始绘制ROC曲线，每遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线， 每遇到一个负样本就沿横轴方向绘制一个刻度间隔的曲线，遍历完所有样本点以后，曲线也就绘制完成了。 究其根本，其最大的好处便是不需要再去指定阈值寻求关键点了，每一个样本的输出概率都算是一个阈值了。当然，无论是工业界还是学术界的实现，都不可能手动去绘制，下面就来讲一下如何用Python高效绘制ROC曲线。 KS指标# KS值定义# 模型的KS值# 最理想的模型，是TPR尽量高而FPR尽量低（召回尽可能多的坏人，漏掉尽可能少的好人），然而任何模型在提高正确预测概率的同时，也会难以避免地增加误判率。 我们训练出来的模型，一般不是直接给出是正类还是负类的结果，给的是为正类的概率，我们还需要选择一个阈值，实例通过模型得到的概率大于阈值，判断为正类，小于阈值判断为负类。也就是说阈值的不同，以上的各个指标的值也是不同的。每一个阈值对应一对TPR和FPR。把阈值看成自变量，以上TPR、和FPR看成因变量，在二维坐标系里面做∣FPT−FPR∣|FPT-FPR|∣FPT−FPR∣关系曲线，这就是KS曲线。 KS曲线实操的时候是可以把将概率的阈值从小到大进行排序，取10%的值为间隔， 同理将10%*k(k=1,…9)处值作为阈值，计算不同的FPR和TPR， 以10%*k（k=1,…9）为横坐标，同时分别以TPR和FPR为纵坐标画出两条曲线就是KS曲线。 KS值是KS曲线的最大值，也就是TPR和FPR差异的最大点 KS值=max(|TPR-FPR|) KS值是在模型中用于区分预测正负样本分隔程度的评价指标。 需要计算每一箱的KS，然后max是在所有分箱的KS上取最大值 一般来说，KS大比较好。但是也不是越大越好，尤其征信行业 业内认为AUC更能体现模型的【整体的】区分能力，但是KS关注的是区分能力的最大值。 我们做的是拒绝模型，关注的是最大值的点取在哪里的。会做一个截断，小于这个值的都拒绝了。关注在最大值之前误杀了多少人。（相比于AUC注重局部而不是全局） KS(Kolmogorov-Smirnov)计算步骤：# KS用于模型风险区分能力进行评估，指标衡量的是好坏样本累计分部之间的差值。 好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强。 KS的计算步骤如下： 计算每个评分区间的好坏账户数。 计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的K-S值。 KS值：是和AUC强相关的，但是样本很小的时候KS大，AUC不一定大。 A卡的KS： 714那种最差的一般也至少要25%， 正常的p2p公司，客户质量稍微好一点会到30%-40%左右。 最好那些有场景的分期产品最多也就不到50%，所以一般是在25%-50%之间。 B卡的KS： 至少也有40%，最高80% 一般60%左右。 各个数据集如dev和oft的KS差值不要太大，否则模型不稳定，跨时间稳定性差。 一般dev和oft的KS差值只能在5%以内，比较求稳的公司要求在3%以内。 正负样本： 逾期样本/正常样本=1%-5%（也有能做到1/1000的） 5%个点就是比较高的了，是很不均衡的。 要是坏账5%，会亏很多钱。badrte 3%以下才可能赚钱。 欺诈样本/正常样本=1/10w 欺诈用户是极少的 https://www.zhihu.com/question/37405102/answer/106668941 KS和ROC的区别# KS值对模型的评价不受样本不均衡问题的干扰，但仅限于模型评价。 模型评价时:# ROC曲线# 描绘的是不同的截断点（判断好人坏人的阈值）时，以FPR和TPR为横纵坐标轴，描述随着截断点的变化，TPR随着FPR的变化。 纵轴：TPR=正例分对的概率 = TP/(TP+FN)，其实就是查全率 横轴：FPR=负例分错的概率 = FP/(FP+TN) 作图步骤： 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）-----这就是截断点依次选取的顺序 按顺序选取截断点，并计算TPR和FPR—也可以只选取n个截断点，分别在1/n，2/n，3/n等位置 连接所有的点（TPR，FPR）即为ROC图 KS值# 作图步骤： 根据学习器的预测结果（注意，是正例的概率值，非0/1变量）对样本进行排序（从大到小）-----这就是截断点依次选取的顺序 按顺序选取截断点，并计算TPR和FPR —也可以只选取n个截断点，分别在1/n，2/n，3/n等位置 横轴为样本的占比百分比（最大100%），纵轴分别为TPR和FPR，计算|TPR-FPR|的ks值，可以得到KS曲线 TPR和FPR曲线分隔最开的位置就是最好的“截断点”，最大间隔距离就是KS值，通常&gt;0.2即可认为模型有比较好的预测准确性 123456789101112131415161718192021222324252627282930313233343536# 模型预测会返回概率，两列，第一列是0的概率，第二列是1的概率proba = lr_model.predict_proba(x)proba# train_thresholds 是阈值，每一个阈值对应roc曲线上的一点train_fpr,train_tpr,train_thresholds = roc_curve(y,proba[:,1])train_ks_arr = abs(train_fpr-train_tpr)train_ks = train_ks_arr.max()print('train KS:',train_ks)# 验证集的ksoft_fpr, oft_tpr,oft_thresholds = roc_curve(oft_y, lr_model.predict_proba(oft_x)[:,1])oft_ks_arr = abs(oft_fpr - oft_tpr)oft_ks = oft_ks_arr.max()print('oft KS:',oft_ks)# 最大值ks对应的下标（画图用）i = train_ks_arr.tolist().index(train_ks)j = oft_ks_arr.tolist().index(oft_ks)import matplotlib.pyplot as pltfrom matplotlib import pyplot as pltplt.plot(train_fpr,train_tpr,label='train roc')plt.plot(train_fpr,abs(train_fpr-train_tpr),label='train ks')plt.scatter(train_fpr[i],abs(train_fpr-train_tpr)[i])plt.plot(oft_fpr, oft_tpr,label='out of time roc')plt.plot(oft_fpr, abs(oft_fpr-oft_tpr),label='out of time ks')plt.scatter(oft_fpr[j],abs(oft_fpr-oft_tpr)[j])plt.plot([0,1],[0,1],'p-.')plt.xlabel('FPR')plt.ylabel('TPR')plt.legend(loc='best')plt.title('ROC Curve')plt.show() PSI群体稳定性指标# PSI(Population Stability Index)的定义# 群体稳定性指标PSI(Population Stability Index)是衡量模型的预测值与实际值偏差大小的指标。 PSI用于评估模型在训练集和时间外样本集上的稳定性指标。 给予的假设是：如果模型是稳定和有效的，那么在几个数据集上人群的分布也应该是稳定的 风控行业常用PSI指标衡量模型或者特征的稳定性，同时也是一种模型效果监控的指标。 PSI = sum[（实际占比-预期占比）* ln（实际占比/预期占比）] 计算举例：# 比如训练一个logistic回归模型，预测时候会有个概率输出p。 以dev为基准，dev上的输出设定为p1，将这个概率值从小到大排序后10等分（实际中等频分箱优于等距分箱）。 现在用这个模型去对新的样本（val或oft）进行预测，预测结果叫p2，按p1的区间也划分为10等分。 实际占比就是p2上在各区间的用户占比，预期占比就是p1上各区间的用户占比。【如果模型是有效的，那么根据p1的区间划分出来的人群占总比和p2划分出来的各个区间的人群占总比应该是大体一致的】 意义就是如果模型跟稳定，那么p1和p2上各区间的用户应该是相近的，占比不会变动很大，也就是预测出来的概率不会差距很大。 仔细想想，PSI就像是两个分布直方图，求了差值后再求和！越小说明模型在不同数据集上预测结果趋于一致，越稳定！ 一般认为PSI小于0.1时候模型稳定性很高，一般认为0.2以下还ok。0.1-0.25一般，大于0.25模型稳定性差，建议重做。 分箱每一箱的样本要大致相同，否则若某一箱太少，造成PSI计算时里面的占比会波动，带来不准确 PS：除了按概率值大小等距十等分外，还可以对概率排序后按数量十等分，两种方法计算得到的psi可能有所区别但数值相差不大。 应用： 样本外测试： 针对不同的样本测试一下模型稳定度，比如训练集与测试集，也能看出模型的训练情况，我理解是看出模型的方差情况。 时间外测试： 测试基准日与建模基准日相隔越远，测试样本的风险特征和建模样本的差异可能就越大，因此PSI值通常较高。至此也可以看出模型建的时间太长了，是不是需要重新用新样本建模了。 模型监控： 模型部署上线后，模型的拒绝率越高，线上的KS越低，也就无法体现模型的真实效果，所以常用PSI值监控线上模型与线下模型的差异，从侧面展示模型真实效果与预期效果的偏差。 特征评估： 将PSI上面第一步的十等分逻辑换成特征取值的分布，对特征进行分箱 在val、oft，或者跨时间段计算PSI 可以评估这个特征随着时间的推移，他的分布是否稳定，考虑是否能将特征代入模型。 如下图： 先把左边的概率或者score十等分，然后在actual（基准数据集，如dev）上面将样本进行划分 对上面dev上各个箱内样本计算各个分箱内的用户站占体用户的比值得到Actual列 同样的上面分箱阈值对Expected数据集进行划分，得到其上各个箱内样本数，计算出各个箱内占总比Expected列 两列相减，乘以 相除的对数值得到index列 sum所有10箱即可得到总体模型的PSI https://www.cnblogs.com/webRobot/p/9133507.html toad底层的PSI实现# 12345678910111213# test 和base 分别是模型在两个数据集上的概率预测输出toad.metrics.PSI(test, base)# 底层实现是先求test 和base 概率值的value_counts，normalize使得返回的数值被归一化。counts成了一个权重# 这里的test_prop是一个series，index是之前test的概率，value是归一化后的countstest_prop = pd.Series(test).value_counts(normalize = True, dropna = False)base_prop = pd.Series(base).value_counts(normalize = True, dropna = False)# 然后两个series相减，只会index相同的相减，也就是概率相同的相减，别的都是Nan# 相除也一样# 得到一个极其稀疏的series，绝大部分都是nan（因为概率相同的很少）# 最后相乘的时候只会乘这些在test和base上概率相同的部分# 再求和psi = np.sum((test_prop - base_prop) * np.log(test_prop / base_prop)) Gini指数# ·GINI系数:也是用于模型风险区分能力进行评估。(使用较少) GINI统计值衡量坏账户数在好账户数上的的累积分布与随机分布曲线之间的面积，好账户与坏账户分布之间的差异越大，GINI指标越高，表明模型的风险区分能力越强。 GINI系数的计算步骤如下： 计算每个评分区间的好坏账户数。 计算每个评分区间的累计好账户数占总好账户数比率（累计good%）和累计坏账户数占总坏账户数比率(累计bad%)。 按照累计好账户占比和累计坏账户占比得出下图所示曲线ADC。 计算出图中阴影部分面积，阴影面积占直角三角形ABC面积的百分比，即为GINI系数。 https://www.zhihu.com/question/37405102/answer/106668941 捕获率capture rate# 我们是低分拒绝模型，希望低分段内坏人尽量多，好人尽量少误伤！ 计算步骤： （1）将用户分数降序排列 （2）对排序后的用户进行等频分箱 （3）计算【累计到每一箱的累计负样本数】 占 【所有负样本】的比值。（cumsum/sum） 用于衡量在低分区间捕捉坏客户的能力，希望模型能尽可能的在更靠前的箱内，捕捉出更多比例的坏人 分段 2018/12/31 capture 5% 13.5% capture 10% 24.2% capture 20% 48.8% 一些表现比较好的B卡，前20%用户中可以捕获到7 80%的坏人。 减少过拟合方法：# 更多的数据 对变量做筛选（模型更简单） 分箱。因为分箱的时候，减少了过拟合（变量变得更稳定，降低噪音） https://www.jianshu.com/p/c61ae11cc5f6","categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"}],"tags":[{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"},{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"}]},{"title":"给hexo的博文添加图床、博文加密","slug":"hexo博客的图床和博文密码解决方案","date":"2018-01-07T07:59:42.000Z","updated":"2020-05-23T08:22:38.607Z","comments":true,"path":"article/hexo-blog-img-password.html","link":"","permalink":"https://blog.sofunnyai.com/article/hexo-blog-img-password.html","excerpt":"","text":"关于博客的图片 关于博文加密 关于博客的图片# 1.少量图片可以丢到根文件的source/images文件夹下，算是可以解决。 2.多一点的图片可以丢到当前文件的同目录同名文件夹下。在_config.yml打开这个注释post_asset_folder: true 就会在hero new xxx的时候自动创建xxx目录放静态资源。（但是费劲，url变化后有问题） hexo新版不支持![img](image_url)的正确渲染了，无法保证路径可以渲染成功。官方推荐用他的标签: 123&#123;% asset_path slug %&#125;&#123;% asset_img slug [title] %&#125;&#123;% asset_link slug [title] %&#125; 更多见 https://hexo.io/zh-cn/docs/asset-folders.html 但是这种方式不是标准markdown语法，无法在我们的markdown编辑器里面正确显示，真是太low了！ 3.所以我建议使用图床神器：ipic、和picgo 戳这里：https://github.com/Molunerfinn/PicGo 大体原理就是可以一键自动上传图片到github或者gitee图床，妈妈再也不用担心我们的图片了。下面是picgo和typora编辑器配合的配置，爽到爆： 关于博文加密# 个别私有博文不方便暴露，需要给博文添加密码，因为我们没有动态服务器去存储密码，只能是在渲染的时候加密，浏览的时候前台js解密。 经过搜寻找到一个工具叫做hexo-blog-encrypt，在Github这里。它会使用对称加密把博文的内容真正加密成密文，只有用户输入密码正确后才会解密成功。 中文介绍在这里，使用起来也很简单，在hexo的主目录安装加密插件： 1cnpm install --save hexo-blog-encrypt 安装完插件后，在hexo的主目录配置一下这个插件_config.yml，添加加密的安全配置： 1234567# Securityencrypt: # hexo-blog-encrypt abstract: 本文为加密的内容, 请输入密码后查看。 message: Password Here： template: &lt;div id=\"hexo-blog-encrypt\" data-wpm=\"&#123;&#123;hbeWrongPassMessage&#125;&#125;\" data-whm=\"&#123;&#123;hbeWrongHashMessage&#125;&#125;\"&gt;&lt;div class=\"hbe-input-container\"&gt;&lt;input type=\"password\" id=\"hbePass\" placeholder=\"&#123;&#123;hbeMessage&#125;&#125;\" /&gt;&lt;label&gt;&#123;&#123;hbeMessage&#125;&#125;&lt;/label&gt;&lt;div class=\"bottom-line\"&gt;&lt;/div&gt;&lt;/div&gt;&lt;script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"&#123;&#123;hbeHmacDigest&#125;&#125;\"&gt;&#123;&#123;hbeEncryptedData&#125;&#125;&lt;/script&gt;&lt;/div&gt; wrong_pass_message: wrong password, try again! wrong_hash_message: 抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容. 然后编辑一下博文的模板文件，把密码字段加到头上： 1vim scaffolds/post.md 就像下面这样，password框里如果是空的就不会加密，否则就会加密： 123456789101112131415---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:- tag1- tag2categories:- xxurlname: 修改我xxxx.htmlpassword:---&lt;!--此处生成目录--&gt;&lt;!-- toc --&gt;&lt;!--下面是latex渲染框架katex样式所需的css，不使用latex的话可以删掉--&gt;&lt;link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"&gt; 这样在列表的时候摘要会显示上面的abstract中的内容，输入框提示message消息。","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"}]},{"title":"Hexo+Github+自定义域名+CDN搭建博客系统（附namesilo优惠码）","slug":"基于hexo和github构建博客","date":"2018-01-06T05:05:26.000Z","updated":"2020-05-23T08:26:59.245Z","comments":true,"path":"article/build-a-blog-base-on-hexo-github.html","link":"","permalink":"https://blog.sofunnyai.com/article/build-a-blog-base-on-hexo-github.html","excerpt":"","text":"Why What How Details 安装Hexo 选择主题 gayhub托管 自定义域名[可选] Others 生成目录 评论管理 关于latex公式显示 在blog根目录给hexo安装hexo-renderer-markdown-it-plus插件 CDN加速[可选] FAQ Why# 之前分别在csdn和cnblogs写了一些文章，csdn的广告越来越过分实在忍不了。然而cnblogs的markdown编辑器又太弱，一直也没什么更新，所以就再造一个轮子。 What# Hexo是个啥，这一套是怎么工作的？ Hexo是一个基于Nodejs的渲染引擎，可以集成多个主题和插件，实现了内容和样式分离，可以根据喜好快速换装。 用户可以撰写一个markdown格式的博客文件，使用Hexo渲染为html格式 然后将html部署到github（或者自有服务器/vps等等） 使用github的pages服务（或者自有服务器的IP）即可访问我们的博客 可选：接着可以用我们的自有域名解析到github的pages服务即可（或者我们服务器的IP） 搭建好了怎么写博客？ 本地写markdown格式，安利下typora，巨好用。 写完执行一个命令会自动渲染成html，再执行一个命令会自动部署到github，相当简单。 How# 把大象关进冰箱需要三步，搭建基于Hexo的博客也需要三步： 安装Hexo，跑起来 搞一个Gayhub的repo，弄一个page.io 搞一个域名，DNS解析即可（如果需要加速，在CDN配置一下） Details# 安装Hexo# 首选需要安装nodejs，安装cnpm 选择操作系统的发行版: https://nodejs.org/en/download/ 我是linux，下载解压，配置环境变量，source一把即可。 windows用户更简单，下载后各种next即可。 mac和linux类似 npm加速，安装cnpm： npm install -g cnpm --registry=https://registry.npm.taobao.org 安装Hexo：cnpm install -g hexo 会自动从gayhub下载hexo并安装 然后就进入目录去配置_conifg.yml,包括博客title、作者、语言等等 运行 hexo s，然后去http://localhost:4000就能看到了。默认样式会有点丑，别着急看下一节。 选择主题# 先戳这里，官方有巨多主题： https://hexo.io/themes/ 也可以去gayhub自己搜hexo-theme即可，也有n多 我一个老年大叔，选择了一个简单一点的主题hexo-theme-pure，这个https://github.com/cofess/hexo-theme-pure 主题的中文说明：https://github.com/cofess/hexo-theme-pure/blob/master/README.cn.md 按照主题说明，clone到hexo的theme文件夹内，然后修改一下hexo的_config.yml文件中的主题theme: pure 按照主题说明，安装主题渲染所需的nodejs插件。无非就是几个cnpm install xxxx即可 按照主题说明，配置主题的配置文件，一般在主题文件夹./hexo/theme/pure下的_config.yml（无非是颜色、元素是否显示、布局之类的），很简单看一眼就知道。 运行渲染hexo clean &amp;&amp; hexo g &amp;&amp; hexo s，分别是清理、生成、运行，然后再去http://localhost:4000看一眼，主题就生效了。 gayhub托管# 我们hexo g渲染生成的静态文件在public文件夹内，需要把它丢到一个web容器内运行就可以了。gayhub提供githubpages服务可以托管静态文件，并可以http浏览。 所以去github新建一个repo，repo名字为xxxx.github.io,这个xxxx必须和你的github用户名一致! 然后回到hexo中配置deploy模式为git，配置仓库地址为上面的repo地址。更多参见https://hexo.io/zh-cn/docs/github-pages 配置完毕hexo d输入github账号密码即可push到服务器（如果本机没有保存，或者服务器配置秘钥的话，具体github配置公钥上网查找） 然后可以访问我们的博客了https://xxxx.github.io` 自定义域名[可选]# 上面虽然博客可以访问了，但是github.io看起来有点low，而且国内访问速度也很慢。 所以，我建议撸一个域名，挂博客，搞微信开发，内网穿透，扶墙等等用处多多。。。而且最好是境外服务商域名，境内的域名要备案、年检，非常非常麻烦。 目前最便宜的是戳这个：namesilo官网，优势： 他家的.com域名只要7.99刀，.xyy和.online域名只要0.99刀，简直白送！关键是续费便宜没有坑，别家有首年很便宜，后面续费巨贵的。 永久免费的whois隐私保护，其他家这个功能还要收费。 支持支付宝收款，不用别家还要信用卡或者PayPal 所以戳链接进去官网： www.namesilo.com/ 进入官网后，右上角注册sign up，输入用户名，邮箱，密码即可。 然后register，选择域名进行注册，第一次会让你填写信息（以免域名丢失找回，或者服务商后续通知一些域名相关事项） 输入你想注册的域名，搜索，看看有没有被注册过： 假如你选择的没有被占用。点击下面的add加入购物车，然后checkout结算,我这里用.com的8.99刀域名举例（你也可以用下面0.99刀的，简直便宜到几乎白送！） 结算页面，按图上选择即可，然后下面的打折码输入**cutoff** ，点击submit即可享受打折优惠！ 下一步就是支付宝扫码付款即可。 付完款去account个人中心，点击domain manager域名管理，会出来你的域名列表。点击设置dns 设置DNS,点击CNAME，会出来一条解析，可以根据喜好设置为www的主域名，还是blog.xxx.com的二级域名。目标设置我们上面个人的xxxxxx.github.io，提交即可。 搞定你以为大功告成了？还需要在github的repo里面设置这个域名，否则github会阻止域名解析，导致404。看下一节 github配置域名： 在那个custom domain填写你的域名，save一下 然后在你本地的hexo/source目录下创建个CNAME文件夹，写上你的域名 最后，重新hexo g &amp; hexo d 此时即可用我们的域名访问。 Others# 生成目录# 为博客生成toc目录 使用插件cnpm install hexo-toc --save 然后配置一下最大深度等 123456789toc: maxdepth: 3 class: toc slugify: transliteration decodeEntities: false anchor: position: after symbol: '#' style: header-anchor 评论管理# 关于博客的评论，一般来说是需要一个数据库的。但是我们是纯静态服务，所以有人搞了类似gitalk、gitment 这样的东西。只用前台引用js即可，一般都不用我们管，主题已经集成好了。只用按照说明进行配置几个参数即可。 关于latex公式显示# latex会显示失败，按照pure主题的解决方案： 数学公式# Hexo默认使用&quot;hexo-renderer-marked&quot;引擎渲染网页，该引擎会把一些特殊的markdown符号转换为相应的html标签 解决方案# 解决方案有很多，可以网上搜下，为了节省大家的时间，这里只提供亲身测试过的方法。 更换Hexo的markdown渲染引擎，hexo-renderer-markdown-it-plus引擎替换默认的渲染引擎hexo-renderer-marked即可。 在blog根目录给hexo安装hexo-renderer-markdown-it-plus插件# 123cnpm un hexo-renderer-marked --save # 卸载cnpm i hexo-renderer-markdown-it-plus --save # 安装新的渲染框架cnpm i markdown-it-katex --save # 安装katex渲染latex 配置# 安装插件后，如果未正常渲染LaTeX数学公式，在博客根目录配置文件_config.yml中添加 12345678910111213141516markdown_it_plus: highlight: true html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: “”‘’ plugins: - plugin: name: markdown-it-katex enable: true - plugin: name: markdown-it-mark enable: false 文章启用mathjax（不用设置true也可以）# 12title: Hello Worldmathjax: true 按照上面操作了还是不行，元素错位。看了下面这个解决了： 还错位或者显示元素不准的话，需要引入一个katex的css# 1&lt;link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"&gt; https://blog.csdn.net/u014792304/article/details/78687859 katex和latex大部分命令是相通的，不同的略微差别见下面： https://khan.github.io/KaTeX/function-support.html CDN加速[可选]# 想继续折腾访问速度的往下看： 首先，不推荐国内的CDN供应商和域名解析商，因为他们动不动就有合规要求。会折腾客户去备案（不是所有的） 然后，推荐cloudflare，也很简单，注册一个账号，在namesilo里面把CDN服务迁移到cloudflare即可。上网搜索巨多资料。 FAQ# 为啥配置好了域名无法访问？ 等待域名解析，尝试DNS那里的TTL设置小一点，刷新本地DNS缓存。 为啥速度不一般？ 因为是国外DNS，可能第一次访问有点慢。有精力的尝试迁移到cloudflare，还有CDN加速，https，爽歪歪。戳这里：https://www.cloudflare.com/","categories":[{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"}],"tags":[{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"}]},{"title":"java8","slug":"java8","date":"2017-12-08T13:35:54.000Z","updated":"2020-07-09T03:40:00.094Z","comments":true,"path":"article/java8.html","link":"","permalink":"https://blog.sofunnyai.com/article/java8.html","excerpt":"","text":"Java8的新特性体验 Lambda表达式和FunctionalInterface 概述@FunctionalInterface Lambda表达式 Consumer Function Predicate Supplier 接口的static和default实现 方法引用:: 引用实例方法 引用静态方法 引用构造方法 引用数组 StreamAPI forEach是一个Consumer&lt;T&gt; map是一个Function&lt;? super T, ? extends R&gt; filter 过滤 sort reduce： flatMap 展平 groupingBy skip、limit、count、distinct等等 Optional 作为一个if else的替代处理null Comparable和Comparator Comparator 比较器，无侵入性，支持自定义 Java8的新特性体验# Lambda表达式和FunctionalInterface# 类似scala和python的lambda表达式终于面世，可以大大简化大量的匿名内部类代码，快速来看一眼。 概述@FunctionalInterface# 函数式接口是指一个接口中有且只有一个方法的接口，此时的接口可以加上一个@FunctionalInterface来标记这个interface是一个函数是接口。当然也不是强制的，只要一个接口中有且只有一个未实现的抽象方法，就可以当作是一个函数式接口。 FunctionalInterface可以用：lambda表达式，方法引用，或构造的引用来创建。 加上@FunctionalInterface只是为了让编译器去检查我们的接口，如果不小心写了第二个抽象方法就会报错，编译不通过。（Object的方法除外，因为已经有默认实现） 同时java8对interface有加强实现，如default的方法可以在子类中实现。 同时java8还允许有static的实现。 以上两个方式都不是抽象方法，不会影响我们的函数式接口的定义。 如: 12345678910111213141516171819@FunctionalInterfacepublic interface InterfaceMethod &#123; /** * lambda能用的接口都只能是一个抽象方法 * 注解不是必须的，如果一个接口符合\"函数式接口\"定义，那么加不加@FunctionalInterface 注解都没有影响。 * 但是如果接口超过一个抽象方法,加上它会报错,给我们一个提示。 */ public void method1(); // 接口里的public可以省略，这里是写顺手了，下同。 //比如函数式注解@FunctionalInterface标记后，解开下面这一行就会编译报错 //public void method9(String param); // 接口中static和default的实现不会影响函数式接口的实现，有任意多个也不影响 // Object的方法也例外，如下面也没关系 // public boolean equals();&#125; 使用的时候，假设用上面的方法来做回调： 1234567891011121314151617181920212223242526class BankService &#123; // 自定义回调的业务类，一般要求外面执行业务时传递一个符合接口规范的回调对象 public void doSth(String param, InterfaceMethod callback)&#123; // 执行业务逻辑 System.out.println(\"业务方法开始回调。。。。\"); callback.method1(); &#125;&#125;// java8之前的业务使用// 创建业务对象,同时传递回调业务BankService bank = new BankService();// 执行业务，会自动回调bank.doSth(\"取款\",new InterfaceMethod() &#123;@Overridepublic void method1() &#123; // 回调的业务逻辑 System.out.println(\"执行完毕取款业务的callback逻辑....\"); &#125;&#125;);// java8之后的业务使用，lambda表达式就代表了我们bank这个方法所需的InterfaceMethod接口实现bank.doSth(\"转账\",()-&gt;&#123;System.out.println(\"执行完毕转账业务的callback逻辑2....\");&#125;;); 上面只是一个演示，有点丑陋。另外可以看到我们写了那么一个只有一个方法名的空的接口没啥意思。 如果我们业务有很多很多场景都要回调，没必要每个地方都定义一个空的接口，所以JDK给我们预制了常见的functionalInterface 我们可以看一眼常见的类型： Lambda表达式# Lambda表达式其实完成了实现接口并且实现接口里的方法这一功能. 一个 Lambda 表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断。例如：(int a)与(a)效果相同 所有参数需包含在圆括号内，参数之间用逗号相隔。例如：(a, b) 或 (int a, int b) 或 (String a, int b, float c) 空圆括号代表参数集为空。例如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号（）可省略。例如：a -&gt; return a*a Lambda 表达式的主体可包含零条或多条语句 如果 Lambda 表达式的主体只有一条语句，花括号{}可省略。匿名函数的返回类型与该主体表达式一致 如果 Lambda 表达式的主体包含一条以上语句，则表达式必须包含在花括号{}中（形成代码块）。匿名函数的返回类型与代码块的返回类型一致，若没有返回则为空 123456() -&gt; &#123;return 0;&#125;，// 没有传入参数，有返回值(int i) -&gt; &#123;return 0;&#125;，// 传入一个参数，有返回值(int i) -&gt; &#123;System.out.println(i)&#125;，// 传入一个int类型的参数，但是没有返回值(int i, int j) -&gt; &#123;System.out.println(i)&#125;，// 传入两个int类型的参数，但是没有返回值(int i, int j) -&gt; &#123;return i+j;&#125;，// 传入两个int类型的参数，返回一个int值(int i, int j) -&gt; &#123;return i&gt;j;&#125;，// 传入两个int类型的参数，返回一个boolean值 如： 1Runnable o1 = () -&gt; &#123; System.out.println(\"hi\"); &#125;; 函数式接口在包jjava.util.function包中,主要包括： Consumer# 顾名思义是给我们消费用的，看看他的参数和返回： 他是一个单个参数、无返回的一个函数式接口，用于我们消费参数并执行一个操作使用。 也就是： Consumer 一个参数，供消费用的。 void accept(T t); 12345678910// 单个参数、无返回的一个函数式接口@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; /** * Performs this operation on the given argument. * @param t the input argument */ void accept(T t);&#125; 使用方式如： 123456789101112131415161718192021// 一个极简的演示class BankService &#123; int balance = 0; // 余额 /** * 充值并使用JDK自带的consumer函数接口进行回调 * @param amt 充值金额 * @param callback 回调余额 */ public void recharge(int amt, Consumer&lt;Integer&gt;callback)&#123; balance += amt; callback.accept(balance); &#125; &#125;// 上面自定义一个空的函数接口没啥意思，本身也是空的，所以JDK提供了很多默认的函数接口java.util.function里面// 充值，并传入一个要求的consumer实现，来作为回调函数bank.recharge(100,balance-&gt;System.out.println(\"recharge completed，余额是....\"+balance)); 当然那还有一堆定制更多的Consumer，如DoubleConsumer消费Double数据的，IntConsumer消费Int数据的，BiConsumer消费两个数据的。 更深入定制的如：ObjIntConsumer 是消费一个Obj，一个Int，他其实是一种BiConsumer，也就是消费两个对象。 1234567891011@FunctionalInterfacepublic interface ObjIntConsumer&lt;T&gt; &#123; /** * Performs this operation on the given arguments. * * @param t the first input argument * @param value the second input argument */ void accept(T t, int value);&#125; Function# 顾名思义，是一个操作。既然是一个操作就有参数和返回值。所以 123456789101112// 一个参数，一个返回值@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; /** * Applies this function to the given argument. * * @param t the function argument * @return the function result */ R apply(T t); &#125; 应用如： 123456789101112131415161718class BankService &#123; /** * 充值并扣税 * 要求传入一个金额和一个扣税方法来计算： * 传入int金额并返回int的税后金额 * @param amount * @param calculateTax */ public void rechargeAndTax(int amount, Function&lt;Integer, Integer&gt;calculateTax)&#123; // 对充值金额进行扣税 amount -= calculateTax.apply(amount); this.balance += amount; &#125;&#125;// 外面业务使用，充值100,并传入扣税的lambda，扣定额的10元税（只有一行，省略return，一个参数省略小括号）bank.rechargeAndTax(100,amount-&gt;amount - 10); Function的变种比较多如LongFunction就是传入一个long，然后进行计算返回一个自定义类型对象： 1234@FunctionalInterfacepublic interface LongFunction&lt;R&gt; &#123; R apply(long value);&#125; 类似的还有IntFunction是处理int类型入参的。DoubleFunction类似。 有个特殊点的，如需要两个参数，一个返回怎么办？答案是BiFunction，更多参数就没有了，要我们自己实现了。 123456789101112@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; &#123; /** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */ R apply(T t, U u);&#125; 演示一个简单的双参数的Function使用： 123456789101112131415161718192021222324/** * 消费，且消费前先校验 * 传入校验的方法 * @param amount * @param validation * @return */ public boolean cash(int amount, BiFunction&lt;Integer,Integer,Boolean&gt; validation)&#123; if(validation.apply(amount,balance))&#123; balance -= amount; System.out.println(\"取现\"+amount+\"元，余额：\"+balance+\"元。\"); return true; &#125;else&#123; System.out.println(\"校验失败，余额不足！\"); return false; &#125; &#125;// 外面使用// bank.cash(50, (amount,balance)-&gt;&#123;return balance &gt; amount;&#125;);bank.cash(500, (amount,balance)-&gt;balance &gt; amount); Predicate# 可以看作是一个Function&lt;T,Boolean&gt;,也是进行一个计算，然后返回一个Boolean值而已 12345678910111213@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return &#123;@code true&#125; if the input argument matches the predicate, * otherwise &#123;@code false&#125; */ boolean test(T t);&#125; Supplier# 没有参数，只是返回，一般用于工厂方法。 12345678910@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; /** * Gets a result. * * @return a result */ T get();&#125; 接口的static和default实现# 默认方法的作用： Java8之前如果已经使用了一个接口，想给这个接口加一个方法，那么需要修改所有实现了这个接口的类，是非常恐怖的，而Java8可以允许我们给这个接口新增一个默认实现方法来解决（子类可以override） 当然如果最开始我们的是接口-抽象类-子类的方式的话，就不用这么麻烦，可以直接在抽象类中新增方法。 12345678910111213141516171819202122232425public interface commonInterface()&#123; public void method1(); /** * java8的default实现 * 当需要新增一个所有实现类都需要的方法时,可以在接口中新增一个default的方法 * 而无需每个实现类都重新相同的实现一遍这个接口类 * * 可以被其他的接口继承,可以被重写,刻意被继承的接口重新定义为一个普通的抽象方法 * * 默认方法不算是抽象方法 */ default public void method2()&#123; //do something &#125; /** * java8允许在接口中实现静态方法 * 静态方法不算是抽象方法 */ public static void method4()&#123; //do something &#125;&#125; 方法引用::# 双冒号代表引用一个方法，通过方法引用来创建函数式接口的实现（引用一个方法来当作一个函数是方法的实现），如： 限制条件： 方法实现只能调用一个方法，一行 引用的那个方法和我们定义的函数式方法的参数和返回值是一致的 引用实例方法# 把PrintStream类的println方法引用过来当作一个函数是接口： 123456// 假设我只是想打印一下，那么需要这么干Consumer&lt;String&gt; consumer = s -&gt; System.out.println(s);consumer.accept(\"sam\");// 但是打印这个功能其实在System.out中已经实现了（其实是PrintStream类），就可以：Consumer&lt;String&gt; consumer = System.out::println; // 将out里面的println方法视为一个Consumer&lt;String&gt; ，通过方法引用来创建函数式接口的实现consumer.accept(\"sam\"); 因为 println的实现就是传入一个String，没有返回值，和我们Consumer&lt;String&gt;的需求一模一样： 而且我们的需求是只用一行就能完成业务System.out.println(str)，不能再有别的代码，否则就不行。 1234567// println的实现就是传入一个String，没有返回值，和我们Consumer&lt;String&gt; 的需求一模一样public void println(String x) &#123; synchronized (this) &#123; print(x); newLine(); &#125; &#125; 同理： 12345// 这里其实是使用了String.compareToIgnoreCase方法来当作一个Comparator&lt;? super T&gt; c的 int compare(T o1, T o2)实现Arrays.sort(strArrs, (s1,s2)-&gt;s1.compareToIgnoreCase(s2));// 类似的Comparator&lt;PersonBean&gt; byName = Comparator.comparing(PersonBean::getUserName); 引用静态方法# 123// 引用静态方法,三个int分别是求max的a,b和返回。这里引用public static int max(int a, int b) 实现BiFunction&lt;Integer,Integer,Integer&gt; max = Math::max;int bigger = max(2,3); 引用构造方法# 123// 引用构造方法SrtingBuffer sb = new StringBuffer(1024);Function&lt;Integer,StringBuffer&gt; sbCreator = StringBuffer::new;sbCreator.apply(1024); 引用数组# 123// 引用数组 Function&lt;Integer,int[]&gt; fun = n-&gt;new int[n];Function&lt;Integer,int[]&gt; arrCreator = int[]::new;arrCreator.apply(1024); StreamAPI# forEach是一个Consumer&lt;T&gt;# 1studentList.forEach(each -&gt; System.out.print(each.getUserName())); map是一个Function&lt;? super T, ? extends R&gt;# 123// 简略写法studentList.stream().map(PersonBean::getAge).distinct().collect(Collectors.toList())// studentList.stream().map(each-&gt;each.getAge()).distinct().collect(Collectors.toList()) 先使用map去处理每一个list的对象，里面使用person.getAge()返回了Int的年龄，然后使用distinct变成另一个stream， 再collecte的时候引用了另外一个Collectors.toList()中实现好的方法 filter 过滤# Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate);还是返回一个stream，后面继续操作 123List&lt;String&gt;names = studentList.stream().filter(each-&gt;each.getAge()&gt;16).sorted(Comparator.comparingInt(each-&gt;each.getAge())).map(PersonBean::getUserName).collect(Collectors.toList());System.out.println(\"所有&gt;18学生的姓名按照年龄排序:\"+names); sort# Stream&lt;T&gt; sorted(Comparator&lt;? super T&gt; comparator);也返回一个stream，后面继续操作 看上面例子 reduce：# 求汇总 1234567891011// 求大于16的人的年龄总和public void testStream5() &#123; int sumAge = studentList.stream().map(each-&gt;&#123; if(each.getAge()&gt;16)&#123; return each.getAge(); &#125;else&#123; return 0; &#125; &#125;).reduce(0,Integer::sum);// 初始值为0去累加 System.out.println(\"大于16的人的年龄总和：\"+sumAge); &#125; flatMap 展平# 12345678public void testStream6() &#123; List&lt;List&lt;Integer&gt;&gt; list =Arrays.asList(Arrays.asList(1,2),Arrays.asList(3,4,5),Arrays.asList(6,7,8)); System.out.println(\"原始list的数据，是三个list：\"); list.stream().forEach(System.out::println); System.out.println(\"flatMap后，展平合并了：\"); Stream&lt;Integer&gt; integerStream = list.stream().flatMap(Collection::stream); integerStream.forEach(System.out::println);&#125; 输出： 123456789101112131415原始list的数据，是三个list：[1, 2][3, 4, 5][6, 7, 8]flatMap后，展平合并了：12345678Process finished with exit code 0 groupingBy# 12345// 按照班级分组studentList.stream().collect(Collectors.groupingBy(PersonBean::getClassName)).forEach((k,v)-&gt;&#123; System.out.println(\"k=\"+k); System.out.println(\"v=\"+v); &#125;); 输出： 123456k&#x3D;3班v&#x3D;[PersonBean(userName&#x3D;王五, age&#x3D;17, married&#x3D;false, addr&#x3D;null, isStudent&#x3D;true, className&#x3D;3班), PersonBean(userName&#x3D;朱八, age&#x3D;15, married&#x3D;false, addr&#x3D;null, isStudent&#x3D;true, className&#x3D;3班)]k&#x3D;2班v&#x3D;[PersonBean(userName&#x3D;张三, age&#x3D;16, married&#x3D;false, addr&#x3D;null, isStudent&#x3D;true, className&#x3D;2班), PersonBean(userName&#x3D;李四, age&#x3D;20, married&#x3D;false, addr&#x3D;null, isStudent&#x3D;true, className&#x3D;2班), PersonBean(userName&#x3D;赵六, age&#x3D;16, married&#x3D;false, addr&#x3D;null, isStudent&#x3D;true, className&#x3D;2班), PersonBean(userName&#x3D;何七, age&#x3D;16, married&#x3D;false, addr&#x3D;null, isStudent&#x3D;true, className&#x3D;2班)]Process finished with exit code 0 skip、limit、count、distinct等等# 比较简单，略 Optional 作为一个if else的替代处理null# 先看一眼api 12345671、isPresent() //有值则返回true2、get(): //值存在时返回值，否则抛出一个NoSuchElement异常（所以调这个，一般先判断上面方法返回是否为true）3、orElse(T other) //值存在时返回值，否则返回一个默认值4、ifPresent(Consumer&lt;T&gt; block) //会在值存在的时候执行给定的代码块5、orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) //与get()类似，不同的是可以自定义异常类型6、orElseGet(Supplier&lt;? extends T&gt; other) //orElse方法的延迟调用版，Supplier方法只有在Optional对象不含值时才执行调用7、map/flatMap/filter //与Stream中用法类似 再看看源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** * final修饰代表不能被子类继承 */public final class Optional&lt;T&gt; &#123; /** * 创建一个空容器 */ private static final java.util.Optional&lt;?&gt; EMPTY = new java.util.Optional&lt;&gt;(); /** * 传入的值 */ private final T value; /** * 构造函数私有化 说明不能被外部new */ private Optional() &#123; this.value = null; &#125; /** * 私有化构造函数 */ private Optional(T value) &#123; this.value = Objects.requireNonNull(value); &#125; /** * 获取空容器 */ public static &lt;T&gt; java.util.Optional&lt;T&gt; empty() &#123; @SuppressWarnings(\"unchecked\") java.util.Optional&lt;T&gt; t = (java.util.Optional&lt;T&gt;) EMPTY; return t; &#125; /** * 传入的对象不能为空 否则抛异常 */ public static &lt;T&gt; java.util.Optional&lt;T&gt; of(T value) &#123; return new java.util.Optional&lt;&gt;(value); &#125; /** * 传入的对象可以为空 */ public static &lt;T&gt; java.util.Optional&lt;T&gt; ofNullable(T value) &#123; return value == null ? empty() : of(value); &#125; /** * 获取容器对象的方法 注意 如果用这个方法则代表容器中一定有对象，否则抛异常 */ public T get() &#123; if (value == null) &#123; throw new NoSuchElementException(\"No value present\"); &#125; return value; &#125; /** * 判断容器对象是否为空 */ public boolean isPresent() &#123; return value != null; &#125; /** * 如果容器对象为空 则返回当前对象 */ public T orElse(T other) &#123; return value != null ? value : other; &#125; /** * 传入Consumer编程式接口参数 */ public void ifPresent(Consumer&lt;? super T&gt; consumer) &#123; if (value != null) consumer.accept(value); &#125; /** * 传入Predicate编程式接口参数 */ public java.util.Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate) &#123; Objects.requireNonNull(predicate); if (!isPresent()) return this; else return predicate.test(value) ? this : empty(); &#125; /** * 传入Function编程式接口参数 */ public &lt;U&gt; java.util.Optional&lt;U&gt; map(Function&lt;? super T, ? extends U&gt; mapper) &#123; Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else &#123; return java.util.Optional.ofNullable(mapper.apply(value)); &#125; &#125; /** * 传入Function编程式接口参数 */ public &lt;U&gt; java.util.Optional&lt;U&gt; flatMap(Function&lt;? super T, java.util.Optional&lt;U&gt;&gt; mapper) &#123; Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else &#123; return Objects.requireNonNull(mapper.apply(value)); &#125; &#125; /** * 传入Supplier编程式接口参数 */ public T orElseGet(Supplier&lt;? extends T&gt; other) &#123; return value != null ? value : other.get(); &#125; /** * 传入Supplier编程式接口参数 */ public &lt;X extends Throwable&gt; T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) throws X &#123; if (value != null) &#123; return value; &#125; else &#123; throw exceptionSupplier.get(); &#125; &#125;&#125; 最后试试： 1234567891011121314151617 public static void func1(String param)&#123; // 传了就有，没传报空指针// Optional&lt;String&gt; optional = Optional.of(param); // 不可为空，否则此行报错// System.out.println(optional.get()); Optional&lt;String&gt; optional1 = Optional.ofNullable(param); System.out.println(optional1.orElse(\"如果是null降级为此\")); // 上面相当于传统的写法： // System.out.println(param == null? \"如果是null降级为此\" : param); Optional&lt;String&gt; optional3 = Optional.ofNullable(param); // 也可以在为空的时候使用一个Supplier进行降级，里面使用稍微复杂一点的逻辑进行降级 System.out.println(optional3.orElseGet(()-&gt;&#123;return \"123456\".substring(1);&#125;));// Optional&lt;String&gt; optional2 = Optional.ofNullable(param);// optional2.get(); 为空的时候也会报错 NoSuchElementException: No value present &#125; 1234567891011121314public static void func2(PersonBean person)&#123; // 判断传入的user是否为null，是的话引用构造方法新建一个 Optional&lt;PersonBean&gt; userOp = Optional.ofNullable(person); PersonBean personBean = userOp.orElseGet(PersonBean::new); Optional&lt;Integer&gt; ageOp = Optional.ofNullable(personBean.getAge()); if(ageOp.isPresent())&#123; // op2.map((age)-&gt;String.valueOf(age)); String ageStr = ageOp.map(String::valueOf).get(); // ... &#125;else&#123; // ... &#125; &#125; Comparable和Comparator# 123456789101112131415161718192021222324252627/** * comparable接口需要对象去实现，相当于表明“我是可以支持排序的” * 因为实现了comparable接口的compareTo方法，可以直接排序。 * 实现Comparable接口这种方法有侵入性，而且已有的类很难去修改代码实现接口。 */ public static void testComparable()&#123; List&lt;Car&gt; carList = getCarList(); Collections.sort(carList); // Comparable的Car的List，所以可以直接排序 carList.forEach(System.out::print); &#125;@Data@AllArgsConstructorclass Car implements Comparable&#123; // 表明是支持直接排序的 private String name; private double price; @Override public int compareTo(Object o) &#123; Car another = (Car)o; return this.price - another.getPrice()&gt;0?1:-1; &#125;&#125; Comparator 比较器，无侵入性，支持自定义# 123456789101112131415161718192021222324252627282930313233343536List&lt;User&gt; users = getUserList();// 要排序我们一般使用Collections.sort(List&lt;T&gt; list, Comparator&lt;? super T&gt; c) &#123;// 需要实现一个List泛型所需的比较器// 1.排序,最原始的写法，我们写一个匿名内部类Comparator，来定义比较的规则Comparator userComparator = new Comparator&lt;User&gt;() &#123; @Override public int compare(User o1, User o2) &#123; return o1.getAge()-o2.getAge(); // 按照年龄从小到大排序 &#125;&#125;;// 然后使用这个比较器Collections.sort(users, userComparator);users.forEach(System.out::print);// 2.上面的Comparator是一个函数式接口，所以我们可以借助java8进行优化，一行搞定users = getUserList();// Comparator函数式接口只有一个方法compare，传入两个泛型参数，输出一个比较结果int，所以：Collections.sort(users, (o1,o2)-&gt;o1.getAge()-o2.getAge());users.forEach(System.out::print);// 3.进一步，JDK为我们内置了常见的比较器，Comparator.comparingInt就会返回我们上面所需的函数式接口Comparatorusers = getUserList();Collections.sort(users, Comparator.comparingInt(User::getAge));users.forEach(System.out::print);@Data@AllArgsConstructorclass User&#123; private int age; private String name;&#125; optional 参考了 https://www.cnblogs.com/qdhxhz/p/12056745.html","categories":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/categories/java/"}],"tags":[{"name":"基础","slug":"基础","permalink":"https://blog.sofunnyai.com/tags/%E5%9F%BA%E7%A1%80/"},{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/tags/java/"}]},{"title":"linux下mysql5.7安装备忘","slug":"linux下mysql5.7安装备忘","date":"2017-10-21T03:41:55.000Z","updated":"2020-06-15T09:14:40.651Z","comments":true,"path":"article/linux-mysql5.7-install.html","link":"","permalink":"https://blog.sofunnyai.com/article/linux-mysql5.7-install.html","excerpt":"","text":"先下载 解压，安装依赖 编辑配置文件 设置环境变量 创建目录 创建用户，授权 初始化 启动，修改密码 启动 修改密码 开机自启动 服务命令 安装过多次，5.7略有变化，记录供日后参考。 先下载# 去https://dev.mysql.com/downloads/mysql/5.7.html下载，比如wget mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz 解压，安装依赖# apt install libaio1,否则会报一个libaio.so找不到的错。centos使用yum安装。 编辑配置文件# vim /etc/my.cnf然后编辑 123456789101112131415161718192021222324252627282930313233[mysql]# 设置mysql客户端默认字符集default-character-set=utf8mb4socket=/var/run/mysqld/mysqld.sock[mysqld]skip-name-resolveport = 3306#language=/usr/local/mysql/share/englishsocket=/var/run/mysqld/mysqld.sock# 设置mysql的安装目录basedir=/main/mysql5.7.30# 设置mysql数据库的数据的存放目录datadir=/main/mysql5.7.30/datalog-error=/var/log/mysql/error.logslow_query_log=ONslow_query_log_file=/var/log/mysql/slowquery.loglong_query_time=3log-queries-not-using-indexes=ON# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8mb4# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB lower_case_table_names=1max_allowed_packet=16Muser=mysqldefault-time_zone = '+8:00'[client]port = 3306socket = /var/run/mysqld/mysqld.sock 设置环境变量# 123#mysqlexport MYSQL_HOME=/main/mysql5.7.30export PATH=$MYSQL_HOME/bin:$PATH 创建目录# 5.7很弱智，上面配置文件中的那些目录都要人肉创建，否则会报错。 123mkdir /main/mysql5.7.30/datamkdir /var/log/mysqlmkdir /var/run/mysqld 创建用户，授权# 123456groupadd mysql useradd -r -g mysql mysql chown -R mysql:mysql /main/mysql5.7.30chown -R mysql:mysql /var/log/mysqlchown -R mysql:mysql /var/run/mysqld 初始化# 1mysqld --initialize --user=mysql --basedir=/main/mysql5.7.30 --datadir=/main/mysql5.7.30/data --lc_messages_dir=/main/mysql5.7.30/share --lc_messages=en_US 然后观察控制台的信息和/var/log/mysql/error.log里面的输出，缺少啥目录或者文件手动创建一下即可。 启动，修改密码# 启动# 初始化后，去到/var/log/mysql/error.log找到里面的临时密码，然后启动： /main/mysql5.7.30/support-files/mysql.server start 正常启动后登录： mysql -u root -p然后输入刚才复制的临时密码 修改密码# 12345678910set password=password('新密码'); flush privileges; use mysql; UPDATE `mysql`.`user` SET `Host`='%', `User`='root', `Select_priv`='Y', `Insert_priv`='Y', `Update_priv`='Y', `Delete_priv`='Y', `Create_priv`='Y', `Drop_priv`='Y', `Reload_priv`='Y', `Shutdown_priv`='Y', `Process_priv`='Y', `File_priv`='Y', `Grant_priv`='Y', `References_priv`='Y', `Index_priv`='Y', `Alter_priv`='Y', `Show_db_priv`='Y', `Super_priv`='Y', `Create_tmp_table_priv`='Y', `Lock_tables_priv`='Y', `Execute_priv`='Y', `Repl_slave_priv`='Y', `Repl_client_priv`='Y', `Create_view_priv`='Y', `Show_view_priv`='Y', `Create_routine_priv`='Y', `Alter_routine_priv`='Y', `Create_user_priv`='Y', `Event_priv`='Y', `Trigger_priv`='Y', `Create_tablespace_priv`='Y', `ssl_type`='', `ssl_cipher`='', `x509_issuer`='', `x509_subject`='', `max_questions`='0', `max_updates`='0', `max_connections`='0', `max_user_connections`='0', `password_lifetime`=NULL, `account_locked`='N' WHERE (`User`='root'); flush privileges; 开机自启动# 123cd support-filescp mysql.server /etc/init.d/mysqldchkconfig --add mysqld 服务命令# 使用的support-files目录下的文件管理 123mysql.server stopmysql.server startmysql.server restart","categories":[{"name":"中间件","slug":"中间件","permalink":"https://blog.sofunnyai.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://blog.sofunnyai.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"运维","slug":"运维","permalink":"https://blog.sofunnyai.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"mysql","slug":"mysql","permalink":"https://blog.sofunnyai.com/tags/mysql/"}]},{"title":"Java Hashmap底层源码剖析","slug":"hashmap","date":"2017-03-19T05:09:19.000Z","updated":"2020-07-22T09:48:38.091Z","comments":true,"path":"article/java-hashmap.html","link":"","permalink":"https://blog.sofunnyai.com/article/java-hashmap.html","excerpt":"","text":"Hash数据结构基础 哈希表： 哈希表的缺点： Hash碰撞解决？—开放地址/链地址 好的哈希函数: QA Hash数据结构基础# 哈希表：# 一个基于数组的K-V存储结构，K经过hash函数后散列到数组的某个位置，去拿到所需的K-V对。适用于可预测数据量且不需要遍历的场合。 哈希表的效率：插入和删除需要O(1)的时间。(既能够具备数组的快速查询的优点又能融合链表方便快捷的增加删除元素的优势) 哈希表的缺点：# 基于数组，由于数组是定长的，长度塞满时效率很低（碰撞太多）。 所以程序需要在合适的时候（如loadFactor大于2/3）把数据移动到更大的哈希表中，这个操作非常费时（因为地址是和数组长度有关的，移动时所有的元素将会逐一重新算hash地址）。 没有一种机制可以有序遍历(如从小到大)哈希表中的数据，如果需要则只能借助使用其他的数据结构。 Hash碰撞解决？—开放地址/链地址# 多个对象通过hash算法后的的地址相同，就产生了“哈希碰撞”。解决哈希碰撞的方法一般有两种： 开放地址法：即在数组中向后找一个合适的空位存储新的碰撞的对象。 线性探测：若碰撞，则从第一次hash的地址开始逐一向后找，找到空位则存储新的对象。（这种算法会在数组的某一段聚集大量的值，会增大碰撞的概率。聚集会降低hash表的效率） 二次探测：若碰撞，则从第一次hash的地址开始继续向后找，但每次找的步长为 1、4、9、16、25…以平方数递增。（比上一种略好，但因为碰撞元素探测的补偿相同，故会造成更细小的碰撞，在数组上聚集很多小段连续元素） 再hash方法：通过另一个hash算法算出第二次的步长。这个步长为一个与hash地址有关的值。如：stepSize = constant - （key % constant） key为第一次hash后碰撞的地址，这个常量要求是小于数组长度的质素。（数组长度也是质数） 链地址法：即在发生碰撞的位置存储一个链表。 好的哈希函数:# 可以快速的计算,有许多乘法/除法会比较慢不合适,除了取模之外可以考虑位运算,左移N位相当于除以2的N次方 结果要随机,哈希函数为了避免哈希碰撞,需要把key映射到数组的下标,越随机越好 使用质数取模,也就是数组长度要是质数,否则会有很大的聚集效应! 字符串hash的时候可以把每一位按照ascii码乘以27的N次方,再相加. 如china的c计算: (charAt(0)-97)*27^4 子母h:(charAt(1)-97)*27^3 … 如果最后数字太大可以使用[同余定理]拆分: (A×B + C×D + E×F +...)%P == ((A×B)%P + (C×D)%P +...)%P 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165package com.sam.phoenix.datastructure.e_HashTable;import java.math.BigDecimal;/*** 本例子采用线性线性探测法 * @author sam */public class HashTableLine &#123; //最大可以存放数据的总数 private int maxDataSize = 0; //数组长度是arraySize除以loadFactor,除完的结果最好是一个质数,否则会有比较大的聚集效应 private Node[]hashArray; //已经使用的长度 private int length = 0; //删除标记 static final Node DELETEED_NODE = new Node(Integer.MIN_VALUE,null); /** * 构造方法，构造数组，初始化数组长度 * * 这里初始化一个比最大长度更长的数组,解决哈希碰撞开放地址后效率下降的问题,用空间换取时间 * @param size 最大存储的数量 * @param loadFactor */ public HashTableLine(int size, float loadFactor)&#123; if(loadFactor &lt;= 0 || loadFactor&gt;1)&#123; System.out.println(\"装载因子必须大于0,小于1,因为输入非法,默认取0.5!!!!\"); loadFactor = 0.5f; &#125; int len = new BigDecimal(size).divide(new BigDecimal(loadFactor),0,BigDecimal.ROUND_HALF_EVEN).intValueExact(); hashArray = new Node[len]; maxDataSize = size; &#125; /** * 哈希算法，根据key的大小，算出在数组中的位置 * @param key * @return */ private int hashFunction(int key)&#123; return key % hashArray.length; &#125; /** * 向hash表插入key-value数据,采用线性探测,如果插入的位置已经有值,自动往后面寻找一个空的位置存储 * @param key * @param value */ public void insert(int key, Object value)&#123; if(length == maxDataSize)&#123; System.out.println(\"已经满了,无法插入!!!!!!\"); //再插入就超过装载因子,碰撞太多,性能急剧下降 &#125; int index = hashFunction(key); //该位置恰好空余,可以插入.发生哈希碰撞,采用线性探测往后找, while(index &lt; hashArray.length)&#123; if(hashArray[index] == null || hashArray[index] == DELETEED_NODE)&#123; //插 hashArray[index] = new Node(key,value); //记录长度 length++; return; &#125; //此处使用线性探测: 每次+1,线性往后探测空余位置 //[二次探测:不使用index++,而是使用每次往后1,4,9...平方探测,将连续的大区域碰撞转化为分散的碎片碰撞导致二次聚集(因为步长是确定的)] //[再hash: 将当前的index再次使用一个不同的hash算法计算后往后找,直到找到目标或者发现null,可以消除原始聚集和二次聚集(步长是不确定的)] index++; //找到了数组最后面,任然没有空余位置 if(index == hashArray.length-1)&#123; //返回数组最前面继续找 index = 0; &#125; &#125; &#125; /** * 查找对象 * @param key * @return */ public Object find(int key)&#123; //是否为空 if(length == 0)&#123; return null; &#125; int index = hashFunction(key); //往后找 while(index &lt; hashArray.length)&#123; //找到一个空节点还没有,说明没有该条记录 if(hashArray[index] == null)&#123; return null; &#125; //该节点有数据,判断是不是目标节点,不是的话可能是碰撞过的,往后找 if(hashArray[index].getKey() == key)&#123; return hashArray[index].getValue(); &#125;else&#123; index++; &#125; if(index == hashArray.length-1)&#123; //找到最后还没有,从队首开始找 index = 0; &#125; &#125; //所有节点都非空,找了还没有 return null; &#125; /** * 从hash表删除 * @param key * @return */ public boolean delete(int key)&#123; //不能硬删除!!!!! 否则之前因为哈希碰撞线性探测存储的数据就找不到了!!!!!!! int index = hashFunction(key); if(hashArray[index]==null)&#123; return false; &#125; //往后找,找到这个元素就软删除,下次查询到这里直接跳过往后找... while(index &lt; hashArray.length)&#123; //找到一个空节点还没有,说明没有该条记录 if(hashArray[index] == null)&#123; return false; &#125; //该节点有数据,判断是不是目标节点,不是的话可能是碰撞过的,往后继续找 if(hashArray[index].getKey() == key)&#123; //找到了，软删除之 hashArray[index] = DELETEED_NODE; length--; return true; &#125;else&#123; index++; &#125; if(index == hashArray.length-1)&#123; //找到最后还没有,从队首开始找 index = 0; &#125; &#125; //没找到 return false; &#125; /** * 打印hash表 */ public void display()&#123; for(int i = 0; i &lt; hashArray.length; i ++)&#123; if(hashArray[i]==null)&#123; System.out.print(\"null,\"); continue; &#125; System.out.print(hashArray[i].getKey()+\"\"+hashArray[i].getValue()+\",\"); &#125; System.out.println(); &#125; /** * 获取长度 */ public int getSize() &#123; return this.maxDataSize; &#125;&#125; QA# 装载因子为啥是0.75？ 是一个时间和空间的这种，tradeoff 这决定扩容的阈值，太低会浪费空间，很早就开始扩容。不过碰撞概率低，查询效率高。 太高会碰撞加剧，插入和查询慢。但是节省空间。 长度为什么是n^2? 因为有一个取&amp;的操作简化取模，保证冲突记录小。否则 # 数组长度是2^3=8 key=2： 00000010 length-1=7： 00000111 ------------------------------------------- 取&amp; 00000010 = 2 key=3： 00000011 length-1=7： 00000111 ------------------------------------------- 取&amp; 00000011 = 3 # 可以看到长度为8的时候，不同的key取的值是不同的 # 数组长度是=9 （非2的整数倍） key=2： 00000010 length-1=8： 00001000 ------------------------------------------- 取&amp; 00000000 = 0 key=3： 00000011 length-1=8： 00001000 ------------------------------------------- 取&amp; 00000000 = 0 # 可以看到长度为8的时候，不同的key取的值是不同的","categories":[{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/categories/java/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://blog.sofunnyai.com/tags/%E6%BA%90%E7%A0%81/"},{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://blog.sofunnyai.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"设计模式---观察者模式","slug":"设计模式-observer观察者","date":"2017-03-03T05:04:09.000Z","updated":"2020-06-03T05:44:45.535Z","comments":true,"path":"article/design-observer.html","link":"","permalink":"https://blog.sofunnyai.com/article/design-observer.html","excerpt":"","text":"观察者模式： 优点： 实际应用： 实现举例 观察者模式：# 参与者：**事件源**(source)、**观察者**（observer/listener）、**事件**（event，可选，如果不想知道时间信息可以不要） 1.将事件源上注册多个观察者 2.当某种特定条件发生的时候（source的某个场景），事件源将此时的信息包装到event中，逐个调用观察者 3.观察者就知晓了事情的发生，并能做出相应(被调用相应方法) 优点：# 避免观察者需要持续关注事件源（比如不用开一个线程去不断判断他的状态是否改变） 只需要将事件发生的逻辑提前准备在观察者上，把观察者注册到事件源上 事件发生的时候就能被自动执行 实际应用：# 典型的如UI界面的各种event和listener 或者AOP，实际上实现是代理，语义上也是一个观察者模式：当方法执行到这里，就触发AOP绑定的拦截器方法。（只是由代理给实现的） 或者Hystrix 实现举例# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 观察者模式： * - 事件源(source)、观察者（observer/listener）、事件（event，可选，如果不想知道时间信息可以不要） * - 将事件源上注册多个观察者 * - 当某种特定条件发生的时候（source的某个场景），事件源将此时的信息包装到event中，逐个调用观察者 * - 观察者就知晓了事情的发生，并能做出相应 * - 典型的如UI界面的各种event和listener * - 或者AOP，实际上实现是代理，语义上也是一个观察者模式：当方法执行到这里，就触发AOP绑定的拦截器方法。（只是由代理给实现的） */public class Main &#123; public static void main(String[] args) &#123; // 事件源，一个baby Child child = new Child(); // 给他添加一些观察者（类似监听） child.addObserver(new Dad()); child.addObserver(new Mum()); // 当发生业务场景，观察者会被触发 child.cry(); &#125;&#125;/** * 事件类，可有可无。是为了给观察者传递当时的业务信息。 * @param &lt;T&gt; */@AllArgsConstructorclass Event&lt;T&gt;&#123; T source; String name; String time;&#125;/** * 所有观察者的接口，观察者统一实现这个接口，发生事件的时候统一触发 * @param &lt;R&gt; */interface Observer &lt;R&gt;&#123; public R actionOnEvent(Event&lt;R&gt;e);&#125;/** * 一个事件源 */class Child&#123; // 观察这个事件源的对象，注册到这里 List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); // 添加观察者 public void addObserver(Observer each)&#123; this.observers.add(each); &#125; public void cry()&#123; // 发生特定事件 System.out.println(\"Baby cry..........\"); // 构造一个事件对象 Event&lt;Child&gt; e = new Event&lt;&gt;(this,\"孩子哭了\", new Date().toLocaleString());; // 触发所有的观察者 for (Observer each : observers) &#123; each.actionOnEvent(e); &#125; &#125;&#125;/** * 一个观察者Dad */class Dad implements Observer&lt;Child&gt;&#123; @Override public Child actionOnEvent(Event&lt;Child&gt; e) &#123; System.out.println(\"Dad feed baby........\"); return e.source; &#125;&#125;/** * 一个观察者Mum */class Mum implements Observer&lt;Child&gt;&#123; @Override public Child actionOnEvent(Event&lt;Child&gt; e) &#123; System.out.println(\"Mum pat baby........\"); return e.source; &#125;&#125;","categories":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://blog.sofunnyai.com/categories/DesignPattern/"}],"tags":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://blog.sofunnyai.com/tags/DesignPattern/"}]},{"title":"设计模式---命令模式","slug":"design-pattern-command","date":"2017-02-03T00:59:25.000Z","updated":"2020-06-03T08:15:29.944Z","comments":true,"path":"article/design-pattern-command.html","link":"","permalink":"https://blog.sofunnyai.com/article/design-pattern-command.html","excerpt":"","text":"设计模式之—命令模式 角色： 文本编辑器的举例 实例 案例实现 命令抽象接口，定义一个无参方法，使得更通用 命令实现----加法命令，一般只携带命令数据（为了简化也可以直接在命令里完成业务逻辑） 命令实现----乘法命令，一般只携带数据（为了简化也可以直接在命令里完成业务逻辑） 真正的业务逻辑处理方法（处理Command的地方） 客户端和Invoker 编辑器案例的伪代码： 设计模式之—命令模式# 命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。它可将请求转换为一个包含与请求相关的所有信息的独立对象。 该转换让你能根据不同的请求将方法参数化、 延迟请求执行或将其放入队列中， 且能实现可撤销操作。 一句话核心：将一个请求封装成一个对象，从而使可以用不同的请求对客户进行参数化。 主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。使用命令对象去分层。 何时使用： 在某些场合，比如要对行为进行&quot;记录、撤销/重做、事务&quot;等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将&quot;行为请求者&quot;与&quot;行为实现者&quot;解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决： 通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 关键代码： 定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口 应用实例： SpringCloud的HystrixCommand使用了命令模式。 优点： 1、降低了系统耦合度。 2、新的命令可以很容易添加到系统中去。 缺点： 使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景： 认为是命令的地方都可以使用命令模式，比如： 类似回调的地方，可以使用观察者模式实现。也可以考虑用命令模式实现一个请求-响应，如GUI 中每一个按钮都是一条命令。 考虑到事务、撤销等场景 角色：# 客户端 （Client） 会创建并配置具体命令对象。 客户端必须将包括接收者实体在内的所有请求参数传递给命令的构造函数。 此后， 生成的命令就可以与一个或多个发送者相关联了。 发送者 （Sender/Invoker）——负责对请求进行初始化， 其中必须包含一个成员变量来存储对于命令对象的引用。 发送者触发命令， 而不向接收者直接发送请求。 注意， 发送者并不负责创建命令对象： 它通常会通过构造函数从客户端处获得预先生成的命令。 命令接口 （Command） ：通常仅声明一个执行命令的方法。 具体命令实现 （Concrete Commands） 会实现各种类型的请求。 具体命令自身并不完成工作， 而是会将调用委派给一个业务逻辑对象。 但为了简化代码， 这些类可以进行合并。 接收对象执行方法所需的参数可以声明为具体命令的成员变量。 你可以将命令对象设为不可变， 仅允许通过构造函数对这些成员变量进行初始化。 接收者 （Receiver） 类包含部分业务逻辑。 几乎任何对象都可以作为接收者。 绝大部分命令只处理如何将请求传递到接收者的细节， 接收者自己会完成实际的工作。 文本编辑器的举例# GUI上的Button持有很多Command类型，事件发生的时候生成并丢给Editor业务逻辑类去执行。并可以撤销。 客户端代码 （GUI 元素和命令历史等） 没有和具体命令类相耦合， 因为它通过命令接口来使用命令。 这使得你能在无需修改已有代码的情况下在程序中增加新的命令。 在代码中看上去就像这样： 一个 GUI 对象传递一些参数来调用一个业务逻辑对象。 这个过程通常被描述为一个对象发送请求给另一个对象。(×，耦合严重) 【改进】：命令模式建议 GUI 对象不直接提交这些请求。 你应该将请求的所有细节 （例如调用的对象、 方法名称和参数列表） 抽取出来组成Command类， 该类中仅包含一个用于触发请求的方法。 命令对象负责连接不同的 GUI 和业务逻辑对象。 此后， GUI 对象无需了解业务逻辑对象是否获得了请求， 也无需了解其对请求进行处理的方式。 GUI 对象触发命令即可， 命令对象会自行处理所有细节工作。 下一步是让所有命令实现相同的接口。 该接口通常只有一个没有任何参数的执行方法， 让你能在不和具体命令类耦合的情况下使用同一请求发送者执行不同命令。 此外还有额外的好处， 现在你能在运行时切换连接至发送者的命令对象， 以此改变发送者的行为。 请求的参数： GUI 对象可以给业务层对象提供一些参数。 但执行命令方法没有任何参数， 所以我们如何将请求的详情发送给接收者呢？ 答案是： 使用数据对命令进行预先配置， 或者让其能够自行获取数据。 让我们回到文本编辑器。 应用命令模式后， 我们不再需要任何按钮子类来实现点击行为。 我们只需在 按钮Button基类中添加一个成员变量来存储对于命令对象的引用， 并在点击后执行该命令即可。你需要为每个可能的操作实现一系列命令类， 并且根据按钮所需行为将命令和按钮连接起来。 其他菜单、 快捷方式或整个对话框等 GUI 元素都可以通过相同方式来实现。 当用户与 GUI 元素交互时， 与其连接的命令将会被执行。 现在你很可能已经猜到了， 与相同操作相关的元素将会被连接到相同的命令， 从而避免了重复代码。 最后，命令成为了减少 GUI 和业务逻辑层之间耦合的中间层 而这仅仅是命令模式所提供的一小部分好处！ 实例# 一般command中会有一个run/execute/do类似的执行方法，还会有一个undo/fallBack类似的反向撤销方法。 比如下面一个Command接口，里面有do和undo方法，同时他好几个不同的Command实现。 案例实现# 优点： 下面将Invoker和Receiver通过Command解耦了！对于调用者可以准备多个Command，在合适的时候使用即可，不用关心实现。 命令抽象接口，定义一个无参方法，使得更通用# 123456public interface Command &#123; // 常见命名为 run execute do 等 public int run(); public int undo();&#125; 命令实现----加法命令，一般只携带命令数据（为了简化也可以直接在命令里完成业务逻辑）# 1234567891011121314151617181920212223/** * 加法命令,只承载具体的请求数据，委托给业务逻辑去处理 */@Data@AllArgsConstructorpublic class PlusCommand implements Command &#123; private Calculator receiver; // 持有一个接受者，接受者计算器去完成业务逻辑 private int num1,num2; // 携带的业务数据 // 执行命令,一般是无参的，可以保证多个command实现类共用一个方法 @Override public int run() &#123; System.out.printf(\"执行加法run命令%d+%d=%d\\n\",num1,num2,num1+num2); return receiver.doPlus(num1,num2); // 由具体的业务逻辑实现类去完成业务，这里只是封装数据 &#125; // 回退命令 @Override public int undo() &#123; System.out.printf(\"执行加法undo命令后的结果：%d\\n\",num1); return num1; &#125;&#125; 命令实现----乘法命令，一般只携带数据（为了简化也可以直接在命令里完成业务逻辑）# 12345678910111213141516171819202122/** * 乘法命令 */@Data@AllArgsConstructorpublic class MultCommand implements Command &#123; private Calculator receiver; //持有一个接受者，接受者计算器去完成业务逻辑 private int num1,num2; // 携带的业务数据 // 执行命令 @Override public int run() &#123; return receiver.doMultiple(num1,num2); // 由具体的业务逻辑实现类去完成业务，这里只是封装数据 &#125; // 回退命令 @Override public int undo() &#123; System.out.printf(\"执行惩乘法undo命令后的结果：%d\\n\",num1); return num1; &#125;&#125; 真正的业务逻辑处理方法（处理Command的地方）# 123456789101112131415/** * 具体的命令接受者，完成真正业务逻辑 */public class Calculator &#123; public int doPlus(int a, int b)&#123; System.out.printf(\"receiver执行加法命令%d×%d=%d\\n\",a,b,a+b); return a + b; &#125; public int doMultiple(int a, int b)&#123; System.out.printf(\"receiver执行乘法命令%d×%d=%d\\n\",a,b,a*b); return a * b; &#125;&#125; 客户端和Invoker# 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Main &#123; /** * 命令模式，一般是一个命令接口，很多个实现 * 常用语实现命令的exec和undo。如Action、Transaction等 * @param args */ public static void main(String[] args) &#123; Client client = new Client(); client.business1Plus(10,2); client.business2Multiple(3,2); &#125;&#125;/** * 客户端，产生事件的地方 */class Client&#123; Calculator receiver = new Calculator(); // 真正的业务逻辑处理receiver /** * 客户端发生加法业务 * @param a * @param b */ public void business1Plus(int a, int b)&#123; // 构造一个命令 Command add = new PlusCommand(receiver, a, b); // 命令给到Invoker去执行（有时候Invoker和Client合二为一） Invoker invoker = new Invoker(); invoker.setCommand(add); int res = invoker.executeCommand(); System.out.println(\"命令执行的结果是：\" + res); &#125; /** * 客户端发生乘法业务 * @param a * @param b */ public void business2Multiple(int a, int b)&#123; // 构造一个乘法命令 Command multiple = new MultCommand(receiver,a,b); // 命令给到Invoker去执行（有时候Invoker和Client合二为一） Invoker invoker = new Invoker(); invoker.setCommand(multiple); int res = invoker.executeCommand(); System.out.println(\"命令执行的结果是：\" + res); &#125;&#125;/** * 调用者，有时候也会和Cliet合二为一 */@Dataclass Invoker&#123; private Command command; public int executeCommand()&#123; return command.run(); &#125;&#125; 编辑器案例的伪代码：# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132// 命令基类会为所有具体命令定义通用接口。abstract class Command is protected field app: Application protected field editor: Editor protected field backup: text constructor Command(app: Application, editor: Editor) is this.app = app this.editor = editor // 备份编辑器状态。 method saveBackup() is backup = editor.text // 恢复编辑器状态。 method undo() is editor.text = backup // 执行方法被声明为抽象以强制所有具体命令提供自己的实现。该方法必须根 // 据命令是否更改编辑器的状态返回 true 或 false。 abstract method execute() //----------------------------------------------------------------------------------// 这里是具体命令实现。class CopyCommand extends Command is // 复制命令不会被保存到历史记录中，因为它没有改变编辑器的状态。 method execute() is app.clipboard = editor.getSelection() return falseclass CutCommand extends Command is // 剪切命令改变了编辑器的状态，因此它必须被保存到历史记录中。只要方法 // 返回 true，它就会被保存。 method execute() is saveBackup() app.clipboard = editor.getSelection() editor.deleteSelection() return trueclass PasteCommand extends Command is method execute() is saveBackup() editor.replaceSelection(app.clipboard) return true// 撤销操作也是一个命令。class UndoCommand extends Command is method execute() is app.undo() return false //---------------------------------------------------------------------------------- // 全局命令历史记录就是一个堆桟。class CommandHistory is private field history: array of Command // 后进... method push(c: Command) is // 将命令压入历史记录数组的末尾。 // ...先出 method pop():Command is // 从历史记录中取出最近的命令。//----------------------------------------------------------------------------------// 编辑器类包含实际的文本编辑操作。它会担任接收者的角色：最后所有命令都会// 将执行工作委派给编辑器的方法。class Editor is field text: string method getSelection() is // 返回选中的文字。 method deleteSelection() is // 删除选中的文字。 method replaceSelection(text) is // 在当前位置插入剪贴板中的内容。 //----------------------------------------------------------------------------------// 应用程序类会设置对象之间的关系。它会担任发送者的角色：当需要完成某些工// 作时，它会创建并执行一个命令对象。class Application is field clipboard: string field editors: array of Editors field activeEditor: Editor field history: CommandHistory // 将命令分派给 UI 对象的代码可能会是这样的。 method createUI() is // ... copy = function() &#123; executeCommand( new CopyCommand(this, activeEditor)) &#125; copyButton.setCommand(copy) shortcuts.onKeyPress(\"Ctrl+C\", copy) cut = function() &#123; executeCommand( new CutCommand(this, activeEditor)) &#125; cutButton.setCommand(cut) shortcuts.onKeyPress(\"Ctrl+X\", cut) paste = function() &#123; executeCommand( new PasteCommand(this, activeEditor)) &#125; pasteButton.setCommand(paste) shortcuts.onKeyPress(\"Ctrl+V\", paste) undo = function() &#123; executeCommand( new UndoCommand(this, activeEditor)) &#125; undoButton.setCommand(undo) shortcuts.onKeyPress(\"Ctrl+Z\", undo) // 执行一个命令并检查它是否需要被添加到历史记录中。 method executeCommand(command) is if (command.execute) history.push(command) // 从历史记录中取出最近的命令并运行其 undo（撤销）方法。请注意，你并 // 不知晓该命令所属的类。但是我们不需要知晓，因为命令自己知道如何撤销 // 其动作。 method undo() is command = history.pop() if (command != null) command.undo() https://refactoringguru.cn/design-patterns/command","categories":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://blog.sofunnyai.com/categories/DesignPattern/"}],"tags":[{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://blog.sofunnyai.com/tags/DesignPattern/"}]},{"title":"超高性能单机队列disruptor","slug":"disruptor","date":"2017-01-11T03:13:11.000Z","updated":"2020-06-15T03:16:19.610Z","comments":true,"path":"article/disruptor.html","link":"","permalink":"https://blog.sofunnyai.com/article/disruptor.html","excerpt":"","text":"Java中的队列介绍 Java中的队列介绍# 开门见山，我们看一眼Java并发包中的常见队列： 队列 有界性 锁 数据结构 ArrayBlockingQueue Y 加锁 arraylist LinkedBlockingQueue optionally-bounded 加锁 linkedlist ConcurrentLinkedQueue N CAS linkedlist LinkedTransferQueue N CAS linkedlist PriorityBlockingQueue N 加锁 heap DelayQueue N 加锁 heap …/cacheline-contended.html","categories":[{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/categories/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"中间件","slug":"中间件","permalink":"https://blog.sofunnyai.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]}],"categories":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/categories/risk/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/categories/SpringCloud/"},{"name":"network","slug":"network","permalink":"https://blog.sofunnyai.com/categories/network/"},{"name":"spring","slug":"spring","permalink":"https://blog.sofunnyai.com/categories/spring/"},{"name":"IO","slug":"IO","permalink":"https://blog.sofunnyai.com/categories/IO/"},{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/categories/java/"},{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"xx","slug":"xx","permalink":"https://blog.sofunnyai.com/categories/xx/"},{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/categories/%E5%B9%B6%E5%8F%91/"},{"name":"框架","slug":"框架","permalink":"https://blog.sofunnyai.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/categories/hexo/"},{"name":"中间件","slug":"中间件","permalink":"https://blog.sofunnyai.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://blog.sofunnyai.com/categories/DesignPattern/"}],"tags":[{"name":"risk","slug":"risk","permalink":"https://blog.sofunnyai.com/tags/risk/"},{"name":"strategy","slug":"strategy","permalink":"https://blog.sofunnyai.com/tags/strategy/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.sofunnyai.com/tags/SpringCloud/"},{"name":"评分卡","slug":"评分卡","permalink":"https://blog.sofunnyai.com/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"},{"name":"网络","slug":"网络","permalink":"https://blog.sofunnyai.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"hexo","slug":"hexo","permalink":"https://blog.sofunnyai.com/tags/hexo/"},{"name":"运维","slug":"运维","permalink":"https://blog.sofunnyai.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"java","slug":"java","permalink":"https://blog.sofunnyai.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://blog.sofunnyai.com/tags/spring/"},{"name":"基础","slug":"基础","permalink":"https://blog.sofunnyai.com/tags/%E5%9F%BA%E7%A1%80/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.sofunnyai.com/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.sofunnyai.com/tags/SpringBoot/"},{"name":"多线程","slug":"多线程","permalink":"https://blog.sofunnyai.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"并发编程","slug":"并发编程","permalink":"https://blog.sofunnyai.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"tag1","slug":"tag1","permalink":"https://blog.sofunnyai.com/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"https://blog.sofunnyai.com/tags/tag2/"},{"name":"aop","slug":"aop","permalink":"https://blog.sofunnyai.com/tags/aop/"},{"name":"并发","slug":"并发","permalink":"https://blog.sofunnyai.com/tags/%E5%B9%B6%E5%8F%91/"},{"name":"框架","slug":"框架","permalink":"https://blog.sofunnyai.com/tags/%E6%A1%86%E6%9E%B6/"},{"name":"jdk","slug":"jdk","permalink":"https://blog.sofunnyai.com/tags/jdk/"},{"name":"源码","slug":"源码","permalink":"https://blog.sofunnyai.com/tags/%E6%BA%90%E7%A0%81/"},{"name":"特征工程","slug":"特征工程","permalink":"https://blog.sofunnyai.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"闲杂","slug":"闲杂","permalink":"https://blog.sofunnyai.com/tags/%E9%97%B2%E6%9D%82/"},{"name":"中间件","slug":"中间件","permalink":"https://blog.sofunnyai.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"mysql","slug":"mysql","permalink":"https://blog.sofunnyai.com/tags/mysql/"},{"name":"数据结构","slug":"数据结构","permalink":"https://blog.sofunnyai.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://blog.sofunnyai.com/tags/DesignPattern/"}]}